---
title: 重要复习
date: 2023-08-22 09:22:48
tags:
- 编程
- 八股
- C++
categories:
- 学习
- 编程
- 面试
---

流程：

1. 先放一套题让做？

2. 正式面试：
   1. 对游戏客户端有什么了解？觉得客户端主要是做什么的
      1. 游戏客户端是和游戏服务端相对应的，为客户提供本地服务的程序，这一点和普通的服务端客户端没有太多差别。
      1. 客户端为客户提供的本地服务主要是游戏玩法的实现Gameplay，比如战斗系统实现、任务流程进行、UI界面交互啊，还有例如人物、技能、装备这种。
      1. 用户界面设计与开发
      1. 游戏的核心逻辑和玩法设计
      1. 客户端主要是做什么的，主要就是实现刚才那些服务，为客户也就是玩家实现与游戏交互的各种响应。

   2. 算法题：
      1. 有序链表合并
         1. 两个有序链表合并（力扣）：使用递归，决定当前这一位是l1还是l2，然后进行递归。
         2. 合并k个有序链表（力扣）：
            1. 两种方法：分治法和优先队列，推荐优先队列
            2. 分治法需要前置两个有序链表合并代码，然后使用二分法，将链表合并，第一波先合并k/2组链表，时间代价为2n，然后k/4组，时间代价为4n，最后为O(kn*logk)，递归使用到logk的栈空间
            3. 优先队列：首先，需要使用优先队列，priority_queue，然后创建一个结构Status，这个Status存储了链表当前指向的指针以及值，还有重载<号（注意一下，这里的operator<需要加上两个const，否则可能会编译错误，原因可能是因为sort里面使用到了const，而const成员只能调用const函数，所以会报错），将<重载为大于的含义，因为优先队列是默认的大根堆，所以会在比对的时候使用<号，我们将其视为>改为小根堆。
            4. 改为小根堆的方法也可以使用priority_queue<Status,vector<Status>,greater<Status>>。
            5. ListNode head,*tail = &head;
      2. 1000位以内十进制转二进制，逆序后再转十进制
         1. 牛客：**KY26** **10进制 VS 2进制**
         2. 因为可能是一个非常大的数，所以不可以直接算，需要一个进制转换的模板。
         3. 好他妈难的进制转换，，，
         4. 重点复习一下
         5. 大概就是拿除法那一套，然后得到最后是否有余数
      3. 哈夫曼，最小编码长度
         1. [最短字符编码_牛客题霸_牛客网 (nowcoder.com)](https://www.nowcoder.com/practice/5f76ce2a25744d96bb9797e03c523302?tab=note#:~:text=描述 给定一个非空字符串%2C 按照如下方式编码%2C 使得编码后长度最小%2C 返回编码后的长度%3A 编码规则为%3A,k [encoding_string]%2C 表示重复k次encoding_strng%2C 例如'abcdefabcdefabc'可表示为'2 [abcdef]abc'%2C 但是'aaa'仅能编码成'aaa'%2C)
         2. 具体答案看牛客上保存的答案。
         3. 还得看，不太会。
         4. 太简单了，我麻了，怎么我没做出来
         5. 反正就是简单地搞一个小根堆，如果堆的大小大于1就取出两个数加到ans上去。
         6. 麻了。
      
   3. 和平时开发软件有什么不一样
      1. 游戏客户端的开发比平常的软件开发更注重图形渲染的表现，也就是需要图形学的知识。
      2. 游戏客户端需要通过引擎来实现游戏里面的各种界面设计和Gameplay设计，平常软件一般来说是不会使用到引擎的。
      3. 服务端方面也需要考虑到实时的同步问题，游戏对延迟的要求非常严格。

   4. 面向对象三大特性

      1. [c++类和继承面试点25连问 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/381970888)

      2. 封装：把数据（属性）和操作（方法）捆绑在一个单一的单元，也就是类，并且把自己的属性和方法让可信的类或对象操作，对不可信的隐藏。对外部隐藏了实现的细节，只暴露了必要的接口供其他代码使用。

         1. public：通常用于暴露类的接口提供给外部代码使用
            1. 公有成员在类的内部和外部都可以访问（友元函数也可以）
            2. 对于类的对象以及类的派生类，都可以直接访问公有成员
         2. protected：通常用于在继承关系中共享信息，但是不希望公开给外部
            1. 保护成员在类的内部可以访问，在外部不可直接访问（友元函数也可以）
            2. 对于类的派生类，可以访问其基类的保护成员，该类的对象不可以访问
         3. private：私有成员用于封装类的内部实现细节，防止外部代码直接访问和修改
            1. 私有成员仅在类的内部可以访问，对外部不可见（友元也可以）
            2. 私有成员对于类的对象和派生类都不可以直接访问

      3. 继承：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。共享父类的属性和方法，子类可以继承父类的特性，然后在此基础上添加新的特性或者覆盖父类的方法。这有助于代码的重用，避免了重复编写相似的代码，也支持代码的扩展和分层。

         1. 基类、父类、超类
         2. 子类、派生类
         3. 子类可以直接访问父类中非私有的属性和行为
         4. 通过extends关键字让类与类之间产生继承关系。
         5. 派生类调用构造函数和析构函数的顺序（先基类构造，后基类析构）
         6. C++多继承？
         7. 虚继承：解决多继承时候的命名冲突和冗余数据，C++提出了虚继承，只保留一份间接基类的成员。

      4. 多态：多种形态，就是我们使用基类的指针或者引用调用基类的某个函数时，编译期并不知道到底是要调用哪个函数，因为我们不能确定这个指针或者引用到底指向基类对象还是派生类对象，直到运行时才能确定，这个就叫多态。

         1. 多态允许不同类的对象对同一方法做出不同的响应。这意味着可以使用统一的方法名来处理不同类型的对象，从而提高了代码的灵活性和可扩展性。多态性可以通过继承和接口（或抽象类）来实现。在运行时，程序会根据对象的实际类型来调用相应的方法。

         2. 个人理解，其实就是实现了接口的重用，同样的接口，派生类与基类不同的实现。

         3. 一般来讲多态分为编译时多态和运行时多态，编译时多态就是指的重载哪些，我们通常默认多态是运行时的多态。

            运行时多态简单来讲就是：使用基类指针或者引用指向一个派生类对象，在非虚继承的情况下，派生类直接继承基类的虚表指针，然后使用派生类的虚函数去覆盖基类的虚函数，这样派生类对象通过虚表指针访问到的虚函数就是派生类的虚函数了。

   5. 多态是如何实现的

      1. 虚函数表：编译器会在编译期创建一个虚函数表，虚函数表里面存储虚函数的地址。这个表在类的对象中不会存储实际的数据，而是在每个对象的内存布局中保留一个指向虚函数表的指针。
      2. 虚函数指针：每个类的对象都会有一个指向其虚函数表的虚函数指针。这个指针在对象的内存布局中通常位于对象的开头部分。当调用一个虚函数时，实际上是通过对象的虚函数指针找到对应的虚函数表，然后根据函数索引从虚函数表中获取需要调用的函数的地址。
      3. 动态绑定：当基类的指针或引用指向派生类的对象并调用虚函数时，编译器会根据对象的实际类型找到相应的虚函数表，并根据函数表中的函数索引调用正确的虚函数，这个过程成为动态绑定，因为在运行时才确定要调用的函数，而不是在编译时静态地确定。

   6. 代码编写层面是如何实现多态的

      1. 父类包含虚函数，用virtual关键字声明，然后从父类派生出多个子类，在子类中重写这些虚函数以实现不同的行为。
      2. 使用基类指针或引用，在运行时候就可以根据对象的类型来调用正确的虚函数
      3. 虚函数关键字和重写，声明虚函数的时候使用virtual关键字，在派生类中重写虚函数时使用override关键字来确保函数签名正确匹配基类的虚函数。

   7. 多个虚函数会影响对象大小吗？

      1. 不会吧，因为如果有虚函数需要在所有成员变量的基础上加上一个虚函数指针的大小，在64位机器中，虚函数指针大小为8个字节。（字节对齐）
      2. 空类大小为1个字节

   8. 可以在析构函数和构造函数中使用虚函数吗？

      1. 可以在析构函数中使用虚函数。一般情况下，只有一个类被用作基类时才需要使用虚析构函数，这样做的作用是当一个基类的指针删除派生类的对象时，能确保派生类的析构函数会被调用。（建议在基类中使用虚析构函数），这其实就相当于析构函数的多态，基于多态的作用，这个指向派生类的基类指针会先调用派生类的析构函数，然后再调用基类的析构函数。
      2. 构造函数不可以为虚函数，因为虚函数是放在虚表里面的，而虚表是在构造函数执行的过程中才建立的，就会产生冲突。
      3. 构造函数里面可以调用虚函数，因为虚函数表是在编译期建立的，当调用构造函数的时候，首先会初始化虚函数指针，那我们就知道了虚函数的地址，就可以调用了。（可以调用虚函数，但是调用的效果不如人意，会指向的是基类的虚函数。）

   9. 程序内存布局

      1. 代码段：程序的所有指令会存放在这个区域，这是已经编译后的机器码
      2. 数据段：已初始化的数据，全局和静态变量，C++用global/static声明的变量都存放在这个区域，对所有函数公开可见。
      3. 字面量池：程序初始化时一些字符串字面量，在程序中用于显示文字。
      4. BSS段：未初始化的数据
      5. 堆：又叫空闲内存区，用于动态内存分配，这个区域是高地址增长的。C++：new delete C：malloc，realloc，free
      6. 栈：用于局部变量和将参数传递给函数，以及函数调用结束时将要执行的下一条指令的返回地址。当需要添加新的堆栈帧（作为新函数的结果），堆栈向下增长。
      7. 命令行参数和环境变量：操作系统，环境变量，命令行参数
      8. 共享库区域：没看到，不答
      9. 内存映射区域：没看到，不答

   10. 堆与栈的区别

       1. 堆：按需申请，动态分配
       2. 栈：程序运行时自动拥有的一小块内存，大小在编译器时由编译器参数决定，用于局部变量的存放或者函数调用栈的保存。
       3. 区别：
          1. 栈是系统自动分配释放的，而堆是由程序员控制的，容易产生内存泄漏。
          2. 大小：每个进程拥有的栈大小要远远小于堆大小。
          3. 生长方向不同：堆的生长方向向上，内存地址由低到高；栈的生长方向向下，内存地址由高到低。
          4. 分配方式不同：堆都是动态分配的，没有静态分配的堆；栈有的动态静态两种。静态分配是由操作系统完成的，比如局部变量的分配。动态分配由alloca()函数分配，但是栈的动态分配和堆是不同的，它的动态分配是由操作系统进行释放，无需我们手工实现。
          5. 分配效率：栈是硬件层级支持，更快。堆是由C++提供的库或则和运算符来完成申请与管理，较为复杂，频繁的申请容易产生内存碎片，效率低得多。
          6. 存放内容不同：堆是由程序员来填充的，栈存放函数返回地址、相关参数、局部变量和寄存器内容等。

   11. 函数的压栈和出栈

       1. [C++ 函数压栈与出栈 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/642851340#:~:text=在C%2B%2B中，函数压栈（函数调用）和出栈（函数返回）是函数调用过程中的两个关键步骤。 下面将逐步解释这两个过程。,函数压栈（函数调用）的过程如下： 调用指令：在函数调用点，会发出一个调用指令（如call指令），将控制权转移到被调用函数的入口点。 保存返回地址：调用指令执行前，当前函数的返回地址会被压入栈中，以便在函数执行完毕后返回到正确的位置。)
       2. 函数压栈：
          1. 调用指令：在函数调用点，会发出一个调用指令，将控制权转移到被调用函数的入口点。
          2. 保存返回地址：当前函数的返回地址被压入栈中，以便哈桉树执行完毕后返回到正确的位置。
          3. 参数压栈：函数调用时，将函数的参数按照一定的顺序压入栈中，通常从右到左依次入栈。
          4. 保存寄存器值：在一些体系结构中，函数调用时需要保存一些寄存器的值，以便在函数执行完毕后能够恢复原始的寄存器状态，
          5. 帧指针与局部变量压栈：为了支持函数内的局部变量和堆栈的动态分配，通常在栈上维护一个帧指针，它指向当前函数的栈帧的底部。同时，函数内部定义的局部变量也会在栈上分配空间。
          6. 执行函数体
       3. 函数出栈：
          1. 恢复寄存器值：在一些体系结构中，函数返回时需要恢复之前保存的寄存器的值。
          2. 释放局部变量和帧指针：函数返回后，会释放函数内部定义的局部变量所占用的栈空间，并将帧指针恢复到上一层函数的栈帧。
          3. 弹出参数和返回地址：函数返回后，参数和返回地址会从栈中弹出，将控制权返回到调用函数的正确位置。

   12. C++工程开发中如何申请分配内存

       1. new和delete：new可以用于动态地分配内存，并返回指向新分配内存的指针，delete用于释放使用new分配的内存。如果是数组则需要使用delete[]。
       2. malloc和free：内存管理函数，如malloc、calloc和realloc，不过返回的是void*类型的指针，需要手动进行类型转换。（static_cast<int *>）
       3. 使用智能指针和标准库容器：
          1. shared_ptr、unique_ptr等提供了更安全的内存管理方式，能够自动处理资源的释放。
          2. 标准库容器如vector、list等可以管理动态大小的数据集合，避免手动内存分配和释放的麻烦。

   13. new和malloc的区别

       1. malloc是一个函数，而new是C++一个操作符。
       2. new是C++的运算符，它可以调用构造函数来初始化内存，并返回正确类型的指针。malloc是C标准库函数，返回一个void*指针，需要手动进行类型转换。malloc不会调用对象的构造函数，只是分配一块内存。（也就是说申请自定义类型对象的时候，malloc只会开辟空间，而new会先开辟空间，再去调用对象的构造函数完成初始化）
       3. malloc需要手动计算开辟空间的大小，new后面只需要跟上空间的类型，如果有多个对象加上[]给个数即可。
       4. malloc失败会返回空指针，需要手动检查，new失败会抛出异常，要用catch捕获。

   14. 内存泄漏有听说过吗

       1. 概念：内存泄露是指在程序运行过程中，分配的内存没有被正确释放，从而导致内存被占用过多的现象。通常，每次内存分配都需要在程序结束后释放，如果忘记释放，可以会导致内存泄露现象的发生。在C/C++中，内存泄露主要与动态内存分配有关，在使用C/C++进行动态内存分配时，程序必须负责分配内存和释放内存，以确保内存使用的正确性。
       2. 原因：
          1. 未正确释放内存：在使用C++进行动态内存分配的时候，应该手动分配内存并在使用完毕后手动释放内存，如果忘记释放内存会导致内存泄露的发生。（使用new和malloc的时候必须使用delete和free来释放）（堆内存泄露）
          2. 在循环中分配内存从未释放：在循环分配内存空间时，如果在循环中忘记释放内存空间，会导致内存泄露。
          3. 对同一个指针重新分配内存
          4. 没有把基类的析构函数定义为虚函数：这就导致了子类的析构函数将不会被调用，子类的资源没有正确地释放，造成内存泄露
          5. 系统内存泄露：程序使用一些系统分配的资源（打开文件、数据库连接或者其他资源），但是没有使用相应的函数释放掉，可能会导致内存泄露。
          6. 异常：在异常抛出后未能正确释放资源，导致内存泄漏。
          7. 代码定义了一个临时对象，定义好后没有用指针对其进行指向，所以在程序退出时申请的资源就不会进行释放。
          8. 内存拷贝和复制：

   15. 野指针听说过吗？什么情况下会引起

       1. 听说过
       2. 指向非法的内存地址的指针就是野指针，也叫作悬挂指针，是没有办法正常使用的指针。
       3. 出现的情况：
          1. 使用未初始化的指针：在定义了指针变量后没有对它进行初始化
          2. 指针所指的对象已经消亡了，超出了它的作用域：指针指向某个对象之后，当这个对象的生命周期已经结束了，对象已经消亡了之后，仍然在使用指针访问该对象。
          3. 指针释放之后没有置空：指针p被free或者delete之后，没有置为NULL，让人以为P是个合法的指针。应该把释放后的指针立即置为NULL，防止产生野指针。
       4. 避免的方法：
          1. 多使用引用
          2. 如果一定要使用指针，在定义指针变量的同时对它进行初始化。
          3. 对指针进行free或者delete操作后，将其置为NULL。

   16. 内存对齐

       1. 方便计算机去读写数据，有些硬件平台不一定支持访问任意内存地址数据
       2. 因为内存是分块的就，假如一个四字节变量里面存在一个四字节地址的后三位和下一个四字节地址的前一位，那么我要得到这个数据的话就需要访问两个内存并将它们结合起来，这样就降低了CPU的性能。
       3. 在内存中分配数据的时候，数据存储的起始地址需要满足一定的要求，以便于处理器能够高效地访问这些数据。处理器的访问效率通常与数据的对齐有关，不正确的内存对齐可能导致性能下降甚至出错。
       4. 有缺点的话可能是：空间浪费；

   17. 程序员开发中要手动内存对齐吗

       1. 大多数情况下不需要手动进行内存对齐，因为编译器通常会自动处理大部分内存对齐问题。
       2. 如果有一些特殊情况，比如说有特定的硬件要求、网络通信和文件读写的数据包排列、内存映射、特殊编译器指令等要求，可能需要手动内存对齐。
       3. 或者是当在编写一些特定的数据结构的时候，手动调整内存对齐可以减少内存的浪费。
       4. #pragma pack(1)

   18. C++map底层实现原理，了解过吗

       1. map的底层是用红黑树实现的，各种操作的时间复杂度都是O(log n)
       2. 红黑树的性质：
          1. 每个节点是红色或者黑色
          2. 根节点是黑色的
          3. 所有的叶子节点都是黑色的
          4. 不能有两个连续的红色节点
          5. 从任意节点到每个叶子节点的所有路径都包含相同数量的黑色节点。、
       3. 查找操作与二叉搜索树类似
       4. 插入与删除先找到插入位置，然后根据红黑树规则进行着色和旋转操作
       5. 迭代器遍历：中序遍历得到的结果是有序的，所以可以按照键的有序顺序遍历元素

       同时：unordered_map的底层是基于哈希表实现的，它的内部是无序的

       1. unordered_map的内部是一个hash_table，一般是一个vector结构
       2. vector里面的每个元素对应一个桶，当桶内数量在8以内使用链表实现，数据量大于8则自动转换为红黑树结构

   19. c#的Dictionary的底层实现

       1. 字典的key-value映射是通过哈希函数来建立的
       2. 哈希桶
       3. C#解决哈希冲突的方法是链接法：将产生冲突的元素建立一个单链表，并将头指针地址存在对应桶的位置，这样每个桶只存了一个值，然后通过遍历单链表的形式来查找元素。
       4. 插入数据时，先获取key值的hashcode，用过hashcode找到桶的索引，以这个索引为下标的桶中存储了作为链表头结点的数据的索引。首先找到entries数组中的空闲位置index，放入entry中，然后接下来使用头插法，将上一个节点的索引保存到自己的next字段，插入的结点变为新的头结点。特别注意的是，此时桶的目标索引指向的是index。

   20. 哈希冲突是怎么解决的

       1. 常用的主要由两种方法解决冲突
          1. 链接法：将所有哈希地址相同的结点链接在同一个单链表里面
          2. 开放定址法（线性探查法、二次探查法、双重散列法）：当冲突发生时，使用某种探查技术在hashtable里面寻找下一个空的地址。
          3. 线性探查法：找不到就+1，可能会出现堆积（也就是不相同的哈希值抢占同一个后续的哈希地址）
          4. 平方探测法：h(x)=(Hash(x) +i)mod (Hashtable.length)
          5. 双重散列法：
          6. 再哈希法：同时构造不同的哈希函数，发生冲突就是用第二个。
          7. 将哈希表分为基本表和溢出表，把发生冲突的放入溢出表

   21. A*算法，一般应用场景

       1. 是一种在图形（或网络）上进行路径搜索和图搜索的常用算法，用于找到从起点到终点的最短路径。算法同时考虑了从起点到当前节点的实际路径成本（通常用代价或距离来表示）以及从当前节点到目标节点的估计成本，通过综合这两个成本来进行决策。
       2. 优先队列openlist
       3. closelist
       4. 游戏开发（NPC的移动计算，可以寻找最优路径）

   22. 了解过那些碰撞算法

       1. 不怎么了解

       2. 应该是有基于图像空间还有基于几何空间的算法

   23. 3D数学有了解过吗，叉乘、点乘、矩阵。叉乘和点乘的区别，引用场景，矩阵有哪些应用。

       1. 点乘：两个向量对应位一一相乘之后求和的操作，点乘的结果是一个标量。可以计算向量a和b之间的夹角 a*b / (|a|*|b|)，可以实现线性变换

       2. 叉乘：也叫向量积，结果是一个向量。a和b的叉乘是法向量，垂直于a和b构成的平面、

          ![b3bdd099721c4402997b2e868ca08cdc](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\b3bdd099721c4402997b2e868ca08cdc.png)

       3. 叉乘的作用：计算法向量、计算旋转轴、计算表面法线

       4. 点乘的作用：计算投影、计算角度、计算向量正交

       5. 区别：

          1. **性质不同：** 叉乘的结果是一个新的向量，而点乘的结果是一个标量（数量）。
          2. **方向不同：** 叉乘的结果垂直于原始向量所在的平面，而点乘的结果表示了两个向量之间的相似性和关系。
          3. **单位不同：** 叉乘的结果的大小是根据平行四边形面积计算的，而点乘的结果是向量在某个方向上的投影。

       6. 矩阵的应用：

          1. 空间变换、坐标变换、投影、物体变换、计算光照阴影、构建相机视图等

   24. Unity中如何做性能分析，提供了哪些工具。

       1. 不是很清楚

   25. gameplay里比较感兴趣哪些方向。

       1. 3C（角色、相机、控制）

   26. vector底层实现了解吗？vector底层怎么优化？扩容机制是怎样的？

       1. 定义了三个指针，start/finish/end_of_storage，调用reserve函数开辟空间来存放新的元素，将原有空间的数据移动到新空间上，释放原有空间，将三个指针重置
       2. insert的实现原理：从最后一个元素开始向后移动，如果指向的位置和插入的位置相同，停止移动，改为用户指定元素、
       3. 使用了动态内存分配来存储元素，初始的时候它会分配一个较小的内存块，并随着元素数量的增加动态扩展内存。（元素在内存中是连续存储的，有助于提高访问效率）
       4. 为了避免频繁的内存分配和释放，通常会在需要扩容的时候一次性分配更多的内存，而不仅仅是添加一个元素所需的内存。
       5. 底层优化：
          1. 连续内存存储：元素在内存中是连续存储的，有助于CPU读取内存块
          2. 预分配：可以预先给vector分配一块较大的内存空间
          3. 指数倍增扩容：当需要扩容的时候会以指数倍增扩容（一般是两倍，有可能是1.5倍）
       6. 扩容机制：capacity永远大于等于size

   27. 红黑树，如何保持红黑树的这些特性，有哪些特性？

       1. 特性：
          1. 节点颜色要么是黑要么是红
          2. 根节点是黑色
          3. 叶子节点是黑色
          4. 不能有两个相连的红色节点
          5. 从任意节点到其每个叶子的路径都包含相同数量的黑色节点
       2. 如何保持：
          1. 插入和删除后，通过旋转和颜色调整来保持这些特性。

   28. 介绍一下哈希表，常用的哈希函数，怎么解决冲突，unordered_map怎么扩容

       1. 哈希表是用来实现键-值对的存储和查找的，它基于哈希函数将键映射到数组中的索引，从而实现快速的查找操作。
       2. 常见的哈希函数：
          1. 除法散列法
          2. 乘法散列法
          3. 散列函数组合
       3. 怎么解决冲突
          1. 链表法
          2. 开放寻址法
       4. 怎么扩容？
          1. 当元素的数量达到负载因子的时候，会触发扩容操作
          2. **创建新表：** 创建一个新的更大的哈希表，通常是原来大小的两倍，并初始化为空。
          3. **重新哈希：** 将原表中的每个键值对重新插入到新表中，根据新表的哈希函数重新计算索引。
          4. **释放旧表：** 释放原来的哈希表的内存。

   29. 重载运算符

       1. .和：不能被重载
       2. ？

   30. 编译原理（我不懂啊）

   31. 操作系统（进程线程相关）

   32. 进程间通信方式，具体介绍Linux创建一个管道函数，参数设置，共享内存怎么做

       1. 管道和共享内存
       2. pipe函数
          1. int pipe(int pipefd[2]);
          2. 0为管道读端，1为管道写端
       3. shmget函数创建一个共享内存段
          1. key：用于识别共享内存的键值
          2. size：共享内存的大小
          3. shmflg：标志位，指定内存段的权限和行为

   33. 给一个虚拟地址，具体怎么寻址，介绍页式，段页式

       1. 将虚拟地址分解为页号和页内偏移

       2. 使用页号查找页表，找到对应的页帧号

       3. 将页帧号和页内偏移组合成物理地址

       4. 页式：

          1. 页式内存管理是一种常见的虚拟内存管理机制。它将虚拟地址分割成固定大小的块，称为页。物理内存也被划分成相同大小的块，称为页帧。虚拟地址通过页表来映射到物理地址。

          页式内存管理的优点是：

          - 分割了虚拟地址和物理地址的空间，提供了更高的灵活性。
          - 适用于多道程序运行环境，允许多个程序共享内存。

       5. 段页式：

          1. 段页式内存管理结合了段式和页式两种机制。在这种模式下，虚拟地址分为段号和页号两部分。每个段包含多个页，每个页包含多个页帧。

          这种方式的优点是：

          - 可以提供更好的内存保护和共享控制，因为段提供了逻辑上相关的代码和数据的划分。
          - 允许动态增长和缩减内存段的大小。

   34. 虚拟内存作用，细说

       1. 它使得应用程序认为它拥有连续的可用的内存。（实际上这些内存被分隔成了多个物理内存碎片）
       2. 分页映射
       3. 分段映射

   35. 缺页中断，分别说程序和系统层面怎么减少缺页中断

       1. 程序：
          1. 局部性原理
          2. 预读取
          3. 合并内存访问
       2. 系统：
          1. 页面置换算法
          2. 页面预调度
          3. 合理设置页面大小

   36. C++虚函数了解过吗？实现原理？

       1. 虚函数指针：为了指定对象的虚表，对象内部包含一个虚表的指针，来指向自己所使用的虚表。为了让每个包含虚表的类的对象都拥有一个虚表指针，编译器在类中添加了一个私有指针，*__vptr，用来指向虚表。这样，当类的对象在创建时便拥有了这个指针，且这个指针的值会自动被设置为指向类的虚表。

          只有拥有虚函数的类才会拥有虚函数指针，所以拥有虚函数的类的所有对象都会因为虚函数产生额外的开销，并且也会在一定程度上降低程序速度。与JAVA不同，C++将是否使用虚函数这一权利交给了开发者，所以开发者应该谨慎的使用。

       2. 虚函数表：虚函数表是一个类的虚函数的地址表，用于索引类本身以及父类的虚函数的地 址，假如子类的虚函数重写了父类的虚函数，则对应在虚函数表中会把对应的虚函数替换为子类的 虚函数的地址；虚函数表指针存在于每个对象中（通常出于效率考虑，会放在对象的开始地址处）， 它指向对象所在类的虚函数表的地址；在多继承环境下，会存在多个虚函数表指针，分别指向对应 不同基类的虚函数表。

   37. 虚函数表会在每个类对象中都存一份吗？

       1. 并不会。其实是每个类会有一个虚函数表，每个类对象有一个虚表指针，这样就可以提现多态性，具体表现为：当我的基类指针如果指向了子类对象的话，这个时候我不会因为我的指针是基类指针而调用父类的虚函数，这个基类的指针实际上指向的是子类的虚函数表，可以调用子类的虚函数。

   38. 函数重载与函数重写

       1. 重载（overloading）的意思是不同的函数使用相同的函数名，但是函数的参数个数或者类型是不同的，它在调用的时候会根据函数的参数来区别不同的函数。
       2. 重写（overriding）的意思是在派生类中对基类中的虚函数重新实现，也就是在子类的虚函数表中用子类虚函数覆盖了父类虚函数。

   39. vector与list的区别

       1. vector和数组相似，内存空间是连续的，并且地址不变；list是双向链表实现的，内存空间是不连续的

       2. vector能进行高效的存取操作，时间复杂度为O(1),list通过指针访问，时间复杂度为O(n)

       3. list的插入更快，因为list不需要进行内存块的拷贝和复制

       4. list的插入和删除很快，一般是常数开销

       5. vector适用于随机访问

       6. 1）vector底层实现是数组；list是双向 链表。

          2）vector支持随机访问，list不支持。

          3）vector是顺序内存，list不是。

          4）vector在中间节点进行插入删除会导致内存拷贝，list不会。

          5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。

          6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。

   40. 可以手动在栈上申请内存吗？

       1. 绝大部分情况不需要在栈上手动申请内存，都是编译器自动分配的
       2. 如果要申请的话可以使用alloca申请

   41. #define和typedefine？

       1. #define是C++预处理器指令之一，用于编译前将一个标识符替换为一个值或者表达式，用于定义常量和宏
       2. typedefine是C++关键字，为数据类型定义一个新的名称（别名）

   42. 给定10000个数求最大3个？

       1. 堆排序？（使用大小为3的小根堆）
       2. 利用快排的思想

   43. 快排大致原理？快排时间复杂度？快排稳定性？

       1. 找到一个基准元素，然后通过两个指针从头和从尾扫描，将需要的元素进行交换，就可以把数组分为两部分，一部分比基准小一部分比基准大，然后递归应用快排
       2. 时间复杂度O(nlog n)
       3. 快排稳定性：差，因为每次排序完后顺序可能会变

   44. 堆排了解过吗？大致原理？

       1. 基于二叉树的数据结构的排序算法。
       2. 最大堆表示父节点值大于等于其子节点，反之。
       3. **排序：** 排序的过程实际上是不断地从堆中取出根节点（最大值或最小值），将其放到已排序部分的末尾，然后重新调整堆，使其保持堆的性质。
       4. 将顶端的数与末尾的数交换，此时，末尾的数为最大值，剩余待排序数组个数为n-1
       5. 然后再把剩余n-1个数构造为大根堆，如此循环。

   45. shared_ptr了解过吗？大致说说？

       1. 是C++标准库中的一个智能指针类，用于管理动态分配的对象的生命周期。它可以自动进行引用计数，以确保不再需要对象时自动释放内存
       2. 引用计数：跟踪有多少个share_ptr指向同一个对象，当没有指针指向的时候对象内存自动释放。
       3. 避免面内存释放
       4. 是线程安全的

   46. 说说迪杰斯特拉？

       1. 迪杰斯特拉算法主要特点是从起始点开始，采用[贪心算法](https://baike.baidu.com/item/贪心算法/5411800?fromModule=lemma_inlink)的[策略](https://baike.baidu.com/item/策略/4006?fromModule=lemma_inlink)，每次遍历到始点距离最近且未访问过的顶点的邻接节点，直到扩展到终点为止。

   47. 线程与进程的区别？

       1. 进程是操作系统中的一个独立执行单元，拥有独立的内存空间和系统资源
       2. 进程之间互相隔绝
       3. 进程间通信相对复杂，需要用到管道、消息队列、共享内存等
       4. 线程是进程中的一个执行流程，多个线程可以共享同一个进程的内存空间和系统资源。
       5. 一个线程的错误可能会影响到别的线程。

   48. 多线程访问同一资源的操作？

       1. 可能会产生死锁或者饥饿
       2. 需要使用一些方法来处理：
          1. 互斥锁
          2. 读写锁
          3. 信号量**：** 信号量是一种计数器，可以控制多个线程对共享资源的访问。
          4. 死锁避免：超时机制

   49. 设计模式了解哪些，简单说说？

       1. 工厂模式
       2. 策略模式
       3. 观察者模式
       4. 适配器模式
       5. 装饰器模式
       6. 代理模式
       7. 命令模式
       8. 模板方法模式

   50. 渲染管线了解过吗？

   51. UE动画蓝图了解过吗？

   52. 游戏里里的AI一般用什么来做？

   53. 行为树有哪些比较重要的节点吗？

   54. 射击游戏中子弹发射、击中敌人扣血等机制的实现

   55. 如何获取子弹和敌人碰撞这一事件

   56. 了解过碰撞的底层实现吗？

   57. UE的反射机制？

   58. 对引擎有更多的了解吗？

   59. GAS系统使用

3. 其他问题：
   1. 一个C++项目，加载起来占用内存比较大，问怎么优化
   2. 项目比较大，怎么优化编译

4. 很抽象的一些数学题：

   1. 五局三胜，比分3:0,3:1,3:2，两只队伍实力相当，求最后比分的概率
   2. 酒鬼，30%可能出去喝酒，70%可能在家里，三家酒吧随机一家，警察在第一家酒吧没找到，求在家里的概率
   3. 01背包，100块钱有多少种组合方式
   4. C++ new了一个对象之后的内存结构？（不是代码段数据段这种）



## 四三九九

1. 预制体是用来做什么的？

   1. 是拿来重复利用资源的。可以把想要重复利用的资源做成预制体，方便我们重复利用，也方便我们在原始预制体的基础上制作变体。

2. 生命周期？FixedUpdate和Update的区别？为什么要这么分？

   1. Awake->OnEnable->Reset->Start
   2. Awake:当一个脚本实例被载入时，即场景加载时或实例化预制体时，Awake被调用，仅调用一次（Awake函数执行时并不保证所有对象都已经被加载和初始化，所以不能在其中进行与对象初始化相关的操作）
   3. OnEnable:当对象每次变为可用或者激活状态的时候该函数被调用，可多次调用。（可以使用gameObject.activeSelf来检查对象是否处于可用状态，对象如果突然可用的话可能是因为在游戏运行的时候被实例化了）
   4. Editor：编辑器模式下才会被调用的函数：
      1. Reset:用户点击检视面板的Reset或者首次添加该组件时被调用
      2. OnValidate:每次设置脚本的属性都会调用
   5. 第一次帧更新之前:
      1. Start:当一个MonoBehaviour实例被载入时，即场景加载时或实例化预制体时，Start被调用，仅调用一次，且在第一次帧更新前调用
   6. FixedUpdate和Update的区别：
      1. Update是更新，FixedUpdate是固定更新（LateUpdate是延迟更新）
      2. Update的更新频率是根据帧的刷新来执行的，也就是每帧调用一次。
      3. FixedUpdate是固定执行间隔，默认是每秒调用50次。
      4. 为什么：
         1. Update用于处理游戏对象的逻辑更新，例如用户输入、物体移动和碰撞检测（？）等操作。（如果用于处理物理模拟可能会出现闪现情况？）
         2. FixedUpdate用于处理涉及物理计算的逻辑更新（为什么：是固定时间间隔内调用的，不会受到帧率的影响，对于保持物理模拟的一致性和可预测性非常重要；用于处理单次按键可能会丢帧）（物理模拟更看重准确度）
         3. （LateUpdate用于处理相机的跟随逻辑）
         4. 最后是硬件问题，对部分较为复杂的物体渲染或者帧数较低的设备，使用FixedUpdate更为稳定。

3. MipMap是什么？优点和缺点？

   1. 多级渐远纹理
   2. **缺点：**会占用内存，因为mipmap会根据摄像机远近不同而生成对应的八个贴图，所以必然占内存！
   3. **优点：**会优化显存带宽，用来减少渲染，因为可以根据实际情况，会选择适合的贴图来渲染，距离摄像机越远，显示的贴图像素越低，反之，像素越高；当渲染引擎将一个大纹理图像缩小显示在远处或以倾斜的角度查看时，由于纹理采样的取样点不再对齐，可能会导致纹理失真或者锯齿状边缘。

4. DrawCall是什么？如何减少DrawCall？

   1. DrawCall就是CPU调用GPU图形绘制接口，用来命令GPU执行相应的绘制任务。

   2. 每次调用DC之前，CPU需要向GPU发送很多内容，包括数据、状态和命令等。在这一阶段，CPU需要完成很多工作，例如检查渲染状态等，如果DC太多CPU就会把太多时间花在提交DC上，造成CPU的过载。

   3. 采用批处理的方法，把很多小的DrawCall合成一个大的。（动态批处理和静态批处理）

   4. 还有合并网格和材质的方式

   5. > 利用批处理，CPU在RAM把多个网格合并成一个更大的网格，再发送给GPU，然后在一个Draw Call中渲染它们。但要注意的是，使用批处理合并的网格将会使用同一种渲染状态。也就是说，如果网格之间需要使用不同的渲染状态，那么就无法使用批处理技术。

5. 万格背包的实现？

   1. 

6. 热更流程？

   1. 通过网络下载资源或者代码下载到本地包。利用动态加载技术，将新的代码或者资源加载到应用程序中，以替换旧的代码或者资源。

   2. 分为几部分：代码和资源

   3. 流程：
      1. 资源或者代码打包，上传服务器

      2. 应用程序启动，与服务器版本对比，如果没有需要更新的内容，就直接启动，如果有新版本，启动下载器，下载最新的资源到本地。

      3. 使用最新版本资源和代码，进入游戏，玩家看到最新内容

7. CDN?

   1. 内容分发网络：Unity CDN（内容分发网络）是由Unity  Technologies提供的一种网络服务，用于加速Unity游戏和应用程序的内容传输。通过将游戏资源和文件存储在全球各地的服务器上，Unity CDN可以将这些内容分发给用户，使他们能够更快地下载和访问游戏。这种技术可以减少网络延迟，并提供更好的用户体验。Unity  CDN还提供了一些其他功能，如版本控制、压缩和缓存，以提高内容传输的效率。总之，Unity  CDN可以帮助开发者更好地管理和分发他们的游戏内容，提高用户的下载和访问速度。

8. UGUI最大的缺点是什么？

   1. UGUI是基于画布的UI系统，UGUI使用了Unity3D的渲染管线，通过直接渲染UI元素到屏幕上，以实现UI的显示。

   2. UGUI的特点是易用性强、功能性丰富和可扩展性高，提供了丰富的UI组件和交互功能

   3. 缺点是：性能较低（使用了Unity3D的渲染管线），自定义性较弱（相对于NGUI来说）

9. 职业规划？

10. 数据基本有序的情况下，哪种排序方式最快？为什么？

    1. 直接插入排序（？）

    2. 快速排序是最快的排序方法

    3. 对于记录多的情况下，归并排序比堆排序更快

    4. 最好情况下：直接插入排序和冒泡最快

    5. 最坏情况下：堆排序和归并排序最快

11. TCP与UDP的区别？

    1. TCP面向连接，提供可靠的服务，UDP是无连接的，即发送数据之前不需要建立连接，且不保证可靠服务。
    2. UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性具有较高要求的通信或者广播通信。
    3. TCP是一对一的，UDP支持一对一一对多多对一多对多
    4. UDP首部开销小，TCP首部开销大
    5. TCP面向字节流，实际上是把数据看成了一连串无结构的字节流，UDP是面向报文的，一次交付一个完整的报文，不可分割，报文是UDP数据报处理的最小单位
    6. UDP适合一次性传输较小数据的网络应用，如DNS,SNMP等
    7. UDP的不可靠（不会确认是第几个发出的包，不能保证不丢包）（解决这个问题可以手动模拟TCP，为数据包增加序列号，然后收到包将序列号变为确定字符，如果从确定字符发现有丢失，重新发送。）

12. 范式？

13. 宏定义与常量的区别？

    1. 类型与安全检查不同

    2. 编译器处理不同

    3. 存储方式不同

    4. 定义域不同

    5. 能否作为函数参数

14. 指针的加减操作

15. 递归与循环的区别

    1. 递归：通过重复将问题分解为子问题

    2. 递归的时间和空间消耗大（重复函数调用，重复计算）

    3. 递归是在函数内部调用函数自身

    4. 循环是用一个布尔表达式来控制计算的开始与结束

16. 面向对象的设计模式

    1. 创建型模式
       1. 单件模式
       2. 工厂方法模式
       3. 原型模式
       4. 抽象工厂模式
       5. Builder生成器模式
    2. 结构型模式
       1. 适配器模式
       2. 桥接模式
       3. 组合模式
       4. 装饰者模式
       5. 外观模式
       6. 享元模式
       7. 代理模式
    3. 行为模式
       1. 职责链模式
       2. 命令模式
       3. 解释器模式
       4. 迭代器模式
       5. 中介者模式
       6. 备忘录模式
       7. 观察者模式
       8. 状态模式
       9. 策略模式
       10. 模板方法模式
       11. 访问者模式

17. 了解的排序算法

18. 归并排序如何实现？

    1. 先把未排序的分为两部分，然后2部分分为4部分，依次分割，直到分割为一个一个数据，然后两两归并排序，使之有序。（排序的方法：两个数组取出第一个数，然后比较大小，放入）

19. 多线程

    1. 线程就是操作系统能够进行运算调度的最小单位，被包含在进程之中。
    2. 多线程是实现并发（并行）的手段，把一件事情的完整步骤拆分为多个子步骤，然后使得这多个步骤同时执行。
    3. join就是该语句所在的线程停止（如果写在main函数里就是主线程停止，然后等待指定线程执行结束）

20. 网络编程

21. Unity对象的生命周期

    1. 静态构造函数
    2. 非静态构造器
    3. Awake
    4. Start
    5. Update
    6. FixedUpdate
    7. OnGUI
    8. OnDestroy
    9. OnEnable
    10. OnDisable

22. 有没有用过协程，有没有了解过原理

    1. 是一个可以在某个地方挂起的特殊函数，并且可以重新在挂起处继续运行。（一个线程可以包含多个协程，协程是绝对串行的）
    2. 没有了解原理

23. 死锁有了解吗？

24. 操作系统的内存管理有了解吗？

25. Unity3D的协程是什么？和C#的线程有什么区别？

    1. 协程是一种特殊的函数，可以在运行过程中暂停和恢复执行。
    2. 协程是一个分部执行的，遇到条件语句会挂起，直到条件满足才会被唤醒继续去执行后面的代码
    3. 作用：
       1. 延时（等待）一段时间执行代码
       2. 等某个操作完成之后再执行后面的代码——通常用于控制运动、序列以及对象的行为（充当状态机）
       3. 总结：控制代码在特定的时机执行
    4. 线程是由操作系统调度的，而协程是由程序自身控制的
    5. 一个线程可以包含多个协程，协程是绝对串行的
    6. 协程不是线程，也不是异步执行的。协程和MonoBehaviour的Update函数一样也是在MainThread中执行的。使用协程不用考虑同步和锁的问题。



## 多乐面试

1. 自我介绍：明天在车上想
   1. 面试官你好，我是2024届的一名本科生，就读于南京大学，专业是软件工程，平时使用的编程语言是C++。我这次来面试的职位是游戏开发工程师，在平时的学习中，我就对游戏开发抱有浓厚的热情，也参加过一次GameJam，学习过一些游戏开发的知识。

2. 指针和引用的区别
   1. 首先是在定义和声明方面：
      1. 指针是一个变量，它存储了一个地址，该地址指向内存中的某个数据。指针需要使用*符号来声明和操作，使用->来访问指针所指向的对象的成员。
      2. 引用是一个别名，它引用了已经存在的变量。引用在声明的时候使用&符号
      3. 区别：
         * 指针是一个实体，引用只是一个别名
         * 引用在使用的时候无需解引用(*)，但是指针需要解引用
         * 引用在定义时被初始化一次，之后不可变，指针可变
         * 引用没有const，指针有const，const指针不可变
         * 引用不可为NULL，指针可以为空
         * sizeof(引用)得到的是所指向的对象的大小，而sizeof(指针)得到的是指针本身的大小。
         * 指针和引用的自增运算意义不同

   2. 内存方面：
      1. 指针可以通过改变指针的值来改变它所指向的数据，也可以让指针指向不同的数据，具有较大的灵活性。但是这样也可能会导致内存错误，比如空指针引用或内存泄露。
      2. 引用：引用一旦与某个变量绑定，就不能改变它引用的对象，引用在声明时必须初始化，并且不能重新绑定到其他对象，这可以避免一些潜在的内存问题

   3. 空值：
      1. 指针可以存储空指针值，表示不指向任何有效的内存位置
      2. 引用不能存储空值，它必须始终引用有效的对象。

   4. 传递参数
      1. 可以把指针作为参数传递给函数，函数可以通过指针修改原始数据
      2. 可以将引用作为参数传递给函数，函数也可以通过引用修改原始数据，引用参数通常更直观，因为不需要使用指针操作符

3. double/float/int来回强制类型转换
   1. double是双精度浮点数类型，通常用于表示带有小数点的数值，并提供了较高的精度和范围
   2. float是单精度浮点数类型，用于表示带有小数点的数值，但是精度较低，范围较小，通常需要更少的内存。（正负号+指数部分+尾数部分（隐含最高位1））
   3. int是整数类型，表示没有小数部分的整数
   4. 隐式类型转换（自动类型转换）：
      1. 非标准到标准，占用少的到占用多的，数值范围小的到大的
      2. 非标准类型的转换为标准类型（bool、char和short转换为int）
      3. int和float运算时候，将int转换为float
      4. int和long运算时候，将int转换为long
      5. int和double运算时，将int转换为double
      6. float和double转为double

   5. 显式类型转换：
      1. static_cast：被执行编译器认为是安全的转换
      2. dynamic_cast：主要用于类层次结构中的安全类型转换
      3. const_cast：用于从const或volatile类型中删除const性质
      4. reinterpret_cast：执行底层位级别的转换，通常用于处理指针和引用。
      5. 将浮点数类型转换为整数类型的时候，小数部分将被截断，而不是四舍五入。
      6. 当整数转换为浮点数类型的时候，可以在某些情况下引入精度损失。

4. 二级指针，实参和形参区别
   1. 二级指针是一个普通的变量，不过它里面保存的是另外一个一级指针的地址定义。
   2. 实参：实际参数是在函数调用时候传递给函数的值或者表达式，他们位于函数调用的括号内，并用于为函数的形参提供值。实参的值将传递给函数，函数可以使用这些值执行操作
   3. 形参：形式参数是函数定义中的参数，它们用于指定函数可以接受的参数的类型和数量。形参是在函数头部声明的，并在函数体内用于处理传递给函数的实际参数的值。形参充当了函数内部变量的角色。

5. 迭代器失效问题
   1. 序列式容器迭代器失效（vector）
      1. 对于erase操作，会返回下一个元素的迭代器，也就是后面的元素会向前面移动一个，然后循环体自加，到了下下个元素的位置。
      2. 解决方法：it = q.erase(it)；//返回下一个元素的迭代器，不需要自加了。
      3. 对于push_back()来说，如果capacity没有改变，那么之前的begin()不失效，之前的end()失效（不再是end），改变了的话说明vector重新开辟了一块内存空间来存储，这个时候之前的迭代器都失效了。

   2. 关联式容器迭代器失效（map）
      1. 对于map来说，当进行erase操作后，只会使当前迭代器失效，不会造成其他迭代器失效，这是因为map底层实现是红黑树实现的，所以只删除一个元素的话，会进行二叉树的调整，但是每个节点在内存中的地址是没有改变的，改变的只是他们之间的指针指向。

6. 使用过哪些STL容器
   1. vector：数组的一种表示，自动管理内存，动态改变长度并随着元素增减而增大或缩小
   2. deque：双端队列，可以队首和队尾插入和弹出，支持随机访问，也就是可以直接用下标来访问元素。
   3. list：双向链表，不支持数组表示法和随机访问。list强调的是元素的快速插入与删除。（序列容器都是线性排列，所以list首尾不会相连）（为什么删除快，因为list是双向链表，只需要改变前后元素的指针就行了，但是vector却需要移动大量数据）
   4. queue：队列，只能队尾插入，队首弹出，无法index遍历，也不可以迭代器遍历
   5. stack：栈，是一个适配器，给底层类（默认vector）提供典型栈接口。
   6. priority_queue?：优先队列，默认是数字大的优先级大，less是默认规则

7. C++多态
   1. 多态是指同一种行为对应不同的实现，即同名的函数有不同的实现。多态是实现“一种接口，多种方法”的技术。
   2. 在面向对象程序设计中，多态体现在：不同类的对象接收到同一个消息时候会执行不同的动作。
   3. 实现：虚函数
   4. 类中声明虚函数时候，编译器会自动在类中生成一个虚函数表，类的对象有一个指向虚表开始的虚指针，虚表和类对应，虚表指针和对象对应。
   5. 虚函数表是一个存储类成员函数指针的数据结构。
   6. virtual成员函数会被编译器放入虚函数表中。
   7. 当存在虚函数时候，每个对象中都有一个指向虚函数表的指针。
   8. 子类复制、重写、添加虚函数表
   9. 虚函数表放在了全局数据段

8. 举一个使用多态的例子
   1. 动物基类，虚函数为eat，猫子类，重写eat函数
   2. 动物指针指向猫对象，调用eat函数，使用的是猫的eat函数。

9. Linux指令说几个
   1. ls：列出当前目录中的文件和子目录
   2. pwd：显示当前工作目录的完整路径
   3. whoami：显示当前登录用户的用户名
   4. cd：切换当前工作目录
   5. touch：创建空文件或者更新文件的时间戳
   6. mkdir：创建一个新的目录
   7. rmdir：删除空目录
   8. rm：删除文件或目录
   9. cp：复制文件或目录
   10. mv：移动文件或目录
   11. cat：连接文件并显示文件目录，也可以用于创建和编辑文件
   12. more和less：逐页显示文件内容
   13. find：在文件系统中查找文件和目录
   14. ps：显示当前运行的进程列表
   15. kiss：终止运行中的进程
   16. chmod：修改文件或目录的文件
   17. chown：修改文件或目录的所有者
   18. tar:打包或解压文件
   19. ln：用于创建链接，主要创建硬链接和符号链接（软链接），允许在文件系统中创建指向其他文件或者目录的链接
       1. ls -s 创建软链接（ln -s /path/to/source /path/to/symlink）（可以链接到文件或目录，允许链接到不存在的文件或目录）(以路径形式存在)
       2. 不带-s默认创建硬链接（ln file1 file2——创建名为file2的硬链接，实际上是file1的别名，修改其中一个文件将同时反映在另一个文件上）（只能链接到文件而不是目录，不允许链接到不存在的）（以文件副本形式存在）
       3. 硬链接认为一个文件拥有两个文件名，软链接则是系统新建一个链接文件，此文件指向所要指的文件

   20. echo:将字符串显示到标准输出也就是屏幕上（可以通过重定向写入文件中，没有文件创见文件）

10. ln命令知道吗
    1. 同上

11. TCP和UDP的区别
    1. TCP/IP模型：应用层（FTP/HTTP/SMTP/DNS【TCP】、DNS/TFTP【UDP】）、传输层（TCP/UDP）、网络层（IP）、网络接口层（Internet/LAN/LANs/WANs）
    2. 两者都是传输层的
    3. TCP是面向连接的，UDP是面向无连接的
    4. TCP是可靠的，UDP是不可靠的
    5. TCP是面向字节流的，UDP是面向报文的
    6. TCP只有一对一，UDP都可以
    7. UDP头部开销小，TCP头部开销大
    8. TCP会产生粘包问题，UDP会产生丢包问题

12. TCP的三次握手和四次挥手
    1. 三次握手：（本质是确定双方接受和发送数据的能力）
       1. 客户端发送请求（SYN）（SYN + seq）
       2. 服务端收到请求，将序列号+1，然后作为ACK返回，此时回复（SYN+ACK + seq + ack）
       3. 客户端接收到服务端回复，进入确定状态，再回复一个ACK，服务端收到进入确定状态（ACK + seq + ack）

    2. 四次挥手：（目的是关闭一个连接）
       1. 客户发送一个请求（FIN = 1,seq = u），进入等待响应阶段
       2. 服务端返回包（ACK = 1,seq = v,ack = u + 1），进入关闭等待阶段
       3. 服务端发送包（FIN = 1，ACK = 1,seq = w，ack = u + 1）
       4. 客户端返回包（ACK = 1,seq = u + 1，ack = w + 1）

    3. 为什么连接时候要三次？
       1. 因为需要考虑连接时丢包的问题，如果只握手2次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数(可以理解服务端已经连接成功)据，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认ack报文丢失，服务端在一段时间内没有收到确认ack报文的话就会重新进行第二次握手，也就是服务端会重发SYN报文段，客户端收到重发的报文段后会再次给服务端发送确认ack报文。

    4. 为什么关闭要4次？
       1. 因为只有在客户端和服务端都没有数据要发送的时候才能断开TCP。而客户端发出FIN报文时只能保证客户端没有数据发了，服务端还有没有数据发客户端是不知道的。而服务端收到客户端的FIN报文后只能先回复客户端一个确认报文来告诉客户端我服务端已经收到你的FIN报文了，但我服务端还有一些数据没发完，等这些数据发完了服务端才能给客户端发FIN报文(所以不能一次性将确认报文和FIN报文发给客户端，就是这里多出来了一次)。

    5. **为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？**
       1. 这里同样是要考虑丢包的问题，如果第四次挥手的报文丢失，服务端没收到确认ack报文就会重发第三次挥手的报文，这样报文一去一回最长时间就是2MSL，所以需要等这么长时间来确认服务端确实已经收到了。

13. Innodb索引结构是什么
    1. B+树（TODO）

14. 事务的特性和原理
    1. 原子性（不可分割，要么全做要么全不做）、一致性（执行前后都必须是一致性）、持久性（一旦事务被提交了对数据的改变是永久性的）、隔离性（一个事务的执行不能被其他干扰，多个并发事务互相隔离）
    2. 原理：
       1. 原子性：回滚日志来保证原子性操作
       2. 一致性：数据库无法保证一致性，需要业务代码来保证
       3. 持久性：redo log（归档日志来保证），先把记录写到redo log上，然后更新内存，防止宕机
       4. 隔离性：利用了锁和MVCC（锁是悲观锁，MVCC是一种乐观锁的方式，也就是每次操作不加锁，对比版本号或者其他标志，如果过程中没有被修改就提交）

15. 事务操作有什么指令？
    1. START TRANSACTION：开始一个新的事务
    2. COMMIT：提交事务
    3. ROLLBACK：回滚事务
    4. SAVEPOINT：创建保存点
    5. RELEASE SAVEPOINT：释放保存点

16. select for update
    1. 排他锁，写锁，一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。
    2. 作用：保证数据的一致性，为了在查询时,避免其他用户对该表进行插入,修改或删除等操作,造成表数据的不一致性。

17. 两个进程同时查一个表，一个select for update，一个没有，会有什么问题
    1. update会对表进行加锁，另一个进程无法访问这个表，直到释放锁
    2. 保证了数据的正确性和一致性
    3. 只有一个应该不会死锁？
    4. 对于InnoDB引擎来说，性能会下降

18. Redis常用数据结构
    1. string
    2. hash
    3. list
    4. set
    5. sorted set

19. 有序集合的应用场景
    1. 带有权重的元素，比如一个游戏的用户得分排行榜

20. Redis集群的原理
21. 切片集群怎么做到数据分布均匀
22. gdb怎么用的，调试core文件的原理是啥？
23. vim用得多吗？都会什么指令
    1. :w：保存文件
    2. :wq：保存并退出
    3. :q：退出
    4. :q!：强制退出不保存
    5. i：在当前位置插入文本
    6. x：删除当前光标所在位置的字符

24. 序列化模块效率为什么这么高
25. 100倍是怎么得出来的
26. this指针
27. 代码，内部类相关
    1. 内部类可以直接访问外部类中的static、枚举成员，不需要外部类的对象或者类名，但不能直接访问外部类的成员函数（因为内部类是一个独立的类，不属于外部类，所以此时还没有外部类的对象也不存在成员变量）

28. SIGPIPE（管道）
    1. 用于进程间通信的机制，允许一个进程的输出直接成为另一个进程的输入

29. 什么是可中断函数，什么是可重入函数，他们有啥区别
    1. 可中断函数：执行期间可以被外部事件或信号中断，并且在中断后继续执行
    2. 可重入函数：在同一时间内可以安全地被多个线程或任务并发调用而不会导致不正确的结果或数据损坏

30. 使用Redis设计一个秒杀的缓存系统
31. TCP如何判断链接是否断开
    1. 错误码和数据信号
    2. 定时发送alive包
    3. 检测是否超时

32. 想在目录中创建一个文件，需要什么权限
    1. 需要写权限
    1. chmod +w file_name

33. 要求用迭代器删除空格
34. topK问题
    1. 建堆
       1. 用数据集合中前K个元素来建堆
       2. 用剩余的元素和堆顶比较，不满足则替换堆顶元素
       3. O（K + logK*(N-K)）

    2. 随机选择算法
       1. 随机选择+分治



TP：

1. 构造函数，析构函数作用

   1. 构造函数：在对象创建的时候系统自动调用构造函数，初始化对象的成员变量

   2. 析构函数：在对象生存期结束后，系统自动调用的成员函数，调用析构函数释放内存，执行对象的清理工作

2. free会有什么隐患

   1. free释放了对象的内存，但是不调用个对象的析构函数，所以如果在对象中使用new分配的内存就会泄露
   2. 尝试多次释放同一块内存可能会导致程序崩溃
   3. 释放内存后没有把指针置为nullptr的话会产生野指针，访问会导致未定义行为，程序崩溃

3. 进程间通信方式

   1. 管道、消息队列、共享内存、信号量、信号、socket

   2. 每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但是内核空间是每个进程都共享的，所以进程之间通信必须通过内核

   3. 不同的进程间通信的机制：

      1. 管道：

         * |一个竖线就是一个管道
         * 它的功能是将前一个命令的输出作为后一个命令的输入
         * 可以看出管道传输数据是单向的，如果想要相互通信，我们需要创建两个管道
         * 另外，这种管道没有名字，我们称之为匿名管道
         * 管道还有一种类型是命名管道，也被叫做FIFO，因为数据是先进先出的传输方式
         * 使用方式：
           * 在使用命名管道前，先需要通过mkfifo命令来创建并且指定管道名字mkfifo myPipe
           * 这个文件的类型是p，也就是管道的意思
           * echo "hello" > myPipe。我们向管道写入数据，发现命令执行后停住了，因为管道里的内容没有被读取，只有管道里的数据被读完后，命令才可以正常退出
           * 于是执行另外一个命令来读取这个管道里的数据：cat < myPipe
         * 管道这种通信方式效率低，不适合进程间频繁地交换数据（好处，简单）
         * 管道就是内核里面的一串缓存，从管道的一端写入的数据，实际上是缓存在内核中的
         * 想要跨进程通信，fork一个子进程，抱有父进程的文件描述符，让父子进程互相沟通
         * 而在shell里，A进程和B进程都是shell的子进程，可以用一个匿名管道连接起来
         * 这是匿名管道，需要有存在父子关系的进程，而命名管道可以提前创建管道，在进程中使用即可，所以可以在不相干的进程间相互通信。

      2. 消息队列

         * A进程给B进程发消息，A进程把数据放在对应的消息队列后正常返回，B需要时候读取数据。

         * 消息对立是保存在内核中的消息链表

         * 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。

         * 消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。

           但邮件的通信方式存在不足的地方有两点，**一是通信不及时，二是附件也有大小限制**，这同样也是消息队列通信不足的点。

         * **消息队列不适合比较大数据的传输**

         * **消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

      3. 共享内存

         * **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。
         * 不会发生用户态与内核态的消息拷贝过程

      4. 信号量

         * 用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。

         * 为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，**信号量**就实现了这一保护机制。

           **信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

         * 信号量表示资源的数量，控制信号量的方式有两种原子操作：

           - 一个是 **P 操作**，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
           - 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

         * 另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。

      5. 信号

         * 上面说的进程间通信，都是常规状态下的工作模式。**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

         * 在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 `kill -l` 命令，查看所有的信号：

         * 运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如

           - Ctrl+C 产生 `SIGINT` 信号，表示终止该进程；
           - Ctrl+Z 产生 `SIGTSTP` 信号，表示停止该进程，但还未结束；

           如果进程在后台运行，可以通过 `kill` 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：

           - kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程；

           所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。

         * 信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。

           **1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。

           **2.捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。

           **3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程

      6. socket

         * 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想**跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。**
         * 创建socket的系统调用：
         
           ```c
           int socket(int domain, int type, int protocal)
           ```
         * domain指定协议族，type指定通信特性（字节流，数据包等），protocal指定通信协议，0即可。

4. 管道和socket的区别

   1. 管道是半双工的，管道只能在具有公共祖先的进程间使用（但是所有用户进程都有共同祖先init）
   1. socket有两个缓冲区，一个读缓冲区一个写缓冲区，当数据的发送速度非常快接受方处理速度跟不上时，读缓冲区会溢出导致丢包
   1. 管道的读端和写端共用一个缓冲区，发送方将会被堵塞，不会发生缓冲区溢出丢包问题。
   1. 管道的使用更简单一些，socket会更复杂
   1. socket可以跨网络和不同主机的进程间通信，管道是同一台主机上进行进程间通信

5. 循环打印abc的线程设计

   1. 创建一个全局互斥锁，一个全局条件变量，一个标志位，标志位初始值为0

   2. 在主线程中创建三个线程，并将打印A、B、C的函数赋给线程。

   3. 三个线程都调用join，阻塞主线程，等到三个线程都执行完毕了才结束主线程。

   4. 每个函数方面：

      1. 使用unique_lock来锁定互斥锁
      2. 如果全局标志位不为自己所属的标志位则阻塞当前线程，wait
      3. 等到后打印所属的字母
      4. 设置新的标志位
      5. 唤醒所有等待的进程

   5. ```C++
      #include<bits/stdc++.h>
      using namespace std;
      
      std::mutex mtx;
      std::condition_variable cv;
      
      char arr[] = {'a', 'b', 'c'};
      char message = 'a';
      
      void test(int i){
          for (int j = 0; j < 10; ++j) {
              std::unique_lock<std::mutex> lk(mtx);
              cv.wait(lk, [=]{ return message == arr[i];});
              std::cout << arr[i];
              message = arr[(i + 1) % 3];
              lk.unlock();
              cv.notify_all();
          }
      }
      
      int main(int argc, char **argv)
      {
          std::thread t[3];
          for (int i = 0; i < 3; ++i) {
              t[i] = std::thread(test, i);
          }
      
          for (int i = 0; i < 3; ++i) {
              t[i].join();
          }
      }
      
      ```

      

6. 从(n)一百万个数中选最大的(m)100个

   1. 快排思想：O()

   2. 取出前100个数，维护一个100个数的最小堆:O(Nlogm)

7. TCP和UDP区别

   1. TCP是面向连接的，UDP是面向无连接的
   2. UDP是不可靠传输，TCP是可靠传输
   3. UDP是面向报文，TCP是面向字节流
   4. UDP头部开销小，TCP头部开销大
   5. TCP一对一，UDP都可以

8. UDP如果要实现可靠运输，可以怎么做

   1. ACK机制，当接受方收到数据时候，回复ACK进行确认，收不到ack包就重发，每个包有递增的序号，当接收方发现中间丢了包就发重传请求
   2. 重传机制
   3. 发送包被每个包加上序号，让接收方收到包后方便重排
   4. 窗口机制，根据网络传输情况来调整。

9. 常见的STL

   1. vector
   2. list
   3. set
   4. 队列
   5. 双端队列
   6. 优先队列

10. vector是怎么实现的

    1. vector是一个动态数组，用于维护一段连续的动态控件，内部有三个成员变量，用来存储起始位置，已使用位置，以及最后位置，每当动态内存用完后，按照原来内存的两倍，重新申请新内存。拷贝到新内存，释放掉原内存。

11. 数据链路层的协议有哪些

    1. OSI协议：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层
    2. 以太网Ethernet：
    3. 无线局域网：
    4. PPP：点对点
    5. HDLC：高级数据链路控制协议，常用于广域网的数据传输
    6. LAPB：平衡链路访问过程

12. 用户态和内核态

    1. 用户态和内核态是操作系统的两种运行状态
       1. 内核态：处于内核态的CPU可以访问任意的数据，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。
       2. 用户态：处于用户态的 CPU 只能访问受限资源，不能直接访问内存等硬件设备，不能直接访问内存等硬件设备，必须通过「系统调用」陷入到内核中，才能访问这些特权资源。
    2. 为什么：有一些指令是非常危险的，所以要设置特权，只让操作系统本身以及相关模块调用较为危险的指令
    3. 什么时候从用户态陷入内核态：
       1. 系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作
       2. 异常：触发由当前运行进程切换到处理此异常的内核相关程序中
       3. 外围设备的中断：外围设备完成用户请求的操作后，向CPU发出相应的中断信号，这个时候CPU回去执行与中断信号对应的处理程序，就发生了用户态到内核态的转变。

13. malloc的底层实现

    1. 本身是C库里的函数，用于动态分配内存，分配内存是向操作系统请求实现的
    2. 方式一：brk()系统调用从堆分配内存(将堆顶指针向高地址移动，获得新的内存空间)
    3. 方式二：通过mmap系统调用在文件映射区域分配内存
    4. 分配的内存小于128KB，使用brk，否则mmap
    5. 分配虚拟内存
    6. 使用内存池来管理已经分配的内存空间，释放后不立即返回操作系统，而是放入内存池

14. 哈希表的实现

    1. 通过一个算法函数将关键码值转换为一个整型数字，也就是数组的下标。
    2. 将value存储在以该数字为下标的数字空间里
    3. 链地址法：
       1. 数组中的每个元素指向一条链表，每个结点都存储了散列值为该元素的索引的键值对。
    4. 开放地址法：发生冲突继续探测其他存储单元，直到找到空位置

15. 死锁

    1. 两个线程为了保护不同的共享资源而使用了两个互斥锁，应用不当时可能会导致两个线程都在等待对面释放锁，一直互相等待发生死锁。
    2. 避免：使用资源有序分配法（也就是让两个不同的线程优先先获取同样的共享资源，这样的话如果产生冲突，会优先给其中一个线程）

16. TCP建立连接断开连接

    1. 三次握手
    2. 四次挥手

17. 如何排查建立不了连接

    1. 看三次握手有哪里出现了问题
    1. 三次握手无法建立，客户端发出的SYN包没有任何响应，返回TIMEOUT错误，可能是对应的服务器IP写错
    1. 客户端收到了RST复位回答，可能是请求端口写错
    1. SYN包引起了destination unreachable，可能是客户端和服务端路由不通

18. 内存溢出和内存泄露

    1. 内存溢出是因为程序申请的内存超出了系统能够提供的范围
    2. 内存泄露是程序在申请内存后无法释放已申请的内存空间，内存没有被回收
    3. 内存泄露可能的原因：
       1. 析构函数未正确地释放内存
       2. 基类的析构函数没有设为虚函数
       3. 循环引用
       4. 动态分配内存后未释放

19. 无法释放指的是什么？

    1. 内存泄露

20. 登录百度网站，会涉及哪些网络协议？

    1. HTTP
    2. DNS
    3. TCP/IP
    4. SSL/TLS

21. 操作系统内核态用户态分别是干嘛的？什么时候用哪个态？为什么要分成用户态和内核态？

    1. 用户态：不能直接使用系统资源，也不能改变 CPU 的工作状态，并且只能访问这个用户程序自己的存储空间！
    2. 内核态：系统中既有操作系统的程序，也有普通用户程序。为了安全性和稳定性，操作系统的程序不能随便访问，这就是内核态。即需要执行操作系统的程序就必须转换到内核态才能执行内核态可以使用计算机所有的硬件资源
    3. 当在运行用户程序进程的时候用用户态，遇到需要高特权的操作时候转换到内核态
    4. 系统调用、异常、外围设备的中断
    5. 在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。如果所有的程序都能使用这些指令，那么你的系统一天死机N回就不足为奇了。
       所以，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。
       如此设计的本质意义是进行权限保护。 限定用户的程序不能乱搞操作系统，如果人人都可以任意读写任意地址空间软件管理便会乱套.

22. 进程在什么时候会被调度

    1. 当前运行的进程主动放弃：
       1. 当一个进程正常的执行完了，进程主动终止结束，在这个时候会触发进程调用，因为需要从就绪队列中再选择一个进程分配给 CPU 去执行。
       2. 当程序在运行过程当中，程序发生了异常，从而导致终止。虽然这里是程序发生了异常，但还是属于程序主动放弃。
       3. 当进程主动请求了某些资源，但是资源被其他进程占用了，所以进程会进入阻塞状态等待资源释放，在这个阻塞期间是需要释放 CPU 资源的，不能一直占用 CPU 不干活。
    2. 当前运行的进程被动放弃：
       1. 当前执行的进程的[时间片](https://so.csdn.net/so/search?q=时间片&spm=1001.2101.3001.7020)用完了，被迫放弃 CPU 执行权，进程调度重新选择进程分配 CPU 。
       2. 当前进程在执行的过程中，检测到了中断信息，在这个时候有优先处理中断信息的，所以也是被迫下 CPU。
       3. 有更高优先级的进程进入就绪队列，调度器会优先让优先级更高的进程优先执行。

23. 进程调度的过程中发生了什么事情

    1. 状态的改变吧
    2. 运行态->等待态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。
    3. 等待态->就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。
    4. 运行态->就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。
    5. 就绪态->运行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态

24. 操作系统学过吗，掌握得怎么样

25. 霍夫曼编码知道吗？

    1. 知道
    2. 每次取出权值最低的两个结点（可以是二叉树），组装成二叉树，新的权值是前面的和

26. 数据结构学过吗？

27. 快排（说了双指针做法，面试官说不对）

    1. 

28. 快排的时间复杂度

    1. O（nlogn）

29. 中继器在哪一层？

    1. 物理层

30. osi七层模型是什么？还有tcp五层模型

    1. OSI七层模型：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层
    2. TCP五层模型：应用层、传输层、网络层、数据链路层和物理层

31. 路由器在哪一层？

    1. 网络层
    2. 路由器并维护路由表和交换表

32. 交换机的作用是什么？

    1. 在数据链路层工作
    2. 执行两个基本操作：
       1. 切换数据帧：在输入介质中接受帧，然后将其传输到输出介质
       2. 维护交换操作：建立和维护交换表并搜索循环
    3. 通过减少流量来缓解以太网LAN拥塞
       1. 创建专用的网段或者点对点连接，将这些网段连接到交换机的虚拟网络中
    4. 局域网交换机减少冲突域的大小
    5. 交换机连接的是一个局域网。路由器连接的是不同局域网

33. 进程调度的算法

    1. 先来先服务FCFS调度算法
    2. 优先级调度算法
    3. 时间片轮转调度算法
    4. 短进程优先调度算法SPF
    5. 最短剩余时间优先调度算法
    6. 最高响应比优先调度算法
    7. 多级反馈队列调度算法

34. 选择排序说一下

    1. 在未排序序列中找到最小或最大元素，放到起始位置，然后继续，以此类推。

35. 希尔排序怎么实现

    1. 将待排序的数据分成若干个子序列，对每个子序列进行插入排序，从而实现对整个序列的排序。
    2. 核心在于定义一个增量序列，将待排序的数据分成若干个子序列。
    3. https://blog.csdn.net/m0_61789994/article/details/131231872

36. 堆排怎么实现

    1. 建立初始堆：将无序序列构造成第 `1` 个[大顶堆](https://so.csdn.net/so/search?q=大顶堆&spm=1001.2101.3001.7020)（初始堆），使得 `n` 个元素的最大值处于序列的第 `1` 个位置。
    2. 调整堆：交换序列的第 `1` 个元素（最大值元素）与第 `n` 个元素的位置。将序列前 `n - 1` 个元素组成的子序列调整成一个新的大顶堆，使得 `n - 1` 个元素的最大值处于序列第 `1` 个位置，从而得到第 `2` 个最大值元素。
    3. 依次类推，不断交换子序列的第 `1` 个元素（最大值元素）与当前子序列最后一个元素位置，并将其调整成新的大顶堆。直到子序列剩下一个元素时，排序结束。此时整个序列就变成了一个有序序列。

37. hashset和hashmap的区别

    1. 存储方式不同：映射表和集合
    2. set存储值，map存储键值对
    3. map键唯一，值可以重复
    4. set元素唯一的
    5. map可以通过键来访问，set只能迭代

38. 分什么时候用hashmap和hashset

    1. map适用于存储键值对的情况，set适用于存储唯一数据去重的情况

39. 反射的原理

40. 排序方法中最坏情况下比较次数最少的是：![3fc72e486143d7d45be3b55c7da75f0f832b5069](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\3fc72e486143d7d45be3b55c7da75f0f832b5069.webp)

41. static：

    1. 静态局部变量：在局部变量前面加上static关键字，即为静态局部变量。用于函数体的内部修饰变量。
       1. 静态局部变量也存储在数据区，程序执行之前已经分配好内存，程序执行结束后才销毁。
       2. 静态局部变量只在首次执行到声明处初始化一次，之后再执行该语句时不在初始化，若没有初始化则编译器会将其初始化为0
       3. 其作用域与局部变量的作用域一样，从定义处到所处语句块结束
    2. 静态全局变量：在全局变量前面加上static关键字，即为静态全局变量。静态全局变量在程序的数据区分配内存，如果没有初始化默认初始化为0，直到程序结束后销毁。
       1. 静态全局变量在该文件内可见，从变量定义处开始直到文件结束(普通全局变量在同一程序的其他文件中可见，默认是 external 属性，而静态全局变量是 internal 属性)， 而在其他文件中不可见
    3. 静态函数：在普通函数的返回类型前加上static关键字，即为静态函数。
       1. 只能在本文件中使用。
    4. 静态数据成员：对于类静态数据成员，无论有多少个该类的对象，该静态数据成员在内存中只有一份拷贝(其他普通数据成员，每个类对象都有自己的内存拷贝)，该静态数据成员由所有该类对象共享。静态数据成员不能再类中定义和初始化，只能在类中声明，在类外进行定义和初始化，默认初始化为0
    5. 静态成员函数：
       1. 静态成员函数只能访问静态数据成员和静态成员函数，普通的都可以。
       2. 静态成员函数没有this指针。
       3. 静态成员函数属于类，不属于类对象

42. 内联函数和宏

    1. 内联函数：
       1. 以inline修饰的函数就叫做内联函数，C++编译器在编译时会在调用内联函数时地方展开，**没有函数压栈的开销**，内联函数提升程序的运行效率。

       2. 内联函数在调用时不是像一般函数那样要转去执行被调用函数的函数体，执行完成后在转回调用函数中，执行其后的语句；而是在调用处 **用内联函数体 的代码来替换**，以这样的方式节省函数调用的开销，提高运行效率。

       3. 内联函数必须是和函数体声明在一起才有效。不建议将声明和定义分离，**分离会导致链接错误**。因为inline被展开，就没有函数地址了，链接就会找不到。

    2. 宏：`#define`命令是C++中的宏定义，它用来将一个标识符定义为一个字符串，该标识符被称为宏名，被定义的字符串称为替换文本。
       1. 只是单纯替换文本
    3. 区别：宏是由预处理器对宏进行替换的，而内联函数是通过编译器控制实现的，宏是在预处理阶段进行替换，内联函数是在编译阶展开的。而且内联函数是真正的函数，只是在需要用到的时候内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销。所以可以像调用函数一样来调用内联函数，而不必担心会产生像宏出现的问题。
       1. **参数类型安全性：** 内联函数比宏定义更加类型安全。内联函数会对参数进行类型检查，而宏定义不会。这意味着，使用内联函数可以避免一些潜在的类型错误。
       2. **编译器优化：** 内联函数是在编译期间展开的，因此它可以进行更多的编译器优化。而宏定义则是在预处理器展开，不能进行编译器优化。因此，使用内联函数通常可以获得更好的性能。
       3. **调试：** 内联函数比宏定义更容易进行调试。因为内联函数是实际函数的一份副本，可以通过调试器跟踪到内联函数的执行过程。而宏定义则无法通过调试器进行调试。
       4. **名称空间：** 内联函数位于名称空间中，而宏定义不属于任何名称空间。这意味着，内联函数可以避免名称冲突问题，而宏定义可能会导致名称冲突。
       5. **大小和可读性：** 内联函数比宏定义更易于阅读和维护。宏定义的代码通常比较冗长，而内联函数则可以使用常规的C++语法编写，更加简洁易懂。另外，内联函数可以利用C++的函数重载和模板等特性，提高代码的可读性和可维护性。

43. TCP的拥塞控制：

    1. 拥塞控制就是防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载。**拥塞控制是一个全局性的过程，和流量控制不同，流量控制指点对点通信量的控制。**
    2. **拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。
    3. 发送窗口=min（接收窗口，拥塞窗口）
    4. 只要网络中没有出现拥塞，`cwnd` 就会增大；
    5. 但网络中出现了拥塞，`cwnd` 就减少；
    6. 其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**
    7. 四个算法：
       1. 慢启动：每当发送方收到一个ACK，拥塞窗口的大小就加一（一个叫慢启动门限  `ssthresh` （slow start threshold）状态变量，当拥塞窗口小于它时候，慢启动，不然的话拥塞避免）
       2. 拥塞避免：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**变为线性增长（比如,原窗口为8，收到8个ack，增长1）
       3. 拥塞发生：当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：
          1. 超时重传：ssthresh设为cwnd/2，cwnd重置为初始值，然后偶开始慢启动（会造成网络卡顿）
          2. 快速重传：还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。cwnd = cwnd/2，ssthresh = cwnd，进入快速恢复算法
       4. 快速恢复：快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。
          1. 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
          2. 重传丢失的数据包；
          3. 如果再收到重复的 ACK，那么 cwnd 增加 1；
          4. 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated  ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；
          5. 解释：
             1. 在快速恢复的过程中，首先 ssthresh = cwnd/2，然后 cwnd = ssthresh + 3，表示网络可能出现了阻塞，所以需要减小 cwnd 以避免，加 3 代表快速重传时已经确认接收到了 3 个重复的数据包；
             2. 随后继续重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1。加 1 代表每个收到的重复的 ACK 包，都已经离开了网络。这个过程的目的是尽快将丢失的数据包发给目标。
             3. 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，恢复过程结束。

44. TCP的滑动窗口机制

    1. 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

    2. 图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。

    3. TCP 头里有一个字段叫 `Window`，也就是窗口大小。

       **这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

    4. 发送方的窗口：已发送并确认、已发送未确认、未发送且在接收方范围内、未发送且超出范围

    5. TCP滑动窗口方案使用三个指针来跟踪四个传输类别中的每一个类别中的字节，其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

       1. `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
       2. `SND.UNA`（*Send Unacknoleged*）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
       3. `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。
       4. 指向 #4 的第一个字节是个相对指针，它需要 `SND.UNA` 指针加上 `SND.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。

    6. 接受方的滑动窗口：

       1. 三个部分：已成功接受并确认，未收到但可以接收、未收到数据并不可以接收
       2. 两个指针划分：
          1. `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
          2. `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
          3. 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。

阿里：

1. 自我介绍

2. select epoll poll的区别

   1. select、poll、epoll都是IO多路复用的机制。IO多路复用就是通过一种机制，让一个进程/线程可以监视多个描述符，一旦某个描述符就绪（一般是读写就绪），能够通知应用程序进行相应的读写操作。
   2. 与多进程/多线程技术相比，I/O多路复用技术最大的优势就是系统开销小，系统不必创建大量进程/线程，也不必维护这些进程/线程，从而大大减少了系统的开销。
   3. 运用场景：
      1. 客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。
      2. 当一个客户同时处理多个套接口时，这种情况是可能的，但很少出现。
      3. 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
      4. 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
      5. 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。
   4. select
      1. 它允许程序同时监控多个文件描述符（可以是套接字socket，也可以是普通文件）的读、写和异常事件。它使进程能够告诉内核等待多个事件中的任何一个发生，并只在有一个或多个事件发生或经历一段指定时间后才唤醒它。这样做的优点是，不需要应用程序自行检测和处理每个客户端连接的状态，可以节省大量的系统资源，提高应用程序的效率。
      2. 优点：
         1. 跨平台性
         2. 精确的超时等待时间
      3. 缺点：
         1. 文件描述符上限
         2. 性能下降：select在内核中通过轮询所有文件描述符的方式来检查其状态，当监控的文件描述符数量增多时，性能会下降。
         3. 使用复杂：select在返回时，只会告诉用户哪些描述符集合是就绪的，但并不会直接告诉用户哪一个具体的文件描述符就绪，用户需要自己去遍历这些集合，操作比较复杂。
         4. 多次数据拷贝：每次调用select都需要将文件描述符集合从用户空间拷贝到内核空间，这增加了额外的开销。
         5. 重复操作：每次select返回后，所有未就绪的文件描述符都会被移除，因此每次使用都需要重新向集合中添加描述符。
   5. poll
      1. poll函数提供了类似于select的功能，允许进程向内核指示等待多个事件中的任何一个发生，它只在有一个或多个事件发生或经历一段指定时间后才唤醒进程。不过，与select相比，poll在处理流设备时能够提供更丰富的信息。它能有效地管理多个输入/输出源，并且在特定事件发生时进行响应，这使得对多任务并发处理的支持更为高效。
      2. 优点：
         1. 无最大文件描述符限制
         2. 调用方式简单
         3. 无需重新设置文件描述符
         4. 提供了更多的事件类型
      3. 缺点：
         1. 仍需要遍历所有文件描述符
         2. 不支持文件描述符的优先级
         3. 缺乏广泛的跨平台支持
   6. epoll
      1. 区别于select和poll每次等待事件之前都需要重新设置监视的文件描述符集，epoll能复用文件描述符集来传递结果，减少了重复的准备工作。获取事件时，epoll无需像select和poll一样遍历整个被侦听的描述符集，只需遍历被内核IO事件异步唤醒并加入到就绪队列的描述符集即可。这使得处理大量文件描述符时，只有实际产生活动的文件描述符才需要被处理，从而大大提升了效率。
      2. 优点：
         1. 没有最大并发连接的限制（一般是系统的最大文件句柄数）
         2. 效率提升，不会随着FD数目增加而线性下降，只会调用活跃的
         3. 提供了更多的触发模式选择，除了LT水平触发模式，还支持ET边缘触发模式，使得用户空间程序有可能缓存IO状态，减少wait调用次数，提高应用程序效率
      3. 缺点：
         1. 只能在Linux系统运行
         2. 对于文件描述符较少的情况，使用select/poll性能并不差
         3. 使用边缘触发模式时候，需要更细心地处理各种情况，防止消息遗漏
   7. 三者的区别：
      1. ![image-20230925022017683](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\image-20230925022017683.png)

3. 哈希map的特性（和map的区别

   1. map是STL的一个关联容器，以键值对存储数据，每个关键字只能出现一次。
   2. HashMap是基于哈希表实现的，每一个元素是一个key-value对，以空间换时间。
   3. hashmap底层采用hash表存储，map一般采用红黑树实现，hashmap需要hash函数，map只需要比较函数
   4. 所以hashmap的key值是无序的，map存储是有序的
   5. map的优点在于可以自动按照Key值进行排序，查找时间复杂度是log(n)；hash_map优点在于它各项操作的平均时间复杂度接近常数，即O(1).
   6. hashmap查找速度会比map快，常数级别，而map是logn级别。
   7. 哈希表的建立比较耗时间
   8. map的空间占用率高、
   9. ![image-20230925023236430](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\image-20230925023236430.png)

4. 红黑树：

   1. 特性：
      1.  结点是红色或黑色
      2. 根结点是黑色
      3. 所有叶子都是黑色
      4. 从每个叶子到根的所有路径上不能有两个连续的红色结点
      5. 从任一结点到其每个叶子的所有路径都包含相同数目的黑色结点
   2. 自平衡的二叉树，O（logn）完成查找插入删除

5. 出现死锁的条件

   1. 互斥条件：多个线程不能同时使用同一个资源
   2. 持有并等待条件：当线程A已经持有资源1，又想申请被持有的资源2，就会处于等待状态，并且不会释放自己已经持有的资源1
   3. 不可剥夺条件：当线程已经持有了资源，在自己使用完之前不能被其他线程获取
   4. 环路等待条件：当死锁发生的时候，两个线程获取资源的顺序构成了环形链

6. 只有一个互斥量和一个线程的时候会发生死锁吗（这个有点没太理解，说了一下迭代锁和非迭代锁）

   1. mutex可以分为递归锁和非递归锁（可重入锁和不可重入锁）
   2. 同一个线程可以多次获取同一个递归锁
   3. 一个线程多次获取同一个非递归锁会产生死锁。
   4. 递归锁：在同一个线程可以多次获取同一个锁，不会产生死锁。
   5. 非递归锁：在同一个线程中，加锁后不可以再次获取该锁，如果获取可能产生死锁。
   6. linux下的pthread_mutex_t是非递归锁，但是可以通过在创建互斥量时设置PTHREAD_MUTEX_RECURSIVE属性，将pthread_mutex_t设置为递归锁。

7. 线程和进程的区别。

   1. 进程是资源（包括内存、打开的文件等）分配的单位，线程是CPU调度的单位
   2. 进程拥有一个完整的资源平台，线程只独享必不可少的资源，如寄存器和栈
   3. 线程同样具有就绪、阻塞、执行三种基本状态
   4. 线程能减少并发执行的时间和空间开销
      1. 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
      2. 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
      3. 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
      4. 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

8. 线程管理的范围（线程资源的管理范围）

   1. 创建、就绪、运行、阻塞、终止
   2. 自己独立的、私有的栈区
   3. 程序计数器、函数运行使用的寄存器组的值
   4. 每个线程用户独立的线程ID，独立的调度优先级，错误返回码
   5. 也许是：？
      1. 线程创建，线程终止，线程等待
      2. 线程的创建和销毁
      3. 线程调度和优先级

9. extern的作用，extern “C”的作用

   1. extern是c++引入的一个关键字，它可以应用于一个全局变量，函数或模板声明，说明该符号具有外部链接(external linkage)属性。也就是说，这个符号在别处定义。

   2. 三种用法：

      1. 补充：引用同一个文件中的变量、引用另一个文件中的变量（全局变量）、引用另一个文件中的函数

      2. 引用别的文件的变量时候不能重新赋值，但是声明之后可以赋值了（如果不想被赋值可以用常量）。

      3. #### 非常量全局变量的外部链接

      4. #### 常量全局变量的外部链接

      5. #### extern “C” 和extern "C++"函数声明

         1. 在C++中，当与字符串连用时，extern指明当前声明使用了其他语言的链接规范，如extern “C”，就指明使用C语言的链接规范。原因是，C++语言在编译的时候为了解决函数的多态问题，会将函数名和参数联合起来生成一个中间的函数名称，而C语言则不会，因此会造成链接时无法找到对应函数的情况，此时C函数就需要用extern “C”进行链接指定，这告诉编译器，请保持我的名称，不要给我生成用于链接的中间函数名。C和C++对函数的处理方式是不同的.extern "C"是使C++能够调用C写作的库文件的一个手段，如果要对编译器提示使用C的方式来处理函数的话，那么就要使用extern "C"来说明。如下所示：

      6. 使用extern和包含头文件来引用函数的区别

         与include相比，extern引用另一个文件的范围小，include可以引用另一个文件的全部内容。extern的引用方式比包含头文件要更简洁。extern的使用方法是直接了当的，想引用哪个函数就用extern声明哪个函数。这样做的一个明显的好处是，会加速程序的编译（确切的说是预处理）的过程，节省时间。在大型C程序编译过程中，这种差异是非常明显的。

10. 静态库和动态库的区别

    1. 静态库：在链接时把库的二进制指令赋值到调用模块中。
       动态库：也叫作共享库，会和调用者一起加载到内存，到执行调用语句时会从程序的调用位置跳转到共享库中运行。
    2. 静态库：在程序编译时候被链接到目标代码
       1. 优点：程序运行时将不再需要该静态库；运行时无需加载库，运行速度更快
       2. 缺点：静态库的代码复制到了程序中，因此体积较大；静态库更新后，程序需要重新编译链接、
    3. 动态库：在程序运行时被载入代码中
       1. 优点：执行时加载动态库，代码体积小；将一些程序升级变得简单；不同应用程序如果调用相同的库，那么内存里只需要有一份该共享库的实例。
       2. 缺点：运行时还需要动态库的存在，移植性较差。
    4. **注意：静态库的扩展名是.a，共享库的扩展名是.so，共享库要有执行权限**

11. 动态库相比静态库的优劣

    1. 静态库的优点是运行速度快，但维护麻烦，当静态库中的内容更新后需要重新编译程序，使用静态编译出的[可执行文件](https://so.csdn.net/so/search?q=可执行文件&spm=1001.2101.3001.7020)会比共享库大。
        共享库的优点是使用方便，共享库如果发生变化不需要重新编译程序，使用它编译出的可执行文件比使用静态库要小，但运行速度要比静态库慢。

12. http与https的区别

    ![6-五大类HTTP状态码](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\6-五大类HTTP状态码.webp)

    1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
    2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
    3. 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
    4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的

13. https在什么情况下不安全（这里提到了中间人攻击，当时回答的不是很了解）

    1. 中间人攻击
    2. 客户端向服务端发起HTTPS请求，被假基站转发到了一个中间人服务器，然后中间人向服务端发送HTTPS请求，这个时候客户端和中间人进行TLS握手，中间人和服务端进行TLS握手
    3. 中间人从客户端取得加密密钥A（通过发送自己伪造的证书，提醒为非法的，但是客户仍然点击），从服务端取得加密密钥B。
    4. 后续通信中，用A解密客户端发送的数据，用B加密后转发给服务端。反之。
    5. 原因：用户点击接受了中间人服务器的证书。

14. tcp和udp的区别

    1. TCP是面向连接的，传输数据前要建立连接，UDP是面向无连接的，即刻传输数据
    2. UDP是不可靠传输，最大努力交付，不保证可靠交付数据。TCP是可靠传输，数据可以无差错、不丢失、不重复、按序到达。
    3. UDP是面向报文，有边界，但是可能丢包和乱序。TCP是面向字节流，流式传输，没有边界，但是保证顺序和可靠
    4. UDP头部开销小(8字节)，TCP头部开销大（没有选项20字节）
    5. TCP一对一，UDP都可以
    6. TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
    7. 应用场景：
       1. TCP
          1. `FTP` 文件传输；
          2. HTTP / HTTPS；
       2. UDP
          1. 包总量较少的通信，如 `DNS` 、`SNMP` 等；
          2. 视频、音频等多媒体通信；
          3. 广播通信；

15. tcp和udp的哪一个会是未来更大的一个方向。

    1. UDP吧？

16. dns协议（域名解析

    1. 域名系统协议，用来将域名转换为IP地址（或者反过来）
    2. 在域名中，**越靠右**的位置表示其层级**越高**。
       1. 根 DNS 服务器
       2. 顶级域 DNS 服务器（com）
       3. 权威 DNS 服务器（server.com）
    3. 根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。
    4. 递归查询
    5. 浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 `hosts`，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下：
       1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
       2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS  会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？”  根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
       3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
       4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com  的 IP 地址吗？”
       5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
       6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
       7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
       8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

17. ARP

    1. 借助ARP请求和ARP响应确定MAC地址

18. c++右值引用，完美转发

    1. C++11新增的特性 string&&

    2. 简单来说，右值对象是指其生命周期即将结束的对象，例如一次函数调用的返回值、临时变量等。

    3. std::move()

    4. 右值引用的使用方法和传统的左值引用不同，它需要使用 std::move() 函数来将一个左值转换为右值.

    5. 需要注意的是，只能对一个右值引用或者一个将要销毁的对象调用 std::move() 函数，否则会导致潜在的内存问题和错误。此外，在使用右值引用时，需要注意数据的生命周期问题，不要在使用后再次使用已经被移动的对象。

    6. 使用场景：**右值引用的主要应用就是重载了移动构造函数，利用了将亡值，将将亡值的空间内容交换到要拷贝的对象中。减少了深拷贝。**

    7.     右值引用做函数的参数
           
               由于右值引用引用的是右值(将亡值)，当函数体里需要对该参数进行拷贝构造时，会调用移动构造。减少深拷贝。提高效率。
           
           函数传值返回，用对象接收。
           
               函数传值返回，返回一个临时对象，是一个将亡值。再用对象接收，临时对象拷贝构造对象。会调用移动拷贝构造函数，减少深拷贝。

    8. C++11有对右值进行了严格的区分：

       - 纯右值：比如常量，表达式值a+b
       - 将亡值：比如函数传值返回，表达式的中间结果。顾名思义，将亡值的空间马上就要被释放了。

    9. 右值引用：**只能引用右值，不能引用左值。但是右值引用可以引用move之后的左值。**move在后面有介绍，可以认为是改变了左值的属性，变成了右值。

    10. https://blog.csdn.net/weixin_57023347/article/details/120957689 当返回值是函数的局部对象时，当将返回值函数返回值赋给另外一个对象，都会进行深拷贝，浪费。

    11. 避免拷贝构造，改为将右值的资源换给目标。

    12. 完美转发：**所谓完美转发**， 是指在函数模板中，完全依照模板的参数类型，将参数传递给函数模板中调用的另一个函数。

    13. https://blog.csdn.net/zhizhengguan/article/details/115833949

    14. 折叠？https://gukaifeng.cn/posts/c-wan-mei-zhuan-fa/

    15. https://zhuanlan.zhihu.com/p/558517874

    16. 模板编程中，如果需要透传参数，那么需要使用完美转发。

    17. ```
        std::forward<>()
        ```

19. linux和win上编程的差异

    1. Linux可以看到源代码，windows不行
    2. Linux命令行强大
    3. 开放源码和高度可定制
    4. 去中心化
    5. Linux是基于网络的
    6. Linux区分大小写，windows在dos界面命令下不分大小写
    7. windows用扩展名区分文件，但是Linux本身没有扩展名，是用权限区分文件的。
    8. -代表普通文件
        d代表目录文件
        l代表链接文件
        b代表块设备文件
        s代表套接口文件
        p代表管道文件
        c代表字符设备文件

20. 对面向对象的编程和面向接口的编程的理解

    1. 面向对象：以一切元素的都是对象，设计时候考虑对象
       1. 重用性、灵活性和扩展性。
       2. **重用性：** 一个类里面的方法可以多次使用。
           **灵活性：** 可以表现为多态，可重复调动等特点，自由度很高，条条大路通罗马。
           **扩展性：** 多态，继承都有这个特性，可便于多样化扩展，进行抽离，降低耦合。
    2. 面向接口：接口作为实体抽象出来的一种表现形式，用于抽离内部实现进行外部沟通，最终实现内部变动而不影响外部与其他实现交互 ，可以理解成按照这种思想来设计编程的方式就可以称为面向接口编程。
       1. 不管外部的实现方式，只关注接口的实现，通过实现内部的变动而不影响外部与其他实现的交互
    3. 面向方面：AOP

21. 解释一下中断机制

    1. 在计算机中，中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

    2. 所以**中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。**

    3. 操作系统需要管理外设，但是外设的速度远远低于CPU的速度，所以我们需要一种机制来弥补这种速度鸿沟，提高CPU的效率。为此我们引入了中断机制，让外设在需要操作系统处理外设相关事件的时候，能够主动通知操作系统，即打断操作系统和应用的正常执行，让操作系统完成外设的相关处理，然后在恢复操作系统和应用的正常执行。当CPU收到中断或者异常的事件时，它会暂停执行当前的程序或任务，通过一定的机制跳转到负责处理这个信号的相关处理例程中，在完成对这个事件的处理后再跳回到刚才被打断的程序或任务中。

       为使系统能及时响应并处理发生的所有中断，系统根据引起中断事件的重要性和紧迫程度，硬件将中断源分为若干个级别，称作中断优先级。

       在实际系统中，常常遇到多个中断源同时请求中断的情况，这时CPU必须确定首先为哪一个中断源服务，以及服务的次序。解决的方法是中断优先排队，即根据中断源请求的轻重缓急，排好中断处理的优先次序即优先级( Priority )，又称优先权，先响应优先级最高的中断请求。另外，当CPU正在处理某一中断时，要能响应另一个优先级更高的中断请求，而屏蔽掉同级或较低级的中断请求，形成中断嵌套。

    4. 1.异步中断(asynchronous interrupt)，由CPU外部设备引起的外部事件如I/O中断、时钟中断、控制台中断等是异步产
       的（即产生的时刻不确定），与CPU的执行无关。也称外部中断,简称中断(interrupt)。
       2.同步中断(synchronous interrupt)，在CPU执行指令期间检测到不正常的或非法的条件(如除零错、地址访问越界)所引起的内部事件称作，也称内部中断，简称异常(exception)。

       3.陷入中断(trap interrupt)，在程序中使用请求系统服务的系统调用而引发的事件，也称软中断(soft interrupt)。

22. mysql中innodb的最大的特性

    1. **插入缓冲** 
    2. **双写机制**
    3. **自适应哈希索引**
    4. **预读** 

23. 上学期间最大的收获。 

手撕代码：

1. 手写memcpy，要考虑内存重叠的情况

   1. 如何考虑内存重叠：如果dst>src以及有src+n>dst，就需要从后向前赋值
   2. strlen？
   3. ```
      void* my_memmove(void* dst, const void* src, size_t n)
      {
          char* s_dst;
          char* s_src;
          s_dst = (char*)dst;
          s_src = (char*)src;
          if(s_dst > s_src && (s_src+n > s_dst)) {      //第二种内存覆盖的情形。
              s_dst = s_dst+n-1;
              s_src = s_src+n-1;
              while(n--) {
                  *s_dst-- = *s_src--;
              }
          }else {
              while(n--) {
                  *s_dst++ = *s_src++;
              }
          }
          return dst;
      }
      
      ```

      

2. Lc 原题，找重复出现的数，没有要求时间复杂度，可以用排序秒

   1. 把原来的数组当成一块空间来进行比较找到重复的数

   2. 可以将当前下标对应的数移动到它本该拥有的下标

   3. ```c++
      int i = 0;
              while(i < nums.size()){
                  if(nums[i] == i){
                      i++;
                      continue;
                  }
                  if(nums[nums[i]] == nums[i]) return nums[i];
                  swap(nums[i],nums[nums[i]]);
              }
              return -1;
      ```


荣耀：

1. 面向过程和面向对象的区别

   1. 面向过程：
      1. 以事件为中心，编程的时候把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步步的具体步骤中再按顺序调用函数。
      2. 以对象为中心，将现实世界中的实体抽象为对象，对象拥有自己的数据和操作（属性和行为）。建立对象的目的不是为了完成一个步骤，而是为了描述对象在整个解决问题的步骤中的属性和行为。

2. 网上学习的网站有什么？

   1. StackOverflow
   2. csdn
   3. 各种博客

3. C++ new和malloc的区别（malloc可以改变申请空间的大小是什么？）

   1. 首先，new是C++中的操作符，malloc是c中的一个函数。
   2. 对于非内部数据类型的对象而言，new不仅仅分配内存，而且会调用类的构造函数，malloc只会分配内存，不会进行初始化类成员的工作。
   3. new能自动计算所需的内存空间，而malloc需要手动计算字节数，在返回后强制转换为实际的指针类型。
   4. new成功分配内存后返回具体类型的指针，而malloc成功分配内存后返回void类型的指针。
   5. new是类型安全的，malloc不是，在进行分配空间前new会进行类型检查，malloc不会。
   6. new可以重载。
   7. 为什么不取消掉malloc？：因为C++经常调用C函数，在C函数中的动态内存管理只能使用malloc。
   8. 申请失败后new会抛出异常，malloc返回空值。

4. delete和free的区别是什么

   1. delete用于释放new分配的空间，free用于分配malloc分配的空间
   2. delete在释放空间时会调用对象的析构函数。
   3. 调用free之前需要检查释放的指针是否为空，delete则不需要（自动检查）

5. 真正释放内存是什么（实质是什么）？

   1. delete后内存并不是立即被回收，而是标记为未使用。
   2. 不知道怎么答？

6. C++内存模型（）

   1. 四大分区
      1. 代码区：存放函数体的二进制代码，由操作系统进行管理的（所有代码包含中文注释）
      2. 全局区：存放全局变量和静态变量以及常量
      3. 栈区：**由编译器自动分配释放, 存放函数的参数值,局部变量等**
      4. 堆区：**由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收** 
   2. C++语言分区
      1. 代码段
      2. 全局静态存储区
         1. 数据段（已初始化的全局变量、静态变量和常量）
         2. BSS段（未初始化的全局变量和静态变量）
      3. 堆：这个区域是由程序员来进行分配内存和释放内存用的，当我们使用malloc/free、new/delete（这是在自由存储区上分配和释放的，某种意义上来说呢，起始自由存储区是堆的一个子集）。
      4. 栈：编译器自动根据变量进行分配的，不是由程序员进行开辟的，所以编译器即会自动分配也会将其释放，这个区域主要存放函数的参数值、局部变量、形参等等。
      5. 内核空间环境变量

7. 堆和栈的区别

   1. 堆：按需申请，动态分配
   2. 栈：程序运行时自动拥有的一小块内存，大小在编译器时由编译器参数决定，用于局部变量的存放或者函数调用栈的保存。
   3. 区别：
      1. 栈是系统自动分配释放的，而堆是由程序员控制的，容易产生内存泄漏。
      2. 大小：每个进程拥有的栈大小要远远小于堆大小。
      3. 生长方向不同：堆的生长方向向上，内存地址由低到高；栈的生长方向向下，内存地址由高到低。
      4. 分配方式不同：堆都是动态分配的，没有静态分配的堆；栈有的动态静态两种。静态分配是由操作系统完成的，比如局部变量的分配。动态分配由alloca()函数分配，但是栈的动态分配和堆是不同的，它的动态分配是由操作系统进行释放，无需我们手工实现。
      5. 分配效率：栈是硬件层级支持，更快。堆是由C++提供的库或则和运算符来完成申请与管理，较为复杂，频繁的申请容易产生内存碎片，效率低得多。
      6. 存放内容不同：堆是由程序员来填充的，栈存放函数返回地址、相关参数、局部变量和寄存器内容等。
   4. 出入栈：
      1. 函数压栈：
         1. 调用指令：在函数调用点，会发出一个调用指令，将控制权转移到被调用函数的入口点。
         2. 保存返回地址：当前函数的返回地址被压入栈中，以便哈桉树执行完毕后返回到正确的位置。
         3. 参数压栈：函数调用时，将函数的参数按照一定的顺序压入栈中，通常从右到左依次入栈。
         4. 保存寄存器值：在一些体系结构中，函数调用时需要保存一些寄存器的值，以便在函数执行完毕后能够恢复原始的寄存器状态，
         5. 帧指针与局部变量压栈：为了支持函数内的局部变量和堆栈的动态分配，通常在栈上维护一个帧指针，它指向当前函数的栈帧的底部。同时，函数内部定义的局部变量也会在栈上分配空间。
         6. 执行函数体
      2. 函数出栈：
         1. 恢复寄存器值：在一些体系结构中，函数返回时需要恢复之前保存的寄存器的值。
         2. 释放局部变量和帧指针：函数返回后，会释放函数内部定义的局部变量所占用的栈空间，并将帧指针恢复到上一层函数的栈帧。
         3. 弹出参数和返回地址：函数返回后，参数和返回地址会从栈中弹出，将控制权返回到调用函数的正确位置。

8. 重载和重写

   1. 定义不同
      1. 重载是定义相同的方法名，参数不同。
      2. 重写是子类重写父类的方法
   2. 范围不同：
      1. 重载在一个类里
      2. 重写是父类子类之间
   3. 多态不同
      1. 重载是编译时多态
      2. 重写是运行时多态
   4. 返回不同
      1. 重载对返回没有要求
      2. 重写要求返回一致
   5. 参数不同
      1. 重载对参数没有要求（要求不同）
      2. 重写参数必须相同
   6. 修饰不同
      1. 重载对访问修饰没有特殊要求
      2. 重写访问修饰符的限制一定要大于被重写的方法

9. 链表和数组

   1. 链表：所谓链表，链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过**链表中的指针**链接**次序**实现的。链表由一系列结点（链表中每一个元素称为结点）组成，结点可以在运行时动态生成。
   2. 数组：所谓数组，就是**相同数据类型**的元素按一定**顺序排列**的**集合**；数组的存储区间是**连续的**，占用内存比较大，故空间复杂的很大。但数组的[二分查找](https://so.csdn.net/so/search?q=二分查找&spm=1001.2101.3001.7020)时间复杂度小，都是O(1)；数组的特点是：**查询简单，增加和删除困难**；（数组的空间在编译时期就需要进行确认，提前留出数组空间的大小）

10. 插入删除的操作谁更快？

    1. 链表更快
    2. 查找元素数组更快

11. 判断链表是否存在环？

    1. 快慢指针：当快慢指针相遇时候，说明链表存在环
    2. 扩展：如何求出环的长度？
       1. 首次相遇后，让两个指针继续循环前进，并统计前进的循环次数，即可求出环长。
    3. 扩展：如何求出环的入口？
       1. 首次相遇后，让fast指向头结点，slow原地不动，让fast和slow每次走一步，再次相遇即为入口结点。
       2. a = b*(n-1)+n*c

12. 进程和线程的区别

    1. 进程是资源（包括内存、打开的文件等）分配的单位，线程是CPU调度的单位
    2. 进程拥有一个完整的资源平台，线程只独享必不可少的资源，如寄存器和栈
    3. 线程同样具有就绪、阻塞、执行三种基本状态
    4. 线程能减少并发执行的时间和空间开销
       1. 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
       2. 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
       3. 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
       4. 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

13. 线程有哪些状态？

    1. 三种：运行、就绪、阻塞
    2. 五种：创建、就绪、运行、阻塞、结束
    3. 七种：就绪挂起、阻塞挂起
    4. 运行->阻塞：
       1. 调用sleep方法，使线程睡眠。
       2. 调用wait方法，使线程进入等待。
       3. 当线程去获取同步锁的时候，锁正在被其他线程持有。
       4. 调用阻塞式IO方法时会导致线程阻塞。
       5. 调用suspend方法，挂起线程，也会造成阻塞。
    5. 阻塞进入就绪

14. 死锁的原因？

    1. 互斥条件：多个线程不能同时使用同一个资源
    2. 持有并等待条件：当线程A已经持有资源1，又想申请被持有的资源2，就会处于等待状态，并且不会释放自己已经持有的资源1
    3. 不可剥夺条件：当线程已经持有了资源，在自己使用完之前不能被其他线程获取
    4. 环路等待条件：当死锁发生的时候，两个线程获取资源的顺序构成了环形链

15. 介绍一下网络，七层网络模型或者四层网络模型

    1. 计算机网络是一个将分散的、具有独立功能的计算机系统通过通信设备和线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。

    2. 网络是由物体、设备或人组成的错综复杂的连接系统

    3. 计算机网络：网络的一种

       1. 目的是共享资源，资源类型比较广泛
       2. 传送的类型是二进制数据流
       3. 组成：硬件，软件，协议
       4. 功能：
          1. 数据通信
          2. 资源共享
          3. 分布式处理
          4. 提高可靠性
          5. 负载均衡

    4. OSI七层模型：

       1. 应用层：各种应用程序协议，如HTTP、FTP、SMTP、POP3等。直接向用户提供服务，完成用户希望在网络上完成的各种工作。
       2. 表示层：信息的语法语义以及它们之间的关联，如加密解密等。处理用户信息的表示问题，如编码、数据格式转换和加密解密等
       3. 会话层：不同机器上的用户之间建立及管理会话。组织和协调两个会话进程之间的通信 ，并对数据交换进行管理。
       4. 传输层：接受上一层的数据，必要时候将数据进行分割，并将这些数据交给网络层，且保证这些数据段有效到达。该层的主要功能是：向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输，同时向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。
       5. 网络层：控制子网的运行，如逻辑编址、分组传输、路由选择，在数据链路层提供的两个相邻端点之间的数据帧的传送功能上，进一步管理网络中的数据通信，控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接，将数据设法从源端经过若干个中间节点传送到目的端（点到点），从而向传输层提供最基本的端到端的数据传输服务。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。数据链路层和网络层的区别为：数据链路层的目的是解决同一网络内节点之间的通信，而网络层主要解决不同子网间的通信。
       6. 数据链路层：物理寻址，同时将原始比特流转变为逻辑传输线路
       7. 物理层：机械、电子、定时接口通信信道上的原始比特流传输。

    5. 四层网络模型：

       * 四层网络模型不是OSI的标准，是我们实践后经过经验定义的四层网络模型。抛弃了七层中的物理层、会话层、表示层。仅保留了数据链路层、网络层、传输层、应用层

       1. 应用层：所以，应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。
       2. 传输层：TCP和UDP都在传输层，是为应用层提供网络支持的
          1. 也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是**网络层**（*Internet Layer*）。
       3. 网络层：实际的传输功能
       4. 数据链路层：主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备
       5. 总结：
          1. ![封装](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\封装.webp)

16. TCP和UDP属于哪一层

    1. 传输层

17. TCP和UDP区别是什么

    1. TCP是面向连接的，传输数据前要建立连接，UDP是面向无连接的，即刻传输数据
    2. UDP是不可靠传输，最大努力交付，不保证可靠交付数据。TCP是可靠传输，数据可以无差错、不丢失、不重复、按序到达。
    3. UDP是面向报文，有边界，但是可能丢包和乱序。TCP是面向字节流，流式传输，没有边界，但是保证顺序和可靠
    4. UDP头部开销小(8字节)，TCP头部开销大（没有选项20字节）
    5. TCP一对一，UDP都可以
    6. TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
    7. 应用场景：
       1. TCP
          1. `FTP` 文件传输；
          2. HTTP / HTTPS；
       2. UDP
          1. 包总量较少的通信，如 `DNS` 、`SNMP` 等；
          2. 视频、音频等多媒体通信；
          3. 广播通信；

18. 微信是TCP和UDP？

    1. TCP
    2. 怎么发现的：在传输文件的时候

19. TCP的三次握手和四次挥手

    1. 看前面的

20. HTTP和HTTPS的区别，是哪一层协议

    1. 看前面的
    1. 会话层？

21. HTTPS是怎么加密的

    1. 引入对称加密和不对称加密

    2. > 在建立通信前使用非对称加密，在通信过程中全部使用对称加密的方式加密明文数据。

    3. TLS阶段非对称密钥，加密解密

    4. 对称密钥，后续传输数据加密解密

    5. 客户端发TLS请求，发送随机数和加密算法给服务器；

    6. 服务器确认协议版本，发送服务器随机数，确认加密套件，发送数字证件

    7. 校验数字证件；客户端取出服务器公钥，加密报文（包括会话密钥、加密算法改变通知等），再发给服务器。

    8. 服务器使用私钥解密，再计算出会话密钥，发送信息给客户端。

    9. ![5c09960e4b42cc41cc058cd7d7b27d8d_720w](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\5c09960e4b42cc41cc058cd7d7b27d8d_720w.png)

22. 为什么要采用两种加密方法

    1. 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢，在数据传输的时候需要考虑效率问题，所以改用对称加密。（防止中间人）

23. 了解的设计模式有哪些？

    1. 工厂模式、抽象工厂模式、中介者模式、观察者模式、装饰器模式、适配器模式
    2. https://zhuanlan.zhihu.com/p/575645658
    3. 创建型模式：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式
    4. 结构性模式：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、结合模式、享元模式
    5. 行为型模式：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式

24. 静态代理和动态代理的区别是什么？

    1. 为什么要用代理模式？
       1. 中介隔离作用
       2. 开闭原则，增加功能：代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后对返回结果的处理等。代理类本身并不真正实现服务，而是同过调用委托类的相关方法，来提供特定的服务。真正的业务功能还是由委托类来实现，但是可以在业务功能执行的前后加入一些公共的服务。例如我们想给项目加入缓存、日志这些功能，我们就可以使用代理类来完成，而没必要打开已经封装好的委托类。
    2. 静态代理：
       1. 静态代理，编译时就已经确定下来了接口代理类被代理类，代理类与被代理类实现同一个接口，代理类持有一个被代理类对象，在代理类中对被代理类的方法进行调用，代理类中就可以加入一些其他的逻辑。
       2. 优点：可以做到在符合开闭原则的情况下对目标对象进行功能扩展。
       3. 缺点： **代理对象与目标对象要实现相同的接口，我们得为每一个服务都得创建代理类，工作量太大**，不易管理。同时接口一旦发生改变，代理类也得相应修改。
    3. 动态代理：
       1. 动态代理，代理类是在程序运行时动态生成的，可以很方便的对被代理类的所有方法做统一的处理
       2. 在运行时才动态生成代理类，并且将其与被代理类绑定，也就是说在运行时才能确定代理的是哪个被代理类。
       3. C++中或许可以使用多态来？

25. 工厂模式有几种？

    1. 三种：简单工厂、抽象工厂、普通工厂
    2. 简单工厂：定义了一个创建对象的类，由这个类来封装实例化对象的行为（违反了开闭原则，如果想要扩展程序必须对工厂类进行修改）
    3. 工厂方法模式：定义了一个创建对象的抽象方法，由子类决定要实例化的类。（工厂类继承有抽象方法的类，通过不同工厂得到不同对象，想要增加功能只需要再做一个实现类，缺点是新增产品的时候还要新增工厂类，系统中类的个数成倍增加）
    4. 抽象工厂：定义了一个接口用于创建相关或者有依赖关系的对象族，而无需明确知名具体类。
       1. 优点：工厂总抽象类可以创建多个类型的产品，当有需求时，可以创建相关产品子类和子工厂类来获取。也就是可以满足生产不同品牌的不同类型的电脑。
       2. 缺点： 扩展新种类产品时困难。抽象工厂模式需要我们在工厂抽象类中提前确定了可能需要的产品种类，以满足不同品牌的多种产品的需求。但是如果我们需要的产品种类并没有在工厂抽象类中提前确定，那我们就需要去修改工厂抽象类了，而一旦修改了工厂抽象类，那么所有的工厂子类也需要修改，这样显然扩展不方便。
       3. 人话：同一个工厂的所有不同产品是一个产品族，同一类型的不同工厂的所有产品是一个产品等级结构
          1. 抽象工厂里声明了创建一族产品的方法，每一个方法对应一种产品
          2. 具体工厂实现方法
          3. 当需要增加新的产品等级结构的时候，就要同时修改抽象类和实现类

26. 一般用什么方法解决hash冲突?

    1. 链地址法
    2. 开放定址法

27. map和set有什么区别？

    1. map存储键值对，set存储唯一的值
    2. 底层依赖红黑树
    3. unordered_map是无序的
    4. set的迭代器是const的，不允许修改元素的值，map允许修改value但不允许修改key
    5. map支持下标操作，set不支持

28. void*是什么

    1. 无类型指针

29. 纯虚函数

    1. 纯虚函数是一种特殊的虚函数，在许多情况下，在基类中不能对[虚函数](https://baike.baidu.com/item/虚函数/2912832?fromModule=lemma_inlink)给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的[派生类](https://baike.baidu.com/item/派生类/9589520?fromModule=lemma_inlink)去做。这就是纯虚函数的作用。
    2. C++中的纯虚函数，一般在函数签名后使用=0作为此类函数的标志。
    3. 包含纯虚函数的类称为[抽象类](https://baike.baidu.com/item/抽象类?fromModule=lemma_inlink)。由于抽象类包含了没有定义的纯虚函数，所以不能定义抽象类的对象。

30. 编写一个集合类，可以是 list/vector/map/dictionary  , 按照你的实现添加需要的主要接口，功能1

字节跳动：

1. 虚拟地址是怎么和转到物理地址的？页表的构成？mmu了解过吗？
   1. 页表的构成：
      1. 页表由多个页表项组成
      2. 页表项：
         1. 页框号
         2. 有效位
         3. 访问位
         4. 修改位
         5. 保护位
      3. MMU：内存管理单元
2. 操作系统的原作操作是怎么实现的？
   1. 总线锁：使用处理器提供的一个LOCK指令信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞，那么该处理器就可以独占共享区。
   2. 缓存锁：不是锁住总线，而是锁住内存对应的缓存行数据，通过缓存一致性（也就是操作系统禁止同时修改由两个以上处理器缓存的内存数据）。当其他处理器回写已被锁定的缓存行数据，会使缓存无效。
      1. 缓存锁是采用“缓存锁定”将原子操作放在cpu缓存中进行（L1、L2、L3高速缓存）。“缓存锁定”指当发生共享内存的锁定，处理器不会在总线上声言LOCK#信号，而是修改内存地址，并通过缓存一致性机制保证原子性。因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓行的数据时，会使缓存行无效
3. C++的内存分区？bss段了解过吗？未初始化的全局变量和初始化的全局变量放在哪里？
   1. 堆
   2. 栈
   3. 全局/静态存储区
      1. 数据段：已初始化的全局变量
      2. BSS段：未初始化的全局变量
   4. 代码区
   5. BSS了解过吗？
      1. 
4. 内存对齐？为什么字节对齐
   1. 方便计算机读写数据
   2. 原因：
      1. 某些平台的特定类型数据只能从某些特定地址开始存取
      2. 提高读取效率
5. vector中push_back和emplace_back的区别？
   1. 多个构造函数情况下，push_back需要传递一个对象，但是em可以传递构造参数
   2. 性能
   3. 就地构造，直接在容器内构造对象，不需要使用拷贝构造函数
   4. 原理：使用完美转发机制，将传入的参数传到了构造函数中，实现了直接从数组里一步到位构造对象，省略了创建临时对象的过程。
6. C++的多态？说一下虚函数的多态
   1. 
7. 内联函数？内联函数的缺点？
   1. 和宏：	
      1. 内联函数更加类型安全，会有类型检查
      2. 内联函数可以调试
      3. 宏不属于名称空间，可能会导致名称冲突
   2. inline
   3. 优点是避免函数调用的开销，提高运行速度
   4. 缺点：
      1. 增大了可执行程序的体积
      2. 每次修改都要重新编译（编译时期）
      3. 头文件信息变多
8. tcp的可靠传输？拥塞控制？流量控制？
   1. 可靠传输：三次握手
   2. 拥塞控制
   3. 流量控制
9. IP数据报的报头字节？TTL的设置了解过吗？
   1. 版本号、报头长度、服务类型、封包总长度、封包标识、标志、片段偏移地址
   2. TTL的设置：生存时间TTL（最大跳数）
      1. TTL值在文件`/proc/sys/net/ipv4/ip_default_ttl`中定义,可通过执行`echo 128 > /proc/sys/net/ipv4/ip_default_ttl`命令修改
          (这是短暂性的)若要永久生效可修改`/etc/sysctl.conf`配置文件，添加`net.ipv4.ip_default_ttl=128`，接着执行`sysctl -p`即可。
      2. 
10. 怎么实现断点续传？
    1. 
11. 算法题：
    1. 最长回文子串：
       1. pair<int,int> expand();
       2. auto [left1,right1] = expand();







一些比较重要的东西：

华为和字节准备：

1. 华为：

   1. 单链表如何找倒数第k个节点

      1. 很简单
      2. 具体来说，使用快慢指针，首先先创建一个头结点连接原链表，然后快慢指针指向头结点，快指针先向后前进n位，然后快慢指针同时前进直到快指针的下一位为空。
      3. 这个时候慢指针指向的是倒数第k+1个节点，如果要找的话直接返回下一位即可，删除的话将慢指针的next指向next的next。

   2. 单链表如何判断是否有环

      1. 同样使用快慢指针，快指针移动两位慢指针移动两位，如果相遇则说明有环

   3. 图如何判断有没有环？

      1. 拓扑排序
         1. 无向图：
            1. 求出图中所有结点的度
            2. 将所有度<=1的结点入队
            3. 当队列不空的时候，弹出队首元素，把与队首元素相邻结点的度减一，如果相邻结点变为1，则将相邻结点入队
            4. 循环结束如果已经访问的结点数等于n则无环，反之有环
         2. 有向图
            1. 在判断有向图是否存在环的时候，是将所有入度=0的结点入队。
      2. DFS
         1. 使用DFS可以判断一个无向图和有向中是否存在环。
         2. 深度优先遍历图，如果发现某个结点中有一条边指向已访问过的结点，且这个已访问过的结点不是上一步访问的结点，则存在环。
         3. 需要规定三种状态，未访问、访问过未完成、完成，如果访问到访问过但未完成的则说明存在环。
      3. 并查集
         1. 对于无向图来说，在遍历边（u-v）时，如果结点 u 和结点 v 的“父亲”相同，那么结点 u 和结点 v 在同一个环中。
         2. 对于有向图来说，在遍历边（u->v）时，如果结点 u 的“父亲”是结点 v，那么结点 u 和结点 v 在同一个环中。

   4. 多线程会出现什么问题？

      1. 死锁
         1. 多个线程互相等待对方释放所占用的资源时，可能陷入死锁状态
         2. 如何解决？
            1. 线程一次性申请所有需要的资源，申请成功就运行，不成功就等待。（可能会造成饥饿）
            2. 改变不可剥夺条件，当想要申请资源并且失败的时候，将当前拥有的资源释放。
            3. 改变循环等待条件：将所有的资源从小到大编号，线程申请资源从小到大申请。
      2. 线程安全问题（竞态条件）
         1. 在某一线程从开始访问到结束访问某一数据期间，该数据被其他的线程所修改，发生了线程安全问题，表现为数据的缺失、数据不一致
         2. 多个线程同时访问共享资源的时候，由于线程执行顺序的不确定性，可能会导致错误
         3. 发生了上下文切换
         4. 解决方法：
            1. 互斥
            2. 锁
      3. 饥饿
         1. 某些线程由于竞争共享资源失败而无法继续执行时，可能会出现饥饿问题。
         2. 解决饥饿的方法：
            1. 保证资源充足
            2. 公平分配资源
            3. 避免持有锁的线程长时间执行

   5. 源码到可执行文件经历了什么？编译、汇编和链接里面具体发生了什么？

      1. 预处理，编译，汇编，链接
      2. test.c（-E）->test.i（-S）->test.s（-c）->test.o
      3. 具体发生了什么？
         1. 预处理：把一些#define的宏定义完成文本替换，然后将#include的文件的内容复制到.cpp文件里，如果.h文件里还有.h文件，就递归展开
         2. 编译：编译把我们写的代码转换为汇编代码，工作是检查词法和语法错误。（词法分析，语法分析，语义分析，源代码优化，代码生成，目标代码优化）
         3. 汇编：转换为机器码，把指令打包成一种叫做可重定位目标程序的格式，保存在.o文件里，是一个二进制文件
         4. 链接：C/C++代码经过汇编之后生成的**目标文件(`\*.o`)并不是最终的可执行二进制文件，而仍是一种中间文件(或称临时文件)，目标文件仍然需要经过链接(Link)才能变成可执行文件**。

   6. 动态链接和静态链接的区别

      1. 静态链接是由链接器在链接时将库的内容加入到可执行程序中的做法。

      2. 动态链接（`Dynamic Linking`），把链接这个过程推迟到了运行时再进行，在可执行文件装载时或运行时，由操作系统的装载程序加载库。

      3. **（1）静态链接的优缺点：**

         **优点：**

         - 代码装载速度快，执行速度略比动态链接库快；
         - 只需保证在开发者的计算机中有正确的.lib文件，在以二进制形式发布程序时不需考虑在用户的计算机上.lib文件是否存在及版本问题。

         **缺点：**

         - 使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费。

      4. **（2）动态链接的优缺点：**

         **优点：**

         - 生成的可执行文件较静态链接生成的可执行文件小；
         - 多个程序执行时候共享同一份副本
         - 更新方便
         - 适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试；
         - 不同编程语言编写的程序只要按照函数调用约定就可以调用同一个DLL函数；
         - DLL文件与EXE文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性；

         **缺点：**

         - 使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息；
         - 速度比静态链接慢；

   7. 哈希冲突怎么办

      1. 链地址法：使用链表来存储有相同哈希值但是不同键的键值对（冲突较多的时候会变得很长，性能下降）
      2. 红黑树：红黑树是一种自平衡的二叉搜索树，具有较快的插入、删除和查找操作
         1. 左旋：将节点转为它的右孩子的左孩子
         2. 右旋：将节点转为它的左孩子的右孩子
      3. 开放寻址法：  \- 当发生哈希冲突时，使用一种探测序列（如线性探测、二次探测或双重散列）来寻找下一个可用的桶。

   8. 手撕leetcode2401

      1. 最长优雅子数组
      2. 首先需要知道几个操作
      3. 使用到的操作：滑动窗口、位操作
      4. 以right为基准，来确定每个right对应的最小left
      5. 位操作中，与可以用来确认是否可以符合优雅子数组的要求，在本题中，将or_（也就是当前从left到right所有数的或操作）与nums[right]进行与操作，意在确认当前or_是否可以满足nums[right],如果不行，left++，并使用异或操作将nums[left]清除出or_；在操作完后，将nums[right]加入or_中，也就是进行或操作
      6. 然后每次将ans与right-left+1比较大小就可以得到最后结果。

   9. 最熟悉的三个协议

      1. TCP协议
      2. SSL协议
      3. UDP协议
      4. ARP协议

   10. tcp在哪一层？

       1. 传输层

   11. 网络层有什么？

       1. ARP协议、IP协议、ICMP协议、IGMP协议

   12. arp的具体过程以及arp里面的类型有什么？ping属于什么协议？什么so是什么协议？

       1. ARP在TCP/IP里是IP层，在OSI模型里是链路层
       2. ping属于ICMP协议
       3. ARP：地址解析协议，是根据IP地址获取物理地址（MAC地址的一个TCP/IP协议。
       4. 主机发送信息时将包含目标ip地址的ARP请求广播到局域网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。
       5. 类型：
          1. 动态ARP
          2. 静态ARP
          3. 路由式ARP
          4. 代理ARP
          5. 免费ARP
       6. 过程：
          1. 判断地址是否是同一网段
          2. 查询目标IP地址的mac（发送arp请求）
       7. ARP请求以广播发送，以单播回应。
       8. 同网段：
          1. 查看ARP高速缓存表，有就直接通过MAC地址传输，没有的话向局域网所有主机广播一个ARP请求，寻找MAC地址。
          2. 收到ARP请求后回复一个ARP数据包
          3. 收到发送回来的请求后将MAC地址写入高速缓存中，然后通过MAC地址进行数据的传输
       9. 不同网段：
          1. 发现没有MAC地址。
          2. 查询ARP，发现是不同网段
          3. 查询网关的MAC地址。
          4. 将数据包发送给路由器。
          5. 路由器查询MAC地址，有就直接发，没有发送ARP请求查询。
          6. 发送给B（封装自己的MAC地址为源，B的为目的MAC，源和目的的IP地址不变）
          7. B回复，网关更改为A的MAC发送，A收到B的回复。

   13. ssl和tls协议有什么差别？

       1. SSL握手
       2. TLS是SSL的继任者
       3. 在加密算法存在差异
       4. 版本差异
       5. **TLS的主要目标是使SSL更安全，并使协议的规范更精确和完善。**

   14. 内联函数（参数类型检查）

2. 字节：

   1. 从键入网址到网页显示，期间发生了什么
   
      1. 首先，通过浏览器解析URL，确定Web服务器和文件名
      2. HTTP：根据这些消息来生成HTTP请求消息，HTTP请求报文
      3. DNS：真实地址查询
         1. 先从缓存找
         2. DNS服务器保存了Web服务器域名和IP的对应关系
         3. 根、顶级域、权威
      4. UDP：DNS是基于UDP协议的
      5. TCP
         1. 源端口号，目的端口号，序号，确认序列，首部长度，保留，窗口大小，校验和，紧急指针，选项
         2. 状态位，SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接
      6. IP协议
         1. 源地址IP和目的地址IP
      7. SSL：？
      8. ARP
         1. 获取MAC地址
      9. ICMP协议：提供网络传输中的差错检测
      10. LLC和MAC：提供数据链路层的组帧、透明传输等功能
      11. 渲染页面
      12. 发起四次挥手
   
   2. ARP协议
   
      1. 上面
   
   3. 哈希表？
      1. 怎么构造一个哈希表
      2. 如何解决哈希表的冲突？
      3. 哈希表的线程安全
      4. 哈希表其他问题
   
   4. TCP/IP的各种问题
   
      1. 重传机制：
         1. 超时重传：超时了就重传
         2. 快速重传：当收到三个相同的ACK报文时，会在定时器过期之前，重传丢失的报文段
         3. SACK方法：选择性确认，将已经收到的数据的信息发送给发送方，发送方收到三次相同的ACK后触发快速重传，发现哪里的数据丢失就选择TCP段重复
         4. D-SACK：其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**（比如ACK确认报文丢失，重复收到，告诉已经发送方已经被接收了。）
      2. 流量控制：
         1. 让发送方根据接收方的实际接受能力控制发送的数据量
         2. 发送数据后，可用窗口向右移动，收到确认报文后SND.UNA往右偏移后指向321，可用窗口扩大。
         3. 收缩窗口，发送确认信息时候通报窗口大小
      3. 拥塞控制：
         1. 慢启动
            1. 拥塞窗口
            2. 慢启动门限
         2. 拥塞避免算法
            1. 拥塞窗口超过慢启动门限后开始启动拥塞避免算法
         3. 拥塞发生
            1. 发生超时重传：
               1. 慢启动门限设为1/2，拥塞窗口重置为1
            2. 发生快速重传
               1. 拥塞窗口变为一半，慢启动门限设为拥塞窗口
               2. 重传丢失的ACK，拥塞窗口+1
               3. 如果收到新数据，将拥塞窗口设为慢启动门限的大小，回到拥塞避免
         4. 快速恢复
   
   5. 多路复用IO的各种技术和问题
   
      1. 多路复用IO解决了什么？作用是什么？
         1. 阻塞IO只能阻塞一个I/O操作，但是多路复用可以阻塞多个I/O操作，所以才叫做多路复用
         2. 一个线程通过记录I/O的状态来同时管理多个I/O，可以提高服务器的吞吐能力。
      2. 有什么多路复用IO的方法？
         1. select
         2. poll
         3. epoll
   
   6. 虚拟内存和物理内存？中间有什么？交换区？
   
      1. 虚拟内存是为了满足物理内存不足时而提出的策略。
      2. 物理内存是有限的，相比起来磁盘的容量是非常大的。
      3. 内存交换：将某些进程一些暂时用不到的内存页保存到磁盘中，然后把物理内存页分配给更紧急的用户使用，等到进程用到的时候再从磁盘读到内存。
      4. LRU最近最少使用
      5. CPU通过MMU寻找虚拟地址对应的物理地址，如果找到从主存里取，没有的话产生缺页，读取数据到主存上，跟新页表对应关系，返回给CPU
      6. 交换区：当系统的物理内存不够用的时候，就把一部分空间释放出来，以供当前运行的程序使用，可能使用LRU最近最少使用算法，把被释放的空间临时保存到交换区，等到那些程序要运行的时候才恢复到内存中。
   
   7. Linux的软链接和硬链接
   
      1. 硬链接
         1. 文件系统里每个文件都会有一个索引节点，来标识文件，硬链接通过索引节点来链接。可以有多个文件指向同一个索引节点，也就是一个文件可以拥有多个路径名，因此一个文件可以对应多个文件名，但是不能对应目录。
         2. 别名
         3. 只能在一个文件系统里创建
         4. 如果硬链接文件的内容修改了，那么源文件也会改变
         5. 类似复制，但是不产生新的文件
         6. 通过inode进行链接
      2. 软链接
         1. 软链接文件可以指向任意一个文件系统下的任意文件和目录，还可以指向不存在的文件
         2. 系统创建链接文件指向要指向的文件
         3. 类似于快捷方式
         4. 存放的内容是另一个文件的路径名的指向
   
   8. 之后再补充有什么问题
   
   9. TCP的标志位：ack和syn，fin，rst（我怎么忘了这个啊nmd）
   
   10. vector和map的线程安全问题
   
       1. map在访问桶的时候上锁，保证效率和安全。（链地址法）
       2. 
   
   11. 单例模式的线程安全
   
       1. 饿汉模式：类加载的时候就创建实例，满足线程安全。内部加锁，多个线程调用静态方法，只有一个线程能够竞争到锁并且完成创建，只执行一次。
       2. 懒汉模式：第一次使用时候才创建，如果没有被创建多个线程都调用方法可能创建多个实例。
          1. 使用同步锁改进：每次调用该方法的时候都竞争锁。（满足线程安全，但是效率低，再调用方法还需要竞争释放锁）
          2. 使用双重校验锁：
             1. 外层使用if判断：实例只被创建一次，如果新加入的线程发现实例已经被创建好了就不要后续操作直接return返回。
             2. 内存使用if判断：实例未被创建的时候，多个线程同时竞争锁，只有一个成功，其他的等待，当释放成功的线程后，其他失败的线程继续竞争，但是实例这个时候已经创建好了，所以用一个新的if来判断他们是否应该直接退出。
          3. volatile
             1. 保证了可见性和有序性，多个线程对他修饰的变量可以进行并发和并行执行。使用了缓存一致性来保证都是最新的主存数据。
   
   12. 同步？
   
       1. 同步的方法有多种，比如：
          1. 互斥锁：
             1. 强调的是资源之间的访问互斥，每个线程在对共享资源操作之前都会尝试先加锁，加锁成功才能操作。
          2. 读写锁
             1. 分为读写两个方式，写锁占用的时候不能加读锁和写锁，读锁占用的时候可以加读写，加写锁会阻塞。
             2. 不同策略：
                1. 强读同步：读锁优先，只要写锁没有占用那么就可以加读锁
                2. 强写同步：写锁优先，只能等到所有正在等待或者执行的写锁执行完成后才能加读锁（为了防止写饥饿）
          3. 条件变量：本质上是一个多线程间共享的全局变量，功能是阻塞线程，直到条件成立才能将继续执行。
          4. 信号量：分为有名信号量和无名，无名用于线程同步，有名用于进程之间管理
             1. 信号量允许多个线程同时进入临界区
   
   13. 阻塞、非阻塞、同步、异步
   
       1. 阻塞就是需要等待IO才能进行下一步操作
   
       2. 非阻塞就是不需要等待IO
   
       3. 同步就是指一个线程要等待上一个线程执行完之后才开始执行当前的线程
   
          异步是指一个线程去执行，它的下一个线程不必等待它执行完就开始执行

4399：

1. 虚拟内存管理
2. 讲一下虚拟地址到物理地址的映射
   1. CPU生成一个虚拟地址，把他传给MMU
   2. MMU生成PTE地址，请求高速内存/内存返回实际数据。
   3. 内存向MMU返回PTE
   4. MMU按照逻辑，构造物理地址PA，并请求内存
   5. 主存返回物理地址存储的数据
   6. 虚拟地址包含两部分，一个p位的虚拟页面偏移VPO和一个(n-p)位的虚拟页号VPN。
   7. MMU利用虚拟页号来选择合适的PTE(页表条目)，然后将PTE中PPN（物理页号）和虚拟页面偏移串联起来，就得到了实际的物理地址。
   8. 加速：TLB
      1. TLB是页表项的缓存
   9. 在程序装入时，将程序中很快会用到的部分装入内存，暂时用不到的部分扔到外存（换出）
       在程序执行时，当程序访问的信息不在内存时，需要请求调页/调段，由OS负责将所需信息从外存调入内存（换进），然后继续执行程序
       若内存空间不够时，需要页面/段置换，由OS负责将暂时用不到的信息换出到外存，交换区
3. CPU是否参与映射过程
   1. 有，提供虚拟地址，并且MMU负责地址的翻译
4. 定点数和浮点数的区别
   1. 定点数就是小数点位置固定不变的数
   2. 浮点数指小数点位置不固定的数
5. 浮点数的存储方式
   1. 既有整数部分，又有小数部分，通常由阶码/指数、尾数组成。
   2. 尾数的长度决定了浮点数的精度
   3. 指数的长度决定了浮点数的取值范围
6. 浮点数表示0-1和1-100精度是否一致
   1. 不一致
   2. 在表示0到1之间的小数时，精度相对较高，因为指数范围内有很多位来表示小数部分。
   3. 在表示1到100之间的整数或小数时，精度相对较低，因为指数的大部分位数已经用于表示整数部分，小数部分的表示受到限制。
7. 浮点数是否能表示所有整型数
   1. 在理论上，浮点数是可以表示所有整型数的，因为整数也是浮点数的一种特殊情况。然而，在实际计算机系统中，由于浮点数采用有限位数的表示，存在有限的精度，因此并非所有整数都能被精确地表示。
   2. 因此，虽然浮点数可以表示很大范围的整数，但在极端情况下，会存在精度损失的问题。对于对整数精度要求极高的应用，通常会使用整数类型而非浮点数类型。

mysql

1. 用的什么引擎
2. 为什么用索引
3. 索引是什么结构

redis该看看了

linux的指令得看了

1. 查看磁盘 df
   1. df命令全称为disk-free，用于查看Linux系统中的可用和已经使用的磁盘空间，一般有以下几个常用选项：
2. du 
   1. du命令全称为disk useage的缩写，以默认千字节大小显示文件、文件夹等磁盘使用情况
3. ls -al命令
   1. ls命令大家再熟悉不过了吧，使用ls -al命令可以列出特定目录的全部内容及其大小。
4. kill
5. ps 查看与进程相关的PID号
6. ps好像也可以看线程
7. top



小米：

1-说一下osi七层模型，数据在每一层怎么转换的，说一下ip地址到mac地址的过程

1. 七层：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层
1. 应用层->字符和数字
1. 表示层->转换为二进制格式，压缩和加密
1. 会话层->建立、管理和维护会话
1. 传输层->按照TCP协议进行封装（传输协议）TCP与UDP协议头部封装
1. 网络层->ip头部封装
1. 数据链路层->接受上层数据，定位源和目MAC地址并且差错检验
1. 物理层->接受上层数据并转换为比特流
9. IP地址到mac地址的过程
   1. ARP协议
   2. 


2-栈空间都保存了什么东西，具体一点

1. 函数的返回地址、形参、局部变量、返回类型、临时的寄存器保存

3-死锁的产生，死锁如何检测

1. 死锁产生有四个条件：
   1. 互斥条件
   2. 持有并等待条件
   3. 不可剥夺条件
   4. 环路等待条件
2. 死锁使用有向图来检测
   1. 线程A获取线程B已占用的锁，则为线程A指向线程B。
   2. 运行过程中线程B获取成功的锁即为线程B已占用的锁
   3. 如果有环就是死锁

4-如果在析构函数抛出异常会怎么样

1. 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在抛出异常后执行了类似于释放资源等动作，则这些动作不会执行，会造成诸如资源泄露的问题。
2. 通常异常发生的时候，C++机制会调用已经构造对象的析构函数来释放资源，如果本身析构函数也抛出异常，那么一个异常尚未处理又有新的异常，会造成程序崩溃的问题。
3. 解决方法是：
   1. 不让异常抛出析构函数外，把异常完全封装在析构函数内部

5-为什么析构函数不是虚函数，就不调用子类的析构函数了？

1. 如果父类的析构函数不是虚函数，就不会触发动态绑定，结果只会调用父类的析构函数，不会调用子类的析构函数，从而可能导致子类的内存泄露。

6-pcb tcb 到底存了什么？

1. 进程控制块 process Control Block
   1. 进程标志符
   2. 上下文数据
   3. 进程调度信息
   4. 进程控制信息
2. 线程控制块
   1. 线程标识
   2. 线程状态
   3. 调度参数
   4. 现场信息
   5. 链接指针

7-父进程怎么解决僵尸进程？如何避免？

1. 僵尸进程
   1. 子进程比父进程先结束，但是父进程没有回收子进程，释放子进程占用的资源，此时子进程成为一个僵尸进程。
   2. 解决的方法：
      1. 让僵尸进程的父进程来回收，父进程每隔一段时间来查询子进程是否结束并回收，调用wait()或者waitpid()，通知内核释放僵尸进程。（父进程调用wait和waitpid函数等待子进程结束，导致父进程挂起）
      2.  采用信号SIGCHLD通知处理，并在信号处理程序中调用wait函数：阻塞自己，自动分析是否当前进程的某个子进程已经退出，如果找到了已经变成僵尸的子进程，就将它彻底销毁后返回，没有找到就一直阻塞。
      3. 杀死父进程
   3. 避免的方法：
      1. 让僵尸进程变成孤儿进程，由init回收，就是让父进程先死。
         1. fork两次，第一次fork的子进程在fork后直接退出，第二次fork的子进程就没有父进程了。

8-孤儿进程怎么避免，怎么解决

1. 确保子进程在父进程结束前完成。使用waitpid函数来等待子进程的结束。



1. JPEG的源码

2. static有什么应用场景？

   1. 修饰成员变量
      1. 对所有对象共享。如计数器，共享资源，常量，状态等
   2. 修饰成员方法
      1. 类共享静态方法，直接通过类名来调用不需要创建类的实例对象
      2. 工具类，单例模式（构造函数定义为私有的，然后提供静态方法来获取类的唯一实例）
   3. 静态代码块
      1. 在类加载的时候自动执行的一段代码块，通常用于进行初始化操作
      2. 初始化静态变量。加载驱动程序，执行一次性操作
   4. 修饰内部类（单例模式）
   5. 静态导包

3. extern解决了什么问题？

   1. extern是c++引入的一个关键字，它可以应用于一个全局变量，函数或模板声明，说明该符号具有外部链接(external linkage)属性。也就是说，这个符号在别处定义。

   2. 三种用法：

      1. 补充：引用同一个文件中的变量、引用另一个文件中的变量（全局变量）、引用另一个文件中的函数

      2. 引用别的文件的变量时候不能重新赋值，但是声明之后可以赋值了（如果不想被赋值可以用常量）。

      3. #### 非常量全局变量的外部链接

      4. #### 常量全局变量的外部链接

      5. #### extern “C” 和extern "C++"函数声明

         1. 在C++中，当与字符串连用时，extern指明当前声明使用了其他语言的链接规范，如extern “C”，就指明使用C语言的链接规范。原因是，C++语言在编译的时候为了解决函数的多态问题，会将函数名和参数联合起来生成一个中间的函数名称，而C语言则不会，因此会造成链接时无法找到对应函数的情况，此时C函数就需要用extern “C”进行链接指定，这告诉编译器，请保持我的名称，不要给我生成用于链接的中间函数名。C和C++对函数的处理方式是不同的.extern "C"是使C++能够调用C写作的库文件的一个手段，如果要对编译器提示使用C的方式来处理函数的话，那么就要使用extern "C"来说明。如下所示：

      6. 使用extern和包含头文件来引用函数的区别

         与include相比，extern引用另一个文件的范围小，include可以引用另一个文件的全部内容。extern的引用方式比包含头文件要更简洁。extern的使用方法是直接了当的，想引用哪个函数就用extern声明哪个函数。这样做的一个明显的好处是，会加速程序的编译（确切的说是预处理）的过程，节省时间。在大型C程序编译过程中，这种差异是非常明显的。

4. heap和stack分别有什么用？

   1. 栈用于快速存取，主要是用来存储变量、寄存器的值、函数的返回地址、参数等
   2. 堆用于解决动态存储，由程序员自己来分配（分配方式类似于链表）

5. 为什么需要虚拟地址？

   1. 方便编译器和操作系统安排程序的地址分布：程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
   1. 方便进程之间隔离：不同进程使用的虚拟地址彼此隔离，一个进程中的代码无法更改正在由另一个进程使用的物理内存
   1. 运行很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存管理使得这种情况下各进程仍然能够正常进行。

6. 进程通信方式？

   1. 管道
      1. 匿名：前一个管道的输出作为后一个管道的输入
      2. 命名：mkfifo
   2. 消息队列
   3. 共享内存
   4. 信号量：用于实现进程之间的互斥与同步
   5. 信号：用于异常情况
   6. Socket

7. socket可以和同一主机下进程通信吗？

   1. 可以
   1. 三个参数：协议族、通信特性、通信协议（已废弃）
   1. 本地：AF_LOCAL和SOCK_STERAM（SOCK_DGRAM）

![5F26B2F524498AEE84B6BBB8CEFFD027](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\5F26B2F524498AEE84B6BBB8CEFFD027.png)



荣耀二面：

1. 遇到过什么重大挫折吗？怎么应对的
   1. 
2. 最近在读什么书？
   1. 最近在读一些技术相关的书？
3. 你的优点有什么？
   1. 性格比较平和，不会和别人起冲突
   2. 有足够的内推力，希望自己能够变得更好
4. 期望薪资
   1. 加上绩效20k？
5. 对荣耀的了解
   1. 国内手机大厂
   2. 舍友在荣耀实习，觉得荣耀的环境很好
6. 有什么兴趣、爱好
   1. 游戏，动漫，线下逛商场
7. 加班的看法
   1. 我认为加班是可以接受的



美团二面

1. 不知道问不问项目，问的话就看一下，今天抽点时间看看

2. 虚函数

   1. 虚函数表、虚函数指针

3. 虚继承：

   1. 虚基表的指针，虚基类表存储的是虚基类相对于当前实例对象的偏移。
   2. 虚继承的实例对象在子类中只存在一份拷贝。
   3. 通过偏移量可以找到虚基类的数据成员。

4. 用户态内核态

   1. 操作系统的两种运行状态
   2. 处于内核态的CPU可以访问任意的数据，包括外围设备，比如网卡硬盘等。处于内核态的CPU可以从一个程序切换到另外一个程序，并且占用CPU不会发生抢占情况，一般位于特权级别0的我们称之为内核态
   3. 处于用户态的CPU只能访问受限资源，不能直接访问内存等硬件设备，不能直接访问内存等硬件设备，必须通过系统调用陷到内核中，才能访问这些特权资源。
   4. 特权指令，非特权指令
   5. 如何切换：
      1. 系统调用：有哪些系统调用？（软中断）
         1. 过程：把系统调用名称转换为系统调用号，接着将系统调用号和请求参数放到寄存器里，然后执行中断指令，产生一个中断，从用户态到内核态。CPU跳转到中断处理程序，把寄存器中的东西取出来，然后根据系统调用号，在系统调用表找到相应的系统调用函数进行调用，并将寄存器中的参数作为函数参数。执行完系统调用函数，执行中断返回指令，回复用户态。
         2. 有哪些系统调用函数：
            1. open(pathname,flags,mode) 打开文件，成功返回文件描述符，失败返回-1
            2. close(fd（文件描述符，open的返回值）) 关闭文件，成功返回0，失败返回1
            3. write(fd,buf(数据首地址),count(写入数据的长度（字节）)) 写入文件，成功返回写入数据的字节个数，失败返回-1
            4. read(fd,buf(把文件数据读取到这个内存),count) 读文件，成功返回实际读取到的字节个数，失败返回-1
            5. mkdir（pathname,mode） 创建目录
            6. access(pathname,mode) 判断路径是否存在
            7. fcntl(fd,cmd,...arg) 改变已打开的文件性质
      2. 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
      3. 中断：硬中断，外围设备的中断，可能是IO中断之类的。

5. 虚拟内存

   1. 图解系统
   2. 虚拟内存是什么？
      1. 操作系统提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。
      2. 通过CPU芯片中的MMU的映射关系来转换变成物理地址，然后通过物理地址访问内存
      3. 内存分段：
         1. 段选择子+段内偏移量
         2. 解决了程序本身不需要关心具体的物理内存地址的问题
         3. 不足：内存碎片，内存交换的效率低（交换区的性能瓶颈）
         4. 解决方法：交换区
      4. 内存分页：**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。
         1. 页表来映射
         2. 如何解决外部内存碎片：划分好页，不会产生外部内存碎片，但是产生内部
         3. 不需要一次性把程序都加载到物理内存，需要用到再加载
         4. 页表和偏移量->从页表查询对应物理页号->物理页号+偏移量得到物理内存地址
         5. 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。
         6. 需要的页表大
   3. 为什么需要虚拟内存？
      1. 为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套**虚拟地址空间**，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。
      2. 每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过**内存交换**技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。
   4. 4G内存可以申请8G空间
      1. 因为首先，我申请的是虚拟内存，可以将先需要用到的数据加载到内存，再通过交换区把其他的交换过来。

6. 滑动窗口协议

   1. 为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

      那么有了窗口，就可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

   2. Window通常由接收方的窗口大小来决定

   3. 发送方窗口四个部分：已发送且受到ack、已发送未收到ack、未发送但是大小在接收方处理范围内、未发送且大小超过（三个指针来确认，SND.WND,SND.UNA,SND.NXT）

   4. 接收方窗口三个部分：已成功接受并确认、未收到但是可以接受、未收到且不可以接受（两个指针，RCV.WND,RCV.NXT）

7. vector

   1. vector就是动态数组，有一段连续的地址空间，实现是通过指针和数组（list是双向链表）
   2. 迭代器问题：
      1. 扩容时候会失效
      2. erase时候会失效（方法：让迭代器=v.erase(it)，返回的是下一个元素的迭代器）
   3. 底层原理
      1. 三个T类型的指针，分别是：_start， _finish, _endofstorage;
      2. reserve(size_t n)
   4. 扩容原理
      1. finish是否等于endofstorage，是的话就扩容

8. 宏和inline

   1. inline：声明内联函数，每当出现对函数的调用，直接将函数体中的代码插入，消除调用函数的系统开销
   2. 用内联函数替代宏定义，能消除宏定义的不安全性（宏定义不检查函数参数和返回值）
   3. 宏定义只是在预处理阶段将文本简单地替换。
   4. 不同：
      1.  内联函数比宏定义更加类型安全。内联函数会对参数进行类型检查，而宏定义不会。这意味着，使用内联函数可以避免一些潜在的类型错误。
      2. 内联函数是在编译期间展开的，因此它可以进行更多的编译器优化。而宏定义则是在预处理器展开，不能进行编译器优化。因此，使用内联函数通常可以获得更好的性能。
      3. 内联函数比宏定义更容易进行调试。因为内联函数是实际函数的一份副本，可以通过调试器跟踪到内联函数的执行过程。而宏定义则无法通过调试器进行调试。
      4. 内联函数位于名称空间中，而宏定义不属于任何名称空间。这意味着，内联函数可以避免名称冲突问题，而宏定义可能会导致名称冲突。
      5. 内联函数比宏定义更易于阅读和维护。宏定义的代码通常比较冗长，而内联函数则可以使用常规的C++语法编写，更加简洁易懂。另外，内联函数可以利用C++的函数重载和模板等特性，提高代码的可读性和可维护性

9. C++的编译过程(.cpp到.o)

   1. 预处理（生成.i文件，处理#define、注释和头文件，还有带#的，最后生成只包含字符串和#pragma和#line的文件）、编译（词法分析、语法分析、语义分析，最后生成汇编代码.s文件）、汇编（生成机器指令.o文件）、链接（静态链接或者动态链接，可以链接多个.o文件.exe）

10. Linux下的常用命令

    1. cd
    2. mkdir
    3. rm-f（删除文件） rm-r（删除目录） rm-rf（都删除）
    4. mv
    5. cp
    6. touch
    7. vi
    8. tar
    9. grep
    10. ls
    11. ln
    12. https://www.oh100.com/kaoshi/caozuoxitong/605669.html (线程进程相关)
    13. ps
    14. kill
    15. top
    16. |

11. sed？

    1. 命令
    2. sed编辑器被称作流编辑器（ stream editor）
    3. sed编辑器可以根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中。 sed编辑器会执行下列操作。
       (1) 一次从输入中读取一行数据。
       (2) 根据所提供的编辑器命令匹配数据。
       (3) 按照命令修改流中的数据。
       (4) 将新的数据输出到STDOUT
    4. sed options script file
    5. 重要的是，要记住， sed编辑器并不会修改文本文件的数据。**它只会将修改后的数据发送到STDOUT。如果你查看原来的文本文件，它仍然保留着原始数据。**

12. redis可能得看一下？

13. mysql的引擎：innoDB

14. mysql特有的函数

    1. ABS();
    2. PI();
    3. SQRT();
    4. MOD(x,y);//余数
    5. CEIL(x);
    6. CEILING(x);//向上取整
    7. FLOOR(x);//向下取整
    8. RAND();RAND(x);
    9. ROUND(x);ROUND(x,y);对x四舍五入，并保留小数点y位
    10. CHAR_LENGTH(str);//统计str的字符个数
    11. CONCAT(s1,s2,...);//合并字符串
    12. TRIM(s1 from s);去除字符串s中两端所有的子字符串s1

15. mysql排序怎么用？

    1. 单字段排序 order by;默认升序，desc是降序2;
    2. 多字段排序 order by x1,x2 desc;先按前面的，再按后面的。x1升序，x2降序

16. mysql统计

    1. COUNT(*);
    2. SUM(*);
    3. GROUP BY;

17. mysql范式 bcnf

    1. 第一范式1NF（保证每个字段的值都具有原子性）
    2. 第二范式2NF（满足第一范式，且每一条数据都是可唯一标识的，所有非主键字段都必须完全依赖主键）
    3. 第三范式3NF（满足第二范式，确保数据表中所有非主键属性之间不能有依赖关系，必须相互独立）
    4. 巴斯科德范式BCNF（一个关系打到了第三范式，并且它只有一个候选键，或者它每个候选键都是单属性，则为巴斯克范式。**要在 3NF 的基础上消除**主属性**对于码的部分与传递函数依赖。**）
    5. 第四范式4NF
    6. 第五范式5NF(完美范式)

18. mysql索引与B+树

    1. 索引
       1. 数据结构：B+树索引、Hash索引、Full-text索引
       2. 物理存储：聚簇索引（主键索引），辅助索引（二级索引）
       3. 字段特性：主键索引、唯一索引、普通索引、前缀索引
       4. 字段个数：单列索引、联合索引
    2. B+树
       1. 为什么使用B+树作为索引？
          1. B+树的非叶子节点不存放实际的记录数据，仅存放索引，相比既存放索引又存放记录的B树，B+树一个数据页中可以存放更多的索引，因此B+树的高度更低，查询底层节点的I/O次数会更少
          2. B+树有大量的冗余节点（所有叶子节点都是冗余节点），这些冗余索引让B+树在插入和删除的时候不容易像B树那样频繁地需要调整树的结构，效率更高。
          3. B+树的叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，只能通过树的遍历来完成。
    3. 优化索引的方法：
       1. 主键索引最好自增
       2. 索引列最好设为NOT NULL
       3. 前缀优化
       4. 覆盖索引

19. 周六周日看mysql和redis

    1. mysql
       1. mysql事务：ACID，原子性、一致性、隔离性、持久性
    2. redis
       1. Redis利用队列技术将并发访问变为串行访问，消除传统数据库串行控制的开销。

20. IO多路复用的理解

    1. 单个进程/线程可以同时处理多个I/O请求。
    2. 一个进程/线程可以监视多个文件句柄，一旦某个文件句柄就绪，就可以通知应用程序进行相应的读写操作
    3. 还需要继续学
    4. select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。
       所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
       poll基本原理与 select 一致，也是轮询+遍历。唯一的区别就是 poll 没有最大文件描述符限制(使用链表的方式存储 fd)。
    5. 第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
       第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。
    6. 边缘触发：边缘触发是指在事件状态发生变化的时刻触发一次，例如从无事件变为有事件。在I/O多路复用中，**边缘触发意味着当某个文件描述符发生I/O事件（如变为可读或可写）时**，我们只会收到一次通知。当收到通知后，我们需要处理该文件描述符上的所有数据，直到数据全部处理完毕，否则不会再收到通知。
       1. **边缘触发的优点是只在事件状态改变时触发，可以减少事件通知的次数。然而，边缘触发的缺点是我们需要确保在收到通知后处理所有相关数据，否则可能会遗漏某些事件**。
    7. 条件触发：条件触发是指只要事件状态保持满足某种条件，就会持续触发。在I/O多路复用中，**条件触发意味着只要某个文件描述符的I/O事件状态满足条件（如可读或可写）**，我们就会不断收到通知。
       1. **条件触发的优点是它可以确保我们不会遗漏任何事件，因为只要条件满足，就会持续触发。然而，条件触发的缺点是它可能导致大量的事件通知，从而增加处理开销。**

21. 数据特别多的集合查找中位数

    1. 两个堆，最小堆和最大堆

    2. 首先要保证数据平均分配到两个堆中，因此两个堆中数据的数目之差不能超过1。为了实现平均分配，可以在数据的总数目是偶数时把新数据插入最小堆，否则插入最大堆。

       为了防止偶数时插入最小堆的数据比最大堆的一些数据小，我们可以先把这个数据插入最大堆，接着把最大堆中最大的数字拿出来插入最小堆。奇数时同理。

       我们用STL中的函数push_heap、pop_heap以及vector实现堆。比较仿函数less和greater分别用来实现最大堆和最小堆。

    3. 或者用二进制来写判断？如果最高位为1那就写入file1，否则写入file2。然后看中位数在哪里

22. n个有序数组找到相同的数

    1. 二分法？
       1. 对一个基准数组，遍历它，使用二分法查找其他数组里面是否有对应的数据
    2. 归并思想

23. 如何设计一个线程池？

    1. 任务队列：用于存储待执行的任务
    1. 线程池管理器：用于创建、管理和调度线程
    1. 线程执行器：
    1. 同步机制：
    5. 如何创建：
       1. 构造函数：
          1. 在构造函数中，线程池会创建指定数量的工作线程，每个工作线程都是一个无限循环，不断从任务队列里取出任务执行。
          2. 通过 `std::condition_variable` 来实现等待任务的机制，如果任务队列为空，则工作线程会被阻塞，直到有新的任务加入。
       2. 任务添加函数：
          1. `enqueue` 函数用于将任务添加到任务队列中。
          2. 使用了模板函数，支持不同参数类型和返回类型的任务。
          3. 使用 `std::packaged_task` 封装任务，并将其添加到任务队列。
          4. 通过 `std::unique_lock` 对 `queue_mutex` 加锁，保证对任务队列的操作是线程安全的。
          5. 使用 `std::condition_variable` 通知等待中的工作线程有新的任务可执行。
       3. 析构函数：
          1. 析构函数首先设置 `stop` 为 `true`，表示线程池要停止。
          2. 通过 `std::condition_variable` 的 `notify_all` 通知所有等待中的工作线程，让它们可以退出循环。
          3. 使用 `std::thread::join` 等待所有工作线程执行完毕

24. 分治的思想

    1. 将一个规模为N的问题分解为K个规模较小的子问题，子问题相互独立且与原问题性质相同

25. 同步和异步

    1. 同步：一个进程在执行某个请求的时候，如果这个请求需要一段时间才返回信息，那么这个进程会一直等待下去，知道收到信息后才继续执行下去。
    2. 异步：无需等待

26. 并发

    1. 一个时间段有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行，但是任意一个时间点上只有一个程序在处理机上运行。

27. 并行

    1. 并行是指两个或者多个事件在同一时刻发生

28. unordered_map和map的区别，vector和list的区别

    1. `map`和`unordered_map`这两种字典结构都是通过键值对（key-value）存储数据的，键（key）和值（value）的数据类型可以不同。且它们的**key是唯一的**。

    2. unordered_map的散列空间会存在部分未被使用的位置，所以其内存效率不是100%的。而map的红黑树的内存效率接近于100%。

    3. map的查找类似于平衡二叉树的查找，其性能十分稳定。例如在1M数据中查找一个元素，需要多少次比较呢？20次。map的查找次数几乎与存储数据的分布与大小无关。而unordered_map依赖于散列表，如果哈希函数映射的关键码出现的冲突过多，则最坏时间复杂度可以达到是O(n)。因此unordered_map的查找次数是与存储数据的分布与大小有密切关系的，它的效率是不稳定的。

    4. map元素有序，性能较为稳定。适用于**元素要求有序、或者对单次查询时间较为敏感，必须保持查询性能的稳定性，比如实时应用。**

       unordered_map查询速度快O(1)，但是元素无序、查询性能不稳定（最坏为O(n)）。**适用于要求查询速率快，对单次查询性能要求不敏感。**

    5. map：

       1. map可以将任何基本类型包括STL容器映射到任何基本类型，map会以键从小到大的顺序自动排序
       2. map是红黑树实现的，因此在map中的元素排列都是有序的。对map的增删改查复杂度都为logn，n即为红黑树的高度
       3. map的红黑树实现：直接内部封装一个红黑树，插入的是pair

    6. unordered_map

       1. 基于哈希表实现的，使得插入和查询的速度接近于1，但是内部元素的排列顺序是无序的。

    7. [vector](https://so.csdn.net/so/search?q=vector&spm=1001.2101.3001.7020)和数组相似，内存空间是连续的，并且地址不变；list是双向链表实现的，内存空间是不连续的。

    8. vector能进行高效的随机存取操作，[时间复杂度](https://so.csdn.net/so/search?q=时间复杂度&spm=1001.2101.3001.7020)为O(1);list是通过指针访问数据，不能随机访问，时间复杂度为O(n)。

    9. vector因地址时连续的，进行插入和删除操作时会进行内存块的拷贝复制，时间复杂度是O(n)；list是非连续的存储结构可以进行快速的插入和删除操作。

29. 红黑树：

    1. 每个结点要么是黑色要么是红色
    2. 根节点是黑色
    3. 每个叶子节点都是黑色，且为空节点
    4. 如果一个节点为红色，那么子节点为黑色
    5. 从一个节点到叶子节点的所有路径包含相同数量的黑节点。
    6. 左旋和右旋：
       1. 左旋时候，右节点变成新的父节点，原来的父节点变为新父节点的左子节点。
       2. 右旋时候，左节点变为新的父节点，原来的父节点变为新父节点的右子节点。

30. 手写实例模式（static？）（懒汉模式，线程安全，效率高）

    1. 饿汉模式：![image-20231024105929633](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\image-20231024105929633.png)

    2. 懒汉1：![image-20231024105944800](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\image-20231024105944800.png)

    3. 懒汉2：![image-20231024110042196](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\image-20231024110042196.png)
       1. 需要C++11支持（C++11保证static成员初始化的线程安全）

       2. 性能问题（同懒汉模式一样，每次调用GetInstance()方法时需要判断局部static变量是否已经初始化，如果没有初始化就会进行初始化，这个判断逻辑会消耗一点性能）

       3. 静态成员:构造的时候是会锁其他线程(线程安全)。访问 [static](https://so.csdn.net/so/search?q=static&spm=1001.2101.3001.7020) 的其他成员是没有锁的(线程不安全)。

31. C++11

    1. 智能指针
       1. auto
       1. unique
       1. shared
       1. weak

32. TCP连接中的心跳包

    1. 在[长连接](https://so.csdn.net/so/search?q=长连接&spm=1001.2101.3001.7020)下，可能很长一段时间都没有数据往来。理论上说，这个连接是一直保持连接的，但是实际情况中，如果中间节点出现什么故障是难以知道的。更致命的是，有的节点（防火墙）会自动把一定时间之内没有数据交互的连接给断掉。这个时候，就可以使用心跳包，来维持长连接以及保活

       心跳机制就是每隔几分钟发送一个固定信息给服务端，服务端收到后回复一个固定信息如果服务端几分钟内没有收到客户端信息则视客户端断开。发包方可以是客户也可以是服务端，具体看哪边实现更方便合理

       [心跳包](https://so.csdn.net/so/search?q=心跳包&spm=1001.2101.3001.7020)的发送通常有以下两种技术：

       1. ### 应用层自已实现的心跳包：

          由应用程序自己发送心跳包来检测连接是否正常，服务器每隔一定时间向客户端发送一个短小的数据包，然后启动一个线程，在线程中不断检测客户端的回应， 如果在一定时间内没有收到客户端的回应，即认为客户端已经掉线；同样，如果客户端在一定时间内没有收到服务器的心跳包，则认为连接不可用

       2. ### 使用SO_KEEPALIVE套接字选项：

          在TCP的机制里面，本身是存在有心跳包的机制的，也就是TCP的选项. 不论是服务端还是客户端，一方开启KeepAlive功能后，就会自动在规定时间内向对方发送心跳包， 而另一方在收到心跳包后就会自动回复，以告诉对方我仍然在线

33. 操作系统的堆和栈

    1. https://www.cnblogs.com/ldcs/p/11822920.html

    2. ### 主要区别如下：

       #### 一、空间分配：

         1.堆（操作系统）：一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收，分配方式类似于链表。PS：java中都是系统GC，程序员无法进行GC。

         2.栈（操作系统）：由操作系统自动分配释放，存放函数的参数值，局部变量值等。操作方式与数据结构中的栈相类似。

       #### 二、缓存方式：

         1.堆：使用二级缓存，生命周期与虚拟机的GC算法有关（并不是引用为空就立即被GC），调用速度相对较低。

         2.栈：使用一级缓存，被调用时通常处于存储空间中，调用后被立即释放。

       ####  三、数据结构：

         1、堆（数据结构）：类似于树结构，可以类比于堆排序

         2、栈（数据结构）：先进后出（FILO）

34. UDP怎么保证可靠性

    1. 

35. TCP的字节流和UDP的报文有什么差别？（粘滞？）

    1. 面向字节流是以字节为单位[发送数据](https://so.csdn.net/so/search?q=发送数据&spm=1001.2101.3001.7020)，并且一个数据包可以以字节大小来拆分成多个数据包，以方便发送。
    2. UDP需要每次发送都需要发送固定长度的数据包，如果长度过长 需要应用层协议 主动将其裁剪到适合长度。
    3.  面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。UDP对应用层交下来的报文，即不合并，也不拆分，而是保留这些报文的边界。这就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。
    4. 面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。

36. class Singleton{

    public:

      Singleton* instance = nullptr;

      static Singleton getInstance(){

    ​    if(instance == nullptr)

    ​      instance = new Singleton();

    ​    return instance;

      }

      void Print(){

    ​    cout << instance;

      }

    private:

      Singleton(){}

      ~Singleton(){}

    }

    这段代码有什么错误？

37. 快速排序也得看一下怎么写？

    1. ```
       if(l > r){
           return;
       }
       int temp = v[l];
       int left = l;
       int right = r;
       while(left < right){
           while(v[right] <= temp && right > left) {
               right--;
           }
           if(left < right){
               v[left++] = v[right];
           }
           while(v[left] >= temp && left < right){
               left++;
           }
           if(left < right){
               v[right--] = v[left];
           }
       }
       v[left] = temp;
       quickSort(v,l,left-1);
       quickSort(v,left+1,r);
       ```

38. 二分查找

39. 操作系统的零拷贝

    1. "零拷贝"中的"拷贝"是指操作系统在I/O操作中,将数据从一个内存区域复制到另外一个内存区域，而"零"并不是指0次复制, 更多的是指在用户态和内核态之间的复制是0次。

    2. • 减少甚至完全避免不必要的 CPU 拷贝，从而让 CPU 解脱出来去执行其他的任务；

       • 减少内存带宽的占用；

       • 通常零拷贝技术还能够减少用户空间和操作系统内核空间之间的上下文切换。

    3. read-send模型：

       1. 应用程序开始读文件的操作；

       2. 应用程序发起系统调用, 从用户态切换到内核态(第一次上下文切换)；
       3. 内核态中把数据从硬盘文件读取到内核中间缓冲区(kernel buf)；
       4. 数据从内核中间缓冲区(kernel buf)复制到(用户态)应用程序缓冲区(app buf),从内核态切换回到用户态(第二次上下文切换)；
       5. 应用程序开始发送数据到网络上；
       6. 应用程序发起系统调用,从用户态切换到内核态(第三次上下文切换)；
       7. 内核中把数据从应用程序(app buf)的缓冲区复制到socket的缓冲区(socket)；
       8. 内核中再把数据从socket的缓冲区(socket buf)发送的网卡的缓冲区(NIC buf)上；
       9. 从内核态切换回到用户态(第四次上下文切换)。
       10. ![v2-4339abe8f90eaf8ccc294907283a43a2_720w](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\v2-4339abe8f90eaf8ccc294907283a43a2_720w.webp)

    4. 其中涉及到2次 CPU 中断, 还有4次的上下文切换。很明显,第2次和第3次的的 copy 只是把数据复制到 app buffer 又原封不动的复制回来, 为此带来了两次的 CPU COPY 和两次上下文切换, 是完全没有必要的。

    5. Linux 的零拷贝技术就是为了优化掉这两次**不必要的拷贝。**

    6. 第一种零拷贝的IO流程：

       1. **Linux 内核2.1**开始引入一个叫 sendFile 系统调用,这个系统调用可以在内核态内把数据从内核缓冲区直接复制到套接字(SOCKET)缓冲区内, 从而可以减少上下文的切换和不必要数据的复制。

       2. 应用程序开始读文件的操作；

       3. 应用程序发起系统调用, 从用户态切换到内核态(第一次上下文切换)；
       4. 内核态中把数据从硬盘文件读取到内核中间缓冲区；
       5. 通过 sendFile,在内核态中把数据从内核缓冲区复制到socket的缓冲区；
       6. 内核中再把数据从 socket 的缓冲区发送的网卡的 buf 上；
       7. 从内核态切换到用户态(第二次上下文切换)。
       8. ![v2-c5b255c1c42e195f32c4afc3cb82a26b_r](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\v2-c5b255c1c42e195f32c4afc3cb82a26b_r.jpg)

    7. 第二种零拷贝的IO流程：

       1. 支持 scatter-gather 特性的 sendFile 的 IO 流程：

       2. **Linux在内核2.4**以后的版本中, Linux 内核对 socket 缓冲区描述符做了优化。通过这次优化, sendFile  系统调用可以在只复制 kernel buffer 的少量元信息的基础上, 把数据直接从 kernel buffer 复制到网卡的 buffer  中去，从而避免了从"内核缓冲区"拷贝到"socket缓冲区"的这一次拷贝。

       3. 应用程序开始读文件的操作；

       4. 应用程序发起系统调用, 从用户态进入到内核态(第一次上下文切换)；
       5. 内核态中把数据从硬盘文件读取到内核中间缓冲区；
       6. 内核态中把数据在内核缓冲区的位置(offset)和数据大小(size)两个信息追加(append)到socket的缓冲区中去；
       7. 网卡的buf上根据socekt缓冲区的offset和size从内核缓冲区中直接拷贝数据；
       8. 从内核态返回到用户态(第二次上下文切换)；
       9. ![v2-b72230f321d142066a2bad52c8e0f3c4_720w](H:\GitHub\blog_1\hexo-kidimos\source\_posts\assets\v2-b72230f321d142066a2bad52c8e0f3c4_720w.webp)
       10. 最后数据拷贝变成只有两次 **DMA COPY:**
           1. 硬盘拷贝到内核缓冲区(DMA COPY)；
           2. 内核缓冲区拷贝到网卡的 buf(DMA COPY)。


1. mysql里面什么样的适合用索引？

   1. 字段的数据有唯一性的限制

   2. 频繁作为WHERE查询条件的字段

   3. 经常GROUP BY和ORDER BY的列

   4. **UPDATE、DELETE** **的** **WHERE** **条件列**

   5. **DISTINCT** **字段需要创建索引**（去重）

   6.  **多表** **JOIN** **连接操作时，创建索引注意事项**

   7. **使用列的类型小的创建索引**

   8. **使用字符串前缀创建索引**

   9. **区分度高(散列性高)的列适合作为索引**

   10. **使用最频繁的列放到联合索引的左侧**

   11. **在多个字段都要创建索引的情况下，联合索引优于单值索引**

2. 计算机网络中TCP中，保证可靠性的措施是什么？

   1. TCP三次握手保证接受和发送的能力

   2. 字节流传输：TCP采用字节流传输的方式，将应用层发送的数据划分成以字节为单位的报文段，并进行序列号标记，以确保数据传输的有序性。

   3. 确认重传机制：接收方收到报文段后，都会进行确认(Ack)操作。如果发送方没有收到确认，则会重新传送该报文。

   4. 头部校验和：在TCP传输过程中，每个报文段都会添加一个头部校验和，以检测数据在传输过程中是否损坏或者被篡改。如果发现数据损坏，则会进行重传，以确保数据的完整性和准确性。

3. 进程和线程

   1. **什么是进程**

      先给一个定义：进程是一个具有一定独立功能的程序在一个数据集合上依次动态执行的过程。进程是一个正在执行的程序的实例，包括程序计数器、寄存器和程序变量的当前值。

      **进程有哪些特征？**

      进程依赖于程序运行而存在，进程是动态的，程序是静态的；

      进程是操作系统进行资源分配和调度的一个独立单位（CPU除外，线程是处理器任务调度和执行的基本单位）；

      每个进程拥有独立的地址空间，地址空间包括代码区、数据区和堆栈区，进程之间的地址空间是隔离的，互不影响。

   2. 什么是线程

   3. **进程与线程的区别总结：**

      - **本质区别：**进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
      - **包含关系：**一个进程至少有一个线程，线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
      - **资源开销：**每个进程都有独立的地址空间，进程之间的切换会有较大的开销；线程可以看做轻量级的进程，同一个进程内的线程共享进程的地址空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
      - **影响关系：**一个进程崩溃后，在保护模式下其他进程不会被影响，但是一个线程崩溃可能导致整个进程被操作系统杀掉，所以多进程要比多线程健壮。

4. http如何预防重放和中间人

   1. 重放：

      1. 时间戳+随机数+签名

      2. 基于timestamp解决方案

         1.一次正常的http请求，响应时间一般在5s内完成，基本上不会超过60s，我们根据自己接口的响应时间设置阈值
          2.客户端每次发起请求，携带当前时间戳
          3.服务端接收请求后，我们校验客户端时间戳与服务端时间戳的差值，超过了60s既认为是重播攻击

      3. 基于nonce解决方案

         1. 1.客户端每次发起请求，都需要携带uuid（要求唯一即可）

            2. 服务端接收到请求后，先校验用户携带的uuid是否存在，不存在：将uuid存储到数据库或缓存服务器中，存在：既认为是重播攻击

            总结：实现简单有效，但随着请求量越多，存储的数据会越来越大。

      4. 三、基于timestamp和nonce解决方案

         总结：结合以上两种方案，并定期清理缓存。

   2. 中间人：

      1. 不对称加密

      2. CA证书

5. 分布式的共识算法？？？

6. HTTP的各个版本与状态码

   1. HTTP常见的状态码

      1. `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。
         1. 200 OK：是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。

         2. 204 No Content:也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据

      2. `3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。
         1. 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。

         2. 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

         3. 

      3. `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。
         1. 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。

         2. 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。

         3. 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

      4. `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。
         1. 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。

         2. 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

         3. 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。

         4. 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

   2. HTTP的各个版本

      1. Http1.0

         1. 默认使用无连接，每次请求都需要与服务器建立一个TCP连接，服务器处理完成后立刻断开TCP连接，服务器不跟踪每个客户端也不记录过去的请求。（无连接/无状态）

      2. Http1.1

         1. 默认使用长连接，避免了连接建立和释放的开销。通过Content-Length字段来判断当前请求的数据是否已经全部接受。不允许同时存在两个并行的响应。

         2. 持久连接的特点：

            1. 持久连接也称为Http keep-alive，只要任意一端没有明确提出断开连接，则保存TCP连接状态。

               减少了TCP连接的重复建立和断开所造成的额外开销，减去了服务器端的压力。

               持久连接使得多数请求以管线化方式（pipelining）成为可能。可以同时并行发送多个请求，而不需要一个接一个的等待响应了。（请求打包一次传输过去，响应打包一次传递回来），管线化的前提是在持久连接下。

            2. **Http1.1缺陷**

               （1）高延迟，带来页面加载速度的降低。（网络延迟问题只要由于队头阻塞，导致宽带无法被充分利用）

               （2）无状态特性，带来巨大的Http头部。

               （3）明文传输，不安全。

               （4）不支持服务器推送消息。

      3. Http2.0

         1. 主要：提高了效率，在用户与网站直接只用一个连接，并且服务器可以推送。

         2. 2009年谷歌公开了SPDY协议，主要解决Http1.1效率不高的问题。

         3. SPDY被当做HTTP2.0的基础，其主要特性（兼容老版本HTTP协议，同时可以使用SSL功能）都在HTTP2.0中得到继承。

            HTTP2.0：**基于SPDY**，专注于性能，目标是**在用户和网站直接只用一个连接**。

         4. 二进制传输

            1. http2.0将请求和响应数据分割为更小的帧，并且它们采用二进制编码(http1.0基于文本格式)。多个帧之间可以乱序发送，根据帧首部的流表示可以重新组装。

         5. Header压缩

            1. Http2.0开发了专门的“HPACK”算法，大大压缩了Header信息。

         6. 多路复用

            1. http2.0中引入了多路复用技术，很好的解决了浏览器限制同一个域名下的请求数量的问题。

               多路复用技术可以只通过一个TCP链接就可以传输所有的请求数据。

         7. 服务端推送

            1. HTTP2.0在一定程度上改不了传统的“请求-应答”工作模式，服务器不再完全被动地响应请求，也可以新建“流”主动向客户端发送消息。（例如，浏览器在刚请求html的时候就提前把可能会用到的JS，CSS文件发送给客户端，减少等待延迟，这被称为“服务端推送Server Push”）

               服务器也不能随便将第三方资源推送给服务器，必须经过双方确认。

      4. Http3.0

         1. Google在推行SPDY的时候意识到了上述http2.0一系列问题，于是又产生了**基于UDP协议的“QUIC”协议**，让HTTP跑在QUIC上而不是TCP上。从而产生了HTTP3.0版本，它**解决了“队头阻塞”的问题**。

         2.     特点：

            （1）实现了类似TCP的流量控制，传输可靠性的功能。

            （2）实现了快速握手功能（QUIC基于UDP，UDP是面向无连接的，不需要握手和挥手，比TCP快）

            （3）集成了TLS加密功能

            （4）多路复用，彻底解决TCP中队头阻塞的问题（单个“流”是有序的，可能会因为丢包而阻塞，但是其他流不会受到影响）

      5. 还是得看图解网络

7. mysql的四个特性的原理

   1. ACID：原子性/一致性/隔离性/持久性
   2. 原子性：
      1. 回滚 

      2. undo log

      3. 一个事务内的sql语句要么全部执行，要么全不执行，是通过undo log原理实现的。

   3. 一致性：
      1. 通过原子性/隔离性/持久性来保证的

      2. 一致性是指事务执行之后，数据库的完整性约束没有被破坏，事务执行前后都是一个合法的数据状态。他的完整性主要体现在数据库主键要唯一，字段的类型、大小、长度、外键约束要符合要求。一致性是事务追求的最终目标，ACID中三种特性都是为了实现最终的一致性。

   4. 隔离性：
      1. 锁和MVCC
      2. 写写操作通过锁解决。写读通过MVCC（多版本控制，主要是通过undo log找到旧版本）
      3. 隔离级别
   5. 持久性：
      1. 概念：持久性是指一个事务一旦提交，它对数据库的改变是永久性的。持久性也是通过一个log来实现，它叫redo log。

      2. mysql突然挂了，数据还没来得及写入磁盘怎么办？

      3. 通过redo log保证的

      4. 当数据库的数据要进行新增或修改的时候，除了修改Buffer中的数据，还要把这次的操作记录到redo log里面。如果MySQL宕机了，还可以从redo log恢复数据。redo log是一个预写式日志，指它会将所有的修改先写入到日志里面，再更新到Buffer里面（笔者认为此思想与Java更新缓存的方式相通，都是先写库再更新缓存），保证了数据不会丢失。

8. mysql的更新操作是怎么实现的？

   1. update

   2. replace：REPLACE语句会先删除表中已有的数据，再插入新的数据。

   3. 过程： update users set name=‘小张’ where id=1

      1. 到存盘上找到需要更新的数据，比如数据为 id=1，name=小李，将数据放到缓存池中（Buffer Pool）

      2. 将查询出来的值（ id=1，name=小李）写到undo日志文件中，目的是后期数据回滚，先将原来值记录下来，回滚的时候就从该日志中取出来，以后会相信分享undo日志详细内容

      3. 更新Buffer Pool中的值，改为name由小李-》小张

      4. 写到将更新操作记录一下，写到Redo log buffer（内存）中

      5. Redo log buffer中的数据持久化到磁盘Redo log文件中，这个时候就算是更新成功了，为什么要用Redo log，以及带来的好处，后续会分享，现在主要了解到整体的流程就行。

      6. 写入binlog日志，binlog实际上是对哪个数据做了什么修改，和Redo log buffer类似，也是有刷盘策略：sync_binlog和innodb_flush_log_at_trx_commit类似

      7. 将binlog的记录写入到Redo日志中，为什么要做个标记呢？

         用来保持redo log日志与binlog日志一致的。必须是在redo  log中写入最终的事务commit标记了，然后此时事务提交成功，而且redo log里有本次更新对应的日志，binlog里也有本次更新对应的日志 ，redo log和binlog完全是一致的，这个时候我们才认为是提交成功的

      8. 异步IO线程将修改后的数据刷到磁盘文件中

      9. https://betheme.net/news/txtlist_i100199v.html?action=onClick

9. redis

10. 逻辑地址和物理地址

    1. 

11. C++11智能指针

    1. auto_ptr

       1. auto_ptr时C++98时就引入的智能指针，auto_ptr通过管理权转移的方式解决了智能指针的拷贝问题，保证资源在任何时刻都只有一个对象在进行管理，这样一个对象就不会被多次释放了

       2. 但是一个对象转移了管理权限也就意味着其不能管理原来的资源并进行访问了，否则程序就会崩溃，因此使用auto_ptr前必须了解其的机制，否则程序很容易出问题，很多公司明确禁止使用auto_ptr

    2. shared_ptr

       1. shared_ptr 也是C++11引入的智能指针，shared_ptr 通过引用计数的方式解决了智能指针拷贝问题，只有一个资源对应的引用计数减为0才会释放资源，因此保证了同一个资源不会被释放多次

       2. 引用计数为何要放在堆区

       3. **因为引用计数并不是单单属于一个对象的**，所以不能使用int类型的成员变量。**而引用计数也并不是属于类的**，所以也不能使用static静态成员变量，**引用计数是属于所有管理同一块区域的对象的**，我们想让这些对象可以看到同一个引用计数最简单的方法就是开辟一块空间，让所有符合条件的对象都看见

       4. 如何保证线程安全？

          1.  使用原子类atomic对引用计数进行封装
          2.  加锁

       5. ```cpp
          (*pcount)++;
          ```

    3. unique_ptr

       1. unique_ptr是C++11中引入的智能指针，unique_ptr通过防拷贝的方式解决了智能指针的拷贝问题。简单粗暴

    4. weak_ptr

       1. Shared_ptr看似非常成功，但是任然存在循环引用问题

       2. 比如链表：

          1. 双向链接
             1. node1和node2->next在管理第一块空间，node2和node1->next在管理第二块空间，两个的引用计数都为2，而每一个智能指针只会调用一次析构函数导致最终他们的引用计数还是1，导致本应该释放的空间没有释放
          2. 单向链接
             1. Node2 和 node1->next 共同管理第二块空间，而只有node1在管理第一块空间，函数结束调用node1和node2的析构函数，node1引用计数由1变零调用析构清理资源，由于next和prev都是自定义类型就会调用他们自己的析构函数来析构，node1->next调用析构函数导致第一块空间的引用计数为1，node2再调用其的析构函数就能将空间全部释放了。这就是为什么只进行一个链接操作时两个节点都能够释放的原因

       3. ##### std::weak_ptr解决循环引用问题

          1. weak_ptr支持用shared_ptr对象来构造weak_ptr对象，构造出来的weak_ptr和shared_ptr对象共同管理同一个资源，但不会增加这块资源的引用计数
          2. 将s_ListNode中的next和prev类型替换成weak_ptr就不会导致循环引用问题了，当node1和node2两个生命周期结束时引用计数都为零，进而释放两个节点的资源

12. http的keep alive

    1. 我们知道 HTTP 协议采用 **请求-应答**  模式，当使用普通模式，即非 KeepAlive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成 之后立即断开连接（HTTP  协议为无连接的协议）；当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服  务器端的连接持续有效，当出现对服务器的后继请求时，Keep- Alive 功能避免了建立或者重新建立连接。

       http 1.0 中默认是关闭的，需要在 http 头加入 `Connection: Keep-Alive`，才能启用 Keep-Alive；http 1.1 中默认启用 Keep-Alive，如果加入 `Connection: close`，才关闭。目前大部分浏览器都是用 http 1.1 协议，也就是说默认都会发起 Keep-Alive 的连接请求了，所以是否能完成一个完整的 Keep- Alive 连接就看服务器设置情况。

13. 协程


    1. 


### 亿联网络

1. C++11有哪些内容？

   1. 统一的列表初始化
   2. 右值引用和移动语义
   3. 新的类功能
   4. 可变模板参数
   5. lambda表达式
   6. 包装器
   7. 线程库

2. 智能指针介绍一下

   1. auto_ptr

      1. auto_ptr时C++98时就引入的智能指针，auto_ptr通过管理权转移的方式解决了智能指针的拷贝问题，保证资源在任何时刻都只有一个对象在进行管理，这样一个对象就不会被多次释放了

      2. 但是一个对象转移了管理权限也就意味着其不能管理原来的资源并进行访问了，否则程序就会崩溃，因此使用auto_ptr前必须了解其的机制，否则程序很容易出问题，很多公司明确禁止使用auto_ptr

   2. shared_ptr

      1. shared_ptr 也是C++11引入的智能指针，shared_ptr 通过引用计数的方式解决了智能指针拷贝问题，只有一个资源对应的引用计数减为0才会释放资源，因此保证了同一个资源不会被释放多次

      2. 引用计数为何要放在堆区

      3. **因为引用计数并不是单单属于一个对象的**，所以不能使用int类型的成员变量。**而引用计数也并不是属于类的**，所以也不能使用static静态成员变量，**引用计数是属于所有管理同一块区域的对象的**，我们想让这些对象可以看到同一个引用计数最简单的方法就是开辟一块空间，让所有符合条件的对象都看见

      4. 如何保证线程安全？

         1.  使用原子类atomic对引用计数进行封装
         2.  加锁

      5. ```cpp
         (*pcount)++;
         ```

   3. unique_ptr

      1. unique_ptr是C++11中引入的智能指针，unique_ptr通过防拷贝的方式解决了智能指针的拷贝问题。简单粗暴

   4. weak_ptr

      1. Shared_ptr看似非常成功，但是任然存在循环引用问题

      2. 比如链表：

         1. 双向链接
            1. node1和node2->next在管理第一块空间，node2和node1->next在管理第二块空间，两个的引用计数都为2，而每一个智能指针只会调用一次析构函数导致最终他们的引用计数还是1，导致本应该释放的空间没有释放
         2. 单向链接
            1. Node2 和 node1->next 共同管理第二块空间，而只有node1在管理第一块空间，函数结束调用node1和node2的析构函数，node1引用计数由1变零调用析构清理资源，由于next和prev都是自定义类型就会调用他们自己的析构函数来析构，node1->next调用析构函数导致第一块空间的引用计数为1，node2再调用其的析构函数就能将空间全部释放了。这就是为什么只进行一个链接操作时两个节点都能够释放的原因

      3. ##### std::weak_ptr解决循环引用问题

         1. weak_ptr支持用shared_ptr对象来构造weak_ptr对象，构造出来的weak_ptr和shared_ptr对象共同管理同一个资源，但不会增加这块资源的引用计数
         2. 将s_ListNode中的next和prev类型替换成weak_ptr就不会导致循环引用问题了，当node1和node2两个生命周期结束时引用计数都为零，进而释放两个节点的资源

3. NULL和nullptr的区别

   1. NULL属于C语言中的宏，nullptr是C++11后引入的关键字，都用来表示空指针
   2. NULL在C++程序中容易引起二义性，因为NULL宏定义为0。（例子，重载函数func(NULL)，有隐式类型转换，(void*)0可能隐式转换到int或char*）
   3. 在表示指针的地方，使用nullptr表示空指针，尽量不使用NULL（引入nullptr解决调用不明确的问题）
   4. C语言不会产生NULL的二义性，因为C语言不支持函数重载

4. push_back和emplace_back的区别

   1. 他们的作用都是往容器尾部插入一个元素

   2. 不同点：

      1. 与push_back不同的是，emplace_back可以接受可变参数。
      2. emplace_back只会调用一次构造函数，不会在原地构造完后再次调用拷贝构造函数
      3. emplace_back的优势：可以避免创建临时对象，造成性能损失

   3. 不同的例子：

      1. push_back

         1. 传入右值：

            1. ```c++
               v.push_back(BaseClass("b3",1));
               ```

               

            2. 调用构造函数，构造出右值A

            3. 调用move构造函数，copy数据到vector的数据空间的对象B

            4. 在参数声明周期结束后，调用A的析构函数

         2. 传入左值

            1. ```c++
               BaseClass b("b3",1);
               v.push_back(b4);
               ```

               

            2. 调用构造函数，构造出右值A

            3. 调用move构造函数，copy数据到vector的数据空间的对象B

            4. 在参数声明周期结束后，调用A的析构函数

      2. emplace_back

         1. 上面两种方法，如果直接把push_back换成emplace_back，本质上没有任何区别

         2. 但是emplace_back支持另一种调用方式:

         3. ```
            v.emplace_back("b1",1);
            ```

         4. 上面的操作会直接简化成为：

            1. 调用构造函数，在vector指定的地址生成对象A

         5. 因为emplace_back传入的右值引用，所以传入右值，不会发生拷贝，可以直接在指定的内存创建。

      3. 不同点汇总：

         1. 两者都支持右值引用
         2. 是否一定会发生拷贝构造：push是，emplace不是
         3. 是否支持直接传入多个构造参数：push支持一个，emplace支持多个
         4. 是否支持原地构造:push不支持，emplace支持
         5. 原地构造的时候，emplace可以省去拷贝构造的过程。

5. 进程线程区别

   1. 本质区别：进程是操作系统资源分配的基本单位，线程是处理器任务调度和执行的基本单位
   2. 包含关系：一个进程至少有一个线程，线程是进程的一部分，所以线程也被叫做轻权进程或者轻量级进程
   3. 资源开销：每个进程都有独立的地址空间，进程之间的切换会有较大的开销；线程可以看做轻量级进程，同一个进程内的线程共享进程的地址空间，每个进程都有自己独立的运行栈和程序计数器，线程之间切换的开销小
   4. 影响关系：一个进程崩溃后，在保护模式下其他进程不会被影响，但是一个线程崩溃可以导致整个进程被操作系统杀死，所以多进程比多线程健壮。

6. 多路复用的难点

   1. ？明天再看看
   2. 和阻塞IO和非阻塞对比一下

7. 如何避免内存泄露

   1. 动态分配的内存未能释放或者无法释放，会造成系统内存的浪费，甚至导致系统崩溃

   2. new和malloc要配对,delete[]或delete

   3. 不要手动管理内存，在适当的时候使用智能指针

   4. **指向对象的指针数组不等同于对象数组**

      　　对象数组是指：数组中存放的是对象，只需要delete [ ] p，即可调用对象数组中的每个对象的析构函数释放空间

         　　指向对象的指针数组是指：数组中存放的是指向对象的指针，不仅要释放每个对象的空间，还要释放每个指针的空间，delete [ ] p只是释放了每个指针，但是并没有释放对象的空间，正确的做法，是通过一个循环，将每个对象释放了，然后再把指针释放了。

   5. 使用容器类

   6. 注意异常处理

8. 内存泄露和指针越界如何检测

   1. 使用的时候注意指针的长度，防止越界
   2. 1). 使用的时候要记得指针的长度. 2). malloc的时候得确定在那里free. 3). 对指针赋值的时候应该注意被赋值指针需要不需要释放. 4). 动态分配内存的指针最好不要再次赋值. 5). 在C++中应该优先考虑使用智能指针.

9. 父进程与子进程间的关系

   1. 子进程得到的除了代码段是与父进程共享外，其他所有的都是得到父进程的一个副本。
   2. 两者并不共享地址空间，两个是单独的进程，继承了之后两者就没有什么关联了，子进程单独运行（采用写时复制技术）
   3. fork创建
   4. 父进程中通过fork()函数可以创建子进程，如果返回值==0，为子进程；否则是为父进程。

10. TCP快重传，超时重传

    1. RTT Round-Trip Time 往返时延

    2. `RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

    3. 超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。

       假设在重传的情况下，超时时间 `RTO` 「较长或较短」时，会发生什么事情呢？

    4. **超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。

    5. 超时重传：

       1. 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**

          也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

          超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

          于是就可以用「快速重传」机制来解决超时重发的时间等待

    6. TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。

       快速重传机制，是如何工作的呢？其实很简单，一图胜千言。

    7. 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

    8. SACK 选择性确认，这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

    9. Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

11. MTU、MSS关系

    1. 明天还得看看

    2. mtu是网络传输最大报文包，mss是网络传输数据最大值。

    3. 1、mss加包头数据就等于mtu. 简单说拿TCP包做例子。  报文传输1400字节的数据的话，那么mss就是1400，再加上20字节IP包头，20字节tcp包头，那么mtu就是1400+20+20.  当然传输的时候其他的协议还要加些包头在前面，总之mtu就是总的最后发出去的报文大小。mss就是你需要发出去的数据大小。

       2、MSS: Maxitum Segment Size 最大分段大小 2.MSS最大传输大小的缩写，是TCP协议里面的一个概念。 3.MSS就是TCP数据包每次能够传输的最大数据分段。

       3、为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。

12. 进程的内存资源结构

    1. 代码区
    2. 数据区（已初始化全局变量，静态变量和常量数据）
    3. BSS区（未初始化全局变量）
    4. 堆区
    5. 栈区

13. C++函数调用过程是什么？

    1. 主要是一个函数压栈和出栈的过程
    2. 函数的压栈和出栈

       1. [C++ 函数压栈与出栈 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/642851340#:~:text=在C%2B%2B中，函数压栈（函数调用）和出栈（函数返回）是函数调用过程中的两个关键步骤。 下面将逐步解释这两个过程。,函数压栈（函数调用）的过程如下： 调用指令：在函数调用点，会发出一个调用指令（如call指令），将控制权转移到被调用函数的入口点。 保存返回地址：调用指令执行前，当前函数的返回地址会被压入栈中，以便在函数执行完毕后返回到正确的位置。)
       2. 函数压栈：
          1. 调用指令：在函数调用点，会发出一个调用指令，将控制权转移到被调用函数的入口点。
          2. 保存返回地址：当前函数的返回地址被压入栈中，以便哈桉树执行完毕后返回到正确的位置。
          3. 参数压栈：函数调用时，将函数的参数按照一定的顺序压入栈中，通常从右到左依次入栈。
          4. 保存寄存器值：在一些体系结构中，函数调用时需要保存一些寄存器的值，以便在函数执行完毕后能够恢复原始的寄存器状态，
          5. 帧指针与局部变量压栈：为了支持函数内的局部变量和堆栈的动态分配，通常在栈上维护一个帧指针，它指向当前函数的栈帧的底部。同时，函数内部定义的局部变量也会在栈上分配空间。
          6. 执行函数体
       3. 函数出栈：
          1. 恢复寄存器值：在一些体系结构中，函数返回时需要恢复之前保存的寄存器的值。
          2. 释放局部变量和帧指针：函数返回后，会释放函数内部定义的局部变量所占用的栈空间，并将帧指针恢复到上一层函数的栈帧。
          3. 弹出参数和返回地址：函数返回后，参数和返回地址会从栈中弹出，将控制权返回到调用函数的正确位置。

14. 链表和数组的区别？

    1. 数组支持随机访问，链表不支持
    2. 链表不连续，数组连续
    3. 增删效率不同

15. string不能被继承，因为他的析构函数不为virtual

16. reverse和resize区别

    1. **resize既分配了空间，也创建了对象，可以通过下标访问。当resize的大小**

       **reserve只修改capacity大小，不修改size大小，resize既修改capacity大小，也修改size大小。**

17. DHCP

18. DNS

19. docker

20. 动态链接、静态链接



## 米哈游

1. 手撕有重复数字的全排列（寄，只写出全排列，有重复数字的情况早忘了）

   1. res

   2. path

   3. used

2. 对vector了解多少,vector底层实现，占用内存是否一定连续

   1. resize，reverse
      1. reverse表示容器预留空间，但并不是真正的创建对象
      2. resize既分配了空间，也创建了对象。（修改size）
   2. 底层实现：三个指针，start、finish、endofstorage
   3. finish==endofstorage的时候进行扩容
   4. 额外申请一块内存空间，拷贝数据，然后删除原数据

3. vector如果加了上万个数据后又立马弹出去，vector容量会变化吗

   1. 不会

4. 深拷贝和浅拷贝

   1. 深拷贝
      1. 
   2. 浅拷贝
      1. 

5. vector数组引用传递和值传递的区别，哪一个是深拷贝，哪一个是浅拷贝

   1. 深拷贝拷贝的是数据本身，创建一个新的对象，新创建的对象与原对象不共享内存，修改新对象的值的时候，不会影响。
   1. 浅拷贝拷贝的是数据数据地址，只复制指向对象的指针，新老对象的指针指向的内存地址是一样的，修改新的会影响旧的。引用类型的变量，默认赋值就是浅拷贝。
   1. 值传递是将实参的值传给形参，形参是实参的一份拷贝，形参和实参的内存地址是不同的。
   1. 引用传递是指针，所以是浅拷贝

6. C++多态的实现（静态多态和动态多态，虚函数表）

   1. 通过虚函数表和虚函数指针来实现

7. 写一个例子实现静态多态和动态多态

   1. 动态多态

      1. > 1. 继承，多个子类一个父类
         > 2. 父类有虚函数，子类重写父类的虚函数
         > 3. 父类指针指向子类对象（一个函数，函数的形参是父类的指针，实参是子类对象的地址）

   2. 静态多态

      1. 直接重载

8. http tcp ip的区别

   1. IP协议是网络层的
   2. TCP协议是传输层的
   3. HTTP协议是应用层的
   4. DHCP是什么？
      1. 动态主机配置协议

9. tcp四次挥手

   1. FIN
   1. ACK
   1. FIN
   1. ACK

10. 解释下socket

    1. 套接字
    2. 是计算机之间进行通信的一种约定或者方式。起源于Unix，一切都是文件，所以socket是一种特殊的文件，一些socket函数就是对其进行的操作。
    3. 我的理解就是Socket就是该模式的一个实现：即socket是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭）。
    4. Socket()函数返回一个整型的Socket描述符，随后的连接建立、数据传输等操作都是通过该Socket实现的。
    5. ip地址、协议、端口
    6. 面向连接、无连接

11. 输入网络地址后到出现页面发生了什么

    1. HTTP
    2. DNS
    3. 协议栈
    4. TCP
    5. IP
    6. MAC
    7. 网卡、交换机、路由器
    8. 解包
    9. 过程：
       1. 浏览器做的第一步工作是对URL进行解析，从而生成发送给Web服务器的请求信息。
       2. 根据确定了的Web服务器和文件名生成HTTP请求
       3. 查询服务器域名对应的IP地址，DNS协议（根DNS服务器，顶级域DNS服务器，权威DNS服务器），先在本地DNS服务器的缓存表格里找，找到返回，没找到去问它的根域名服务器。
       4. 浏览器通过调用Socket库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的TCP和UDP协议，这两个传输协议会接受应用层的委托执行收发数据的操作。协议栈的下面一半是用IP协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由IP负责的。
       5. IP还包括ICMP协议和ARP协议。（ICMP用于告知网络包传送过程中产生的错误以及各种控制信息。ARP用于根据IP地址查询相应的以太网MAC地址。）。IP下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责弯沉故事集的收发操作，也就是对网线中的信号执行发送盒接收操作。
       6. 基于TCP协议传输的HTTP，三次握手，TCP传输数据，发送TCP报文
       7. IP模块将数据封装成网络包发送给通信对象，IP协议里需要有源地址IP和目标地址IP
       8. 生成IP头部后，接下来网络包还需要在IP头部的前面加上MAC头部（ARP寻找MAC地址）
       9. 将数字信息转换为电信号，才能在网线上传输，负责这一操作的是网卡，控制网卡的是网卡驱动程序。
       10. 。。。
       11. 数据包抵达了服务器，开始对数据包开始解包。然后把要访问的页面封装在HTTP响应报文发送。
       12. 客户端收到数据包，开始渲染页面。
       13. 四次挥手。

12. mysql主键和唯一键的区别，唯一键可不可以是null,字符串可不可以为空

    1. 主键和唯一键的区别：
       1. 用来唯一地约束该字段里面的数据，不能重复，不能为空，一张表里最多只能有一个主键，主键所在的列通常是整数类型。
       2. 唯一键的本质和主键差不多，唯一键允许为空，且允许多个为空，空字段不做唯一性要求
    2. 唯一键可不可以是null：
       1. 唯一键允许为空，且允许多个为空，空字段不做唯一性要求
    3. 字符串可不可以为空：
       1. 字符串字段的值可以为空。空字符串是指字段中没有任何字符的情况，与NULL值不同。
       2. 在MYSQL中，NULL表示缺少值或者未知值，当我们不知道或者没有提供某个字段的值时候，可以将其设置为NULL。NULL值在数据库中被视为未知或无效的值，因此无法与任何其他值进行比较。
       3. 空字符串表示字段有一个值，但该值为空。空字符串是有效的字符串，可以与其他字符串进行比较。

13. 详细解释一下索引，以及索引的好处

    1.  对数据库中的表进行查询操作，有两种搜索扫描方式：一种是全表扫描，另一种是使用表上建立的索引进行扫描。

       ​    全表扫描要查找某个特定的行，必须从头开始一一查看表中的每一行，与查询条件作对比，返回满足条件的记录，当表中有很多行时，查询效率非常低。

    2.  索引在MySQL中也叫做“键”，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能
       非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。

    3.  b+树

    4.  真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。

    5.  如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。

    6.  提高查询速度
        保证列值的唯一性
        查询优化依靠索引起作用
        提高ORDER BY，GROUP BY的执行速度

14. 游戏测试的主要内容：

    1. 功能测试：主要是黑箱测试
    2. 客户端的性能测试：也就是客户端CPU占用率之类的
    3. 服务端的压力测试：服务器CPU使用率
    4. 兼容测试：机型适配测试
    5. 安全测试：内存修改测试、加密测试等
    6. 接口测试？

15. 游戏测试的流程：

    1. 阅读策划需求
    2. 理解需求
    3. 需求核对
    4. 制定测试计划、需求估时、资源准备
    5. 用例设计以及评审
    6. 测试和跟进流程
    7. 回归测试（bug修复后重新进行测试）、冒烟测试（完成新版本的开发后对该版本最基本的功能进行测试）
    8. 输出测试报告

16. 黑盒测试：

    1. 等价类->有效等价类和无效等价类
    2. 边界值法（一般都是大一和小一的）
    3. 因果图法
    4. 场景法
    5. 正交实验法
    6. 判定表法

17. **白盒测试需要遵循的原则：**
       1、保证一个模块中的所有独立至少被测试一次；
       2、所有逻辑值需要测试真（true）和假（false）；
       3、检查程序的内部数据结构，保证其结构的有效性；
       4、在上下边界及可操作范围内运行所有循环。

18. HTTP无状态

    1. HTTP无状态协议，是指协议对于事务处理没有记忆[能力](https://baike.baidu.com/item/能力/33045?fromModule=lemma_inlink)。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。

19. acid:原子性、一致性、隔离性、持久性

    1. 原子性：事务是最小执行单位，不允许分割。事务的原子性确保动作要么全部执行要么全部不执行。
    2. 一致性：执行事务的前后，数据保持一致。
    3. 隔离性：并发访问数据库的时候，一个用户的事务不应该被其他事务所影响，各并发事务之间数据库是独立的。
    4. 持久性：一个事务被提交后，它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有影响。

20. 聚集索引和非聚集索引的区别

    1. 聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个。
    1. 聚集索引存储记录是物理上连续存在，物理存储按照索引排序，而非聚集索引是逻辑上的连续，物理存储并不连续。

21. 公平锁和非公平锁

    1. 多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。
    2. 多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。

22. 乐观锁和悲观锁

    1. 乐观锁：乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。
    2. 悲观锁：悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。

23. B+树的结构

    1. B+ 树索引由根节点（root node）、中间节点（non leaf node）、叶子节点（leaf node）组成，其中叶子节点存放所有排序后的数据。当然也存在一种比较特殊的情况，比如高度为 1 的B+ 树索引
    2. 叶子节点中间用链表相连
    3. 3层的B+树能存放几千万数据
    4. 4层能存放几十亿数据

24. 事务隔离

    1. 读取未提交：允许读取尚未提交的数据变更，可能造成脏读、不可重复读、幻读。
    2. 读取已提交：允许读取并发事务已经提交的数据，可以避免脏读，但是可能造成不可重复、幻读。
    3. 可重复读取：对同一字段多次读取的结果都是一致。
    4. Serializable（可串行化）：最高级别的隔离级别，完全服从ACID的隔离级别，所有的事务依次执行，可以避免脏读、不可重复读、幻读
    5. MYSQL默认的是可重复读，不能避免幻读

25. 多线程

    1. 两个线程轮流输出奇偶数
       1. sem_t || sem_init(&sem1,0,0) || sem_post(&sem) || sem_wait(&sem)
    2. 


## Unix网络编程

1. 先完成WebServer
2. 线程间的同步机制
3. 进程间的通信

## 游戏图形学

1. 叉乘的物理意义
2. 旋转的顺序变换结果一样吗（不一样，矩阵乘法）
